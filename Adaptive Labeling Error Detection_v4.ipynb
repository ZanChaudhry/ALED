{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "# %matplotlib inline\n",
    "#import imutils\n",
    "\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.layers import Conv2D,Input,ZeroPadding2D,BatchNormalization,Flatten,Activation,Dense,MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle #shuffling the data improves the model\n",
    "import warnings\n",
    "\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "#torch.cuda.manual_seed_all(SEED)\n",
    "warnings.filterwarnings(\"ignore\", \"Lazy modules are a new feature.*\")\n",
    "\n",
    "from torch import nn,optim\n",
    "from torchvision import transforms as T,datasets,models\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torchsummary\n",
    "#from torchvision import imshow\n",
    "# import cleanlab\n",
    "# from cleanlab.classification import CleanLearning\n",
    "# from cleanlab.benchmarking import noise_generation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from numpy.random import multivariate_normal\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import random\n",
    "#import cv2\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from PIL import Image\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data.sampler import SubsetRandomSampler  # For validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALED Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.covariance import MinCovDet\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import scipy.stats\n",
    "\n",
    "class ALED(sklearn.base.BaseEstimator, sklearn.base.ClassifierMixin):\n",
    "    # BaseEstimator provides get and set_params() functions and ClassifierMixin provides weighted accuracy\n",
    "\n",
    "    def __init__(self, random_state = 0): # random_state is default 0 for now, should be changed later!\n",
    "        # Note: I think the sklearn API would say that some fit() params [e.g., model, max_pca_components, max_pca_variance]\n",
    "        #   should be instantiation params and not fit() params\n",
    "\n",
    "        self.random_state = random_state\n",
    "\n",
    "    @staticmethod\n",
    "    def sum_until(in_list, threshold):\n",
    "        \"\"\"\n",
    "        Helper function for fit()\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        for n in range(len(in_list)):\n",
    "            if count < threshold:\n",
    "                count += in_list[n]\n",
    "            else:\n",
    "                break\n",
    "        return count, n+1\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_likelihood(cov_matrix, mahalanobis_squared_dist):\n",
    "        \"\"\"\n",
    "        Helper function for fit()\n",
    "        \"\"\"\n",
    "        n = cov_matrix.shape[0]\n",
    "        sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
    "        prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
    "        #if prob_x_f > 1: print(\"prob_x_f > 1; prob_x_f =\", prob_x_f)\n",
    "        return prob_x_f\n",
    "\n",
    "    def extract_conv_net_features(self, conv_net, dataset):\n",
    "        \"\"\"\n",
    "        Helper function for fit()\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def map_conv_net_output(self):\n",
    "        \"\"\"\n",
    "        Map the last layer of the convolutional layer (or other last feature extraction layer)\n",
    "        so each sample ends up with 1 dimension of representative features\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def extract_out_label(self, prediction_stats_row):\n",
    "        given_label = prediction_stats_row['given label (name)']\n",
    "        probabilities_row = np.array([prediction_stats_row[\"p(k = {} | x)\".format(class_i)] for class_i in self.classes_])\n",
    "        if (self.classes_[probabilities_row.argmax()] != given_label)\\\n",
    "           and (probabilities_row.max()/prediction_stats_row[\"p(k = {} | x)\".format(given_label)] > self.likelihood_ratio_threshold):\n",
    "            return self.classes_[probabilities_row.argmax()]\n",
    "        else:\n",
    "            return given_label\n",
    "\n",
    "    def fit_predict(self, model, dataset, device=None, max_pca_components=10, max_pca_variance=0.25, likelihood_ratio_threshold=2, prob_method=\"gaussian\", batch_size=100):\n",
    "        # sklearn would want us to separate into fit() and predict() (NR)\n",
    "        \"\"\"\n",
    "        Given a model and data, outputs predicted class for each sample based on ALED algorithm.\n",
    "        Creates a new model that aggregates input classification model features / feature maps at last layer before classification into a [p x 1] vector.\n",
    "        Then performs PCA to generate an [n x 1] vector of PCs, where n is specified either explicitly or by a desired level of explained variance. Then\n",
    "        the probability that a given sample belongs to the assigned class is assessed using Bayes' rule, and if the probability falls below the within\n",
    "        class threshold, then the sample is compared to the other class(es), and if the probability that it belongs in another class is higher than the\n",
    "        out of class threshold, then the sample is added to an output DataFrame containing suspect samples and their associated probabilities. This\n",
    "        function is dependent on the ability of the input classification model to extract salient features from the input data and thus should only be\n",
    "        applied if the model is achieving some threshold auc / accuracy.\n",
    "\n",
    "        ### Parameters\n",
    "        1. model : Pytorch model (torch.nn.Sequential)\n",
    "            -A classification model\n",
    "        2. dataset : Pytorch Dataset (torch.utils.data.Dataset, eventually...right now needs an ImageFolder)\n",
    "            -The dataset used to train model\n",
    "             note: the dataset is responsible for holding any transformation functions;\n",
    "             the transformations need to be the same transformations done for model evaluation; data augmentation should NOT be used!!!\n",
    "        x. device : str, or None\n",
    "            -Specifies device (e.g. 'cuda' GPU) to be used for processing\n",
    "        4. max_pca_components : int\n",
    "            -Maximum number of components used for PCA (10 by default);\n",
    "             determines\n",
    "        5. pca_variance : float\n",
    "            -Ratio of explained variance desired, if\n",
    "             using explained variance method (0.25 by\n",
    "             default)\n",
    "        6. wc_threshold : float\n",
    "            -Within class threshold to consider sample\n",
    "             within distribution of other class(es) (0.05\n",
    "             by default)\n",
    "        7. ooc_threshold : float\n",
    "            -Out of class threshold to see whether flagged\n",
    "             samples belong to other class(es) (0.95 by\n",
    "             default)\n",
    "        8. prob_method : str\n",
    "            -Method to use for calculating the likelihood,\n",
    "             either specify a distribution type or use a\n",
    "             non-parametric estimator (\"gaussian\" is\n",
    "             default)\n",
    "        9. data_transforms : func\n",
    "            -Any data transformations performed prior to use\n",
    "             by the model # specify torchvision transforms (NR)\n",
    "\n",
    "        ### Returns\n",
    "        1. label_issues_df : Pandas DataFrame (pd.DataFrame)\n",
    "            -A DataFrame containing the samples that are\n",
    "             suspected label errors and their associated\n",
    "             probabilities of belonging to each class,\n",
    "             as calculated by the above methods\n",
    "\n",
    "        ### Raises\n",
    "        ______\n",
    "        We'll get to that\n",
    "\n",
    "        ### object attributes created:\n",
    "        - self.conv_net\n",
    "        - self.X_\n",
    "        - self.y_\n",
    "        - self.classes_\n",
    "        - self.pca\n",
    "        - self.num_pca_components\n",
    "        - self.pca_explained_variance\n",
    "        - self.X_pca_tf\n",
    "        - self.c\n",
    "        - self.prediction_stats\n",
    "\n",
    "        \"\"\"\n",
    "        # Define Adaptive Labeling Error Detection (ALED) feature extraction model\n",
    "        # I changed \"ALED_model\" to \"self.conv_net\"; please don't kill me; I think CNN, conv_net, or FEM are better names (NR)\n",
    "        self.conv_net = nn.Sequential(*list(copy.deepcopy(model).eval().children())[:-1])\n",
    "        # self.conv_net\n",
    "        # I think this^ won't work for all models; maybe we do a deep recursive dive into model.modules() or\n",
    "        #    model.children() to identify the last layer of type conv (NR)\n",
    "\n",
    "        self.conv_net.avgpool = torch.nn.AdaptiveAvgPool2d((1,1)) # Feature pooling of feature maps, probably will need to add another method for 1d and 3d features\n",
    "        print(self.conv_net)\n",
    "        # Create sorted representation of data (right now only works on images in chest x-ray dataset):\n",
    "\n",
    "        BATCH_SIZE = batch_size # maybe a param?\n",
    "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        feat_array = None # will be initialized once we know size of\n",
    "        y = np.zeros(len(dataset))\n",
    "        with torch.no_grad():\n",
    "            for batch_num, (inputs, labels) in enumerate(dataloader):\n",
    "                # note: the dataset is responsible for holding any transformation functions;\n",
    "                # the transformations need to be the same transformations done for model evaluation; data augmentation should NOT be used!!!\n",
    "\n",
    "                batch_cuda = inputs.to(device)\n",
    "                \n",
    "                batch_feat = self.conv_net(batch_cuda)\n",
    "                batch_feat_cpu = batch_feat.to('cpu').squeeze() # this might need to be changed - can we assume user wants to use 'cpu'?\n",
    "                # return batch_feat_cpu\n",
    "                if feat_array is None:\n",
    "                    feat_array = np.zeros((len(dataset), *batch_feat_cpu.shape[1:]))\n",
    "\n",
    "                feat_array[batch_num*BATCH_SIZE : batch_num*BATCH_SIZE + len(batch_feat_cpu)] = batch_feat_cpu\n",
    "                y[         batch_num*BATCH_SIZE : batch_num*BATCH_SIZE + len(batch_feat_cpu)] = labels\n",
    "\n",
    "                del batch_cuda\n",
    "                del batch_feat\n",
    "\n",
    "        # feat_array.squeeze()\n",
    "\n",
    "        print(\"feat_array.shape, y.shape:\", feat_array.shape, y.shape)\n",
    "        # Check that X and y have correct shape\n",
    "        feat_array, y = check_X_y(feat_array, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = feat_array\n",
    "        self.y_ = y\n",
    "#         self.sample_weights = sample_weight # might need sample_weight param for compatibility with sklearn - document if ignored\n",
    "\n",
    "        # perform PCA\n",
    "        from sklearn.decomposition import PCA\n",
    "        self.pca = PCA(n_components = max_pca_components) # don't rename this - we overwrite this variable 3 lines later\n",
    "        self.pca.fit(feat_array)\n",
    "        calc_var, max_variance_num_comps = self.sum_until(self.pca.explained_variance_ratio_, max_pca_variance)\n",
    "        self.pca = PCA(n_components = min(max_pca_components, max_variance_num_comps)).fit(feat_array)\n",
    "        self.X_pca_tf = self.pca.transform(feat_array) # pca_tf means pca transformed\n",
    "\n",
    "        # instead of PCA, consider sklearn.random_projection.GaussianRandomProjection - maybe more robust to noise (NR)\n",
    "        # also, random_projection.johnson_lindenstrauss_min_dim(...) finds a 'safe' number of components to randomly project to.\n",
    "\n",
    "\n",
    "        # optional (could be helpful for user):\n",
    "        self.num_pca_components = self.pca.n_components_\n",
    "        self.pca_explained_variance = calc_var\n",
    "        print(\"number of pca components:\", self.num_pca_components)\n",
    "        print(\"PCA explained variance:\", self.pca_explained_variance)\n",
    "\n",
    "        # Calculate covariance matrices for all class distributions\n",
    "        self.num_classes = len(self.classes_)\n",
    "        self.class_indices_dict = {}\n",
    "        self.priors_dict = {}\n",
    "        self.PC_dict = {}\n",
    "        self.cov_dict = {}\n",
    "        self.mvn_distributions = {}\n",
    "\n",
    "        for class_i in self.classes_:\n",
    "            class_indices = np.array(np.arange(len(feat_array))[y == class_i])\n",
    "            self.class_indices_dict[\"class{}_indices\".format(class_i)] = class_indices\n",
    "            class_PC_array = self.X_pca_tf[class_indices, :]\n",
    "            self.PC_dict[\"class{}_PC_array\".format(class_i)] = class_PC_array\n",
    "            self.cov_dict[\"robust_cov{}\".format(class_i)] = MinCovDet(random_state=self.random_state).fit(class_PC_array)\n",
    "            # self.mvn_distributions[\"mvn_{}\".format(class_i)] = scipy.stats.multivariate_normal(mean=class_PC_array.mean(axis=0), cov=np.cov(class_PC_array, rowvar=False), seed=self.random_state) # this line from chatgpt, so could be good to double check the cov matrix is right (NR)\n",
    "\n",
    "        # Calculate prior probabilities\n",
    "        for class_i in self.classes_:\n",
    "            prior = len(self.class_indices_dict[\"class{}_indices\".format(class_i)]) / len(y)\n",
    "            self.priors_dict[\"prior_prob{}\".format(class_i)] = prior\n",
    "\n",
    "        # Calculate likelihoods\n",
    "        likelihoods_df_dict = {}\n",
    "        for class_i in self.classes_:\n",
    "            likelihoods_dict = {}\n",
    "            for class_j in self.classes_:\n",
    "                cov_matrix = self.cov_dict[\"robust_cov{}\".format(class_j)].covariance_ #raw_covariance_ # why do we use raw_covariance_ instead of covariance_? (NR)\n",
    "                cov_mahalanobis = self.cov_dict[\"robust_cov{}\".format(class_j)].mahalanobis(self.PC_dict[\"class{}_PC_array\".format(class_i)]) # I think this was redundant; see MinCovDet.dist_ (NR)\n",
    "                likelihoods_dict[\"p(x | k = {})\".format(class_j)] = np.array([self.gaussian_likelihood(cov_matrix, sample) for sample in cov_mahalanobis])\n",
    "\n",
    "                # mahalanobis_distances = self.cov_dict[\"robust_cov{}\".format(class_j)].dist_\n",
    "                # likelihoods_dict[\"p(x | k = {})\".format(class_j)] = np.array([self.gaussian_likelihood(cov_matrix, sample**2) for sample in mahalanobis_distances])\n",
    "\n",
    "                # likelihoods = self.mvn_distributions[\"mvn_{}\".format(class_j)].pdf(self.PC_dict[\"class{}_PC_array\".format(class_i)])\n",
    "                # class_j_pca_tf = self.PC_dict[\"class{}_PC_array\".format(class_j)]\n",
    "                # likelihoods = scipy.stats.multivariate_normal.pdf(self.PC_dict[\"class{}_PC_array\".format(class_i)], mean=class_j_pca_tf.mean(axis=0), cov=np.cov(class_j_pca_tf, rowvar=False))\n",
    "                # likelihoods_dict[\"p(x | k = {})\".format(class_j)] = likelihoods\n",
    "\n",
    "            likelihoods_df = pd.DataFrame.from_dict(likelihoods_dict).set_index(self.class_indices_dict[\"class{}_indices\".format(class_i)])\n",
    "            likelihoods_df_dict[\"likelihood_df{}\".format(class_i)] = likelihoods_df\n",
    "\n",
    "        # Calculate probabilities\n",
    "        final_dfs_list = []\n",
    "        for class_i in self.classes_:\n",
    "            likelihoods_df = likelihoods_df_dict[\"likelihood_df{}\".format(class_i)]\n",
    "            for class_j in self.classes_:\n",
    "                likelihoods_df[\"p(k = {} | x)\".format(class_j)] = likelihoods_df[\"p(x | k = {})\".format(class_j)] * self.priors_dict[\"prior_prob{}\".format(class_j)] / \\\n",
    "                    sum( [likelihoods_df[\"p(x | k = {})\".format(class_k)] * self.priors_dict[\"prior_prob{}\".format(class_k)] for class_k in self.classes_] )\n",
    "#             likelihoods_df[\"given label (num)\"] = n\n",
    "            likelihoods_df[\"given label (name)\"] = class_i\n",
    "            # likelihoods_df[\"updated label (name)\"] =\n",
    "            final_dfs_list.append(likelihoods_df)\n",
    "\n",
    "        self.prediction_stats = pd.concat(final_dfs_list).sort_index()\n",
    "        self.likelihood_ratio_threshold = likelihood_ratio_threshold\n",
    "        self.prediction_stats['Aled label'] = self.prediction_stats.apply(self.extract_out_label, axis=1)\n",
    "\n",
    "        return self.prediction_stats['Aled label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    # 'test'  : torch.utils.data.DataLoader(test_data,  ############################### FOR NOW TEST ON TRAIN DATA. NO DATA LEAKAGE!\n",
    "    #                                       batch_size=100, \n",
    "    #                                       shuffle=True, \n",
    "    #                                       num_workers=1),\n",
    "\n",
    "    'test'  : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/600], Loss: 0.1092\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0455\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1383\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0259\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1006\n",
      "Epoch [1/1], Step [600/600], Loss: 0.0640\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "num_epochs = 1\n",
    "def train(num_epochs, cnn, loaders, optimizer):\n",
    "    \n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            output = cnn(b_x)\n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "    #             pass\n",
    "        \n",
    "    #     pass\n",
    "    \n",
    "    \n",
    "    # pass\n",
    "train(num_epochs, cnn, loaders, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(cnn):\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        labels_list = []\n",
    "        preds_list = []\n",
    "\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "        print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "        return labels, (torch.softmax(test_output, 1))\n",
    "\n",
    "\n",
    "def get_output_probs(model, loader, device=None):\n",
    "    # Test the model\n",
    "    model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = None\n",
    "        all_preds = None\n",
    "\n",
    "        for images, labels in loader:\n",
    "            if all_labels is None:\n",
    "                all_labels = labels\n",
    "                all_preds = model(images.to(device))\n",
    "            else:\n",
    "                all_labels = torch.cat((all_labels, labels))\n",
    "                all_preds = torch.cat((all_preds, model(images.to(device))))\n",
    "        return np.array(all_labels.cpu()), np.array(torch.softmax(all_preds.cpu(), 1))\n",
    "\n",
    "def get_outputs(model, loader, device=None):\n",
    "    labels, probs = get_output_probs(model, loader, device)\n",
    "    return labels, np.argmax(probs, axis=1)\n",
    "\n",
    "# test(cnn)\n",
    "# get_outputs(cnn, loaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction number: [1 9 0 9 7 5 3 3 1 3]\n",
      "Actual number: [1 9 0 9 7 5 3 3 1 3]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(loaders['test']))\n",
    "imgs, lbls = sample\n",
    "actual_number = lbls[:10].numpy()\n",
    "test_output = cnn(imgs[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(f'Prediction number: {pred_y}')\n",
    "print(f'Actual number: {actual_number}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Mislabeling Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "\n",
    "class Mislabeling_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    a Dataset class that contains a Dataset, providing the data of the internal Dataset\n",
    "    but with labeling errors\n",
    "    \"\"\"\n",
    "    def __init__(self, internal_dataset, internal_dataset_labels = None, fraction_mislabeled = 0.1, random_state = None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.internal_dataset = copy.deepcopy(internal_dataset)\n",
    "        self.true_labels = copy.deepcopy(internal_dataset_labels)\n",
    "        if self.true_labels is None:\n",
    "            self.set_true_labels()\n",
    "        elif len(self.true_labels) != len(internal_dataset):\n",
    "          raise Exception(\"Must have same number of labels as the length of the dataset [i.e. len(internal_dataset_labels) == len(internal_dataset)]\")\n",
    "        self.classes = unique_labels(self.true_labels)\n",
    "        self.fraction_mislabeled = fraction_mislabeled\n",
    "        self.rng = np.random.default_rng(random_state)\n",
    "        # could potentially add a parameter to choose what method to mislabel (e.g., completely random, half mislabeled from each class)\n",
    "\n",
    "\n",
    "        self.mislabel_sample_inds = self.rng.choice(np.arange(len(self.internal_dataset)), size=int(self.fraction_mislabeled*len(internal_dataset)), replace=False)\n",
    "        mislabel_maps = [[class_j for class_j in self.classes if class_j != class_i] for class_i in self.classes]\n",
    "\n",
    "        self.labels = copy.deepcopy(self.true_labels)\n",
    "        for ind in self.mislabel_sample_inds:\n",
    "            self.labels[ind] = mislabel_maps[self.true_labels[ind]][self.rng.integers(len(self.classes)-1)]\n",
    "\n",
    "\n",
    "    def set_true_labels(self):\n",
    "        # helper function used by __init__()\n",
    "        self.true_labels = np.zeros(len(self.internal_dataset), dtype=object)\n",
    "        for i in range(len(self.internal_dataset)):\n",
    "            self.true_labels[i] = self.internal_dataset[i][1]\n",
    "\n",
    "    # def __getattr__(self, attr):\n",
    "    #     # wrapping an object; source: https://code.activestate.com/recipes/577555-object-wrapper-class/\n",
    "    #     if attr in self.__dict__:\n",
    "    #         return getattr(self, attr)\n",
    "    #     return getattr(self.internal_dataset, attr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.internal_dataset[idx][0], self.labels[idx].item()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.internal_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mislabeled_train_data = Mislabeling_Dataset(train_data, internal_dataset_labels=train_data.targets, fraction_mislabeled=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent purposely mislabeled =  0.09999999999999998\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7]\n",
      "[5 0 4 1 9 2 1 3 1 4 3 3 4 6 1 7 2 3 6 9 9 0 9 1 1 2 4 3 9 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_dataset_labels = train_data.targets\n",
    "mislabeled_dataset_true_labels = mislabeled_train_data.true_labels\n",
    "mislabeled_dataset_labels = mislabeled_train_data.labels\n",
    "\n",
    "assert((original_dataset_labels == mislabeled_dataset_true_labels).all())\n",
    "print(\"percent purposely mislabeled = \", 1 - (mislabeled_dataset_true_labels.numpy() == mislabeled_dataset_labels.numpy()).mean())\n",
    "\n",
    "(mislabeled_dataset_true_labels.numpy() != mislabeled_dataset_labels.numpy())[:40]\n",
    "print(np.arange(10), mislabeled_dataset_true_labels.numpy()[:30], mislabeled_dataset_labels.numpy()[:30], sep='\\n')\n",
    "for i in range(2):\n",
    "  plt.imshow(train_data[i][0].squeeze().numpy(), cmap='gray')\n",
    "  plt.title('trainset %i' % train_data.targets[i])\n",
    "  plt.show()\n",
    "\n",
    "  plt.imshow(mislabeled_train_data[i][0].squeeze().numpy(), cmap='gray')\n",
    "  plt.title('trainset_mislabeled %i' % mislabeled_train_data.labels[i])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_1 = {\n",
    "    'train' : torch.utils.data.DataLoader(mislabeled_train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=0),\n",
    "    \n",
    "    \n",
    "    # 'test'  : torch.utils.data.DataLoader(test_data, ############################### FOR NOW TEST ON TRAIN DATA. NO DATA LEAKAGE!\n",
    "    #                                       batch_size=100, \n",
    "    #                                       shuffle=True, \n",
    "    #                                       num_workers=0),\n",
    "\n",
    "    \n",
    "    'test' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_1 = CNN()\n",
    "print(cnn_1)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "optimizer_1 = optim.Adam(cnn_1.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/600], Loss: 0.5552\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5772\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6843\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7443\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8214\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5348\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, cnn_1, loaders_1, optimizer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([2, 1, 4, 4, 3, 4, 3, 6, 0, 8, 9, 2, 9, 6, 2, 9, 4, 3, 8, 8, 6, 3, 7, 0,\n",
       "         3, 0, 7, 0, 4, 3, 4, 7, 6, 2, 3, 4, 5, 3, 6, 9, 9, 4, 5, 0, 4, 6, 6, 6,\n",
       "         4, 9, 9, 8, 5, 7, 4, 6, 8, 1, 0, 6, 6, 9, 7, 4, 5, 6, 9, 7, 0, 5, 6, 4,\n",
       "         4, 2, 1, 5, 0, 0, 3, 8, 2, 6, 5, 2, 2, 3, 8, 9, 0, 7, 1, 8, 2, 3, 9, 9,\n",
       "         7, 5, 7, 1]),\n",
       " tensor([[4.9779e-03, 6.7816e-04, 9.6743e-01, 3.0782e-03, 7.8087e-03, 6.7515e-04,\n",
       "          1.6864e-03, 4.1178e-03, 8.0452e-03, 1.5041e-03],\n",
       "         [1.5127e-02, 9.3075e-01, 1.0856e-02, 6.8854e-03, 5.3118e-03, 1.0177e-02,\n",
       "          4.2306e-03, 3.7324e-03, 7.5036e-03, 5.4313e-03],\n",
       "         [6.5658e-03, 2.7613e-02, 1.5635e-02, 3.0340e-03, 9.0495e-01, 9.3573e-03,\n",
       "          7.9207e-03, 1.1126e-02, 7.4067e-03, 6.3975e-03],\n",
       "         [3.1525e-02, 5.6164e-02, 7.9518e-03, 1.3949e-01, 4.5264e-01, 7.3019e-02,\n",
       "          9.6137e-03, 7.2515e-02, 5.0268e-02, 1.0681e-01],\n",
       "         [3.0646e-02, 7.9453e-03, 5.6333e-03, 8.9871e-01, 4.0600e-03, 1.0600e-02,\n",
       "          2.3221e-03, 2.9507e-02, 2.8355e-03, 7.7438e-03],\n",
       "         [2.7111e-02, 3.7886e-02, 1.2082e-02, 6.5241e-02, 6.1492e-01, 3.3592e-02,\n",
       "          8.6097e-03, 7.2913e-02, 2.8925e-02, 9.8725e-02],\n",
       "         [7.8572e-03, 1.8684e-02, 4.5602e-02, 7.3699e-01, 2.7914e-02, 1.2411e-02,\n",
       "          7.1150e-03, 2.6995e-02, 4.7003e-02, 6.9425e-02],\n",
       "         [2.3606e-02, 1.7730e-02, 8.5710e-03, 3.1639e-02, 3.3975e-02, 1.5668e-01,\n",
       "          5.9042e-01, 5.8736e-03, 9.5622e-02, 3.5889e-02],\n",
       "         [9.4140e-01, 7.7515e-03, 1.6612e-02, 9.1705e-03, 8.6459e-03, 1.8617e-03,\n",
       "          8.1796e-03, 1.7631e-03, 8.1003e-04, 3.8105e-03],\n",
       "         [4.0449e-03, 5.4081e-03, 8.9205e-03, 1.1189e-02, 7.6022e-03, 5.2376e-03,\n",
       "          2.2458e-03, 4.8218e-02, 9.0538e-01, 1.7569e-03],\n",
       "         [4.7457e-03, 8.3335e-03, 1.8779e-03, 3.8360e-03, 8.0129e-03, 4.6316e-01,\n",
       "          2.0619e-02, 2.0707e-02, 4.4527e-03, 4.6426e-01],\n",
       "         [1.8642e-03, 8.7650e-04, 9.7821e-01, 1.6201e-03, 2.6873e-03, 3.1072e-03,\n",
       "          1.6417e-03, 5.8551e-03, 3.2405e-03, 8.9797e-04],\n",
       "         [7.6015e-03, 2.0977e-02, 1.6652e-03, 3.5214e-03, 4.9956e-02, 1.1379e-01,\n",
       "          1.7059e-02, 3.2277e-02, 2.0542e-02, 7.3261e-01],\n",
       "         [1.2995e-02, 3.1748e-02, 4.9326e-03, 1.9755e-02, 1.6017e-02, 1.2068e-02,\n",
       "          8.7638e-01, 7.5058e-03, 7.0922e-03, 1.1508e-02],\n",
       "         [2.3516e-03, 5.6407e-04, 9.7739e-01, 7.3082e-03, 5.5504e-03, 1.0160e-03,\n",
       "          9.3664e-04, 4.0664e-03, 6.5933e-04, 1.6051e-04],\n",
       "         [1.9837e-02, 1.5420e-02, 1.1268e-02, 3.8874e-02, 1.8654e-02, 3.4500e-02,\n",
       "          4.8816e-03, 4.6286e-02, 3.2285e-02, 7.7799e-01],\n",
       "         [9.4869e-03, 1.6187e-02, 1.7425e-02, 4.8106e-03, 8.6687e-01, 9.9435e-03,\n",
       "          2.9060e-02, 6.6753e-03, 2.6539e-02, 1.2997e-02],\n",
       "         [2.7991e-02, 3.5185e-03, 2.1943e-02, 9.0082e-01, 6.5826e-03, 7.3101e-03,\n",
       "          3.2210e-03, 8.7397e-03, 7.2747e-03, 1.2598e-02],\n",
       "         [2.1709e-02, 6.5110e-03, 2.2035e-02, 9.2998e-03, 4.3880e-02, 7.1324e-03,\n",
       "          1.1845e-02, 3.4021e-03, 8.5828e-01, 1.5902e-02],\n",
       "         [2.5725e-02, 2.3854e-03, 1.0382e-02, 7.4972e-03, 7.5400e-03, 4.5482e-03,\n",
       "          8.7622e-03, 1.5698e-03, 9.2531e-01, 6.2769e-03],\n",
       "         [9.0095e-02, 9.6357e-02, 3.0109e-02, 4.8089e-02, 2.2860e-02, 2.8031e-02,\n",
       "          6.3198e-01, 4.6484e-03, 3.7917e-02, 9.9142e-03],\n",
       "         [2.4081e-02, 1.7316e-02, 1.8155e-02, 8.3439e-01, 7.3535e-03, 2.6634e-02,\n",
       "          5.5207e-03, 1.3865e-02, 2.4943e-02, 2.7742e-02],\n",
       "         [2.5519e-03, 7.9092e-03, 4.2396e-02, 5.0079e-03, 6.5031e-03, 1.1117e-03,\n",
       "          5.4298e-03, 9.1688e-01, 7.0589e-03, 5.1474e-03],\n",
       "         [8.4414e-01, 8.9502e-03, 3.7658e-02, 5.2672e-03, 7.3236e-03, 6.5301e-03,\n",
       "          3.9065e-02, 3.0720e-03, 8.9075e-03, 3.9084e-02],\n",
       "         [6.5734e-03, 9.0288e-03, 2.1805e-02, 9.2294e-01, 5.8015e-03, 7.5491e-03,\n",
       "          4.2095e-03, 4.7551e-03, 9.0000e-03, 8.3339e-03],\n",
       "         [6.6797e-01, 2.3748e-02, 2.5974e-02, 3.3138e-02, 4.6226e-03, 6.8844e-02,\n",
       "          6.8229e-02, 5.5642e-02, 6.0461e-03, 4.5788e-02],\n",
       "         [1.1382e-03, 2.5669e-03, 1.0677e-03, 1.5641e-03, 2.8236e-03, 6.3454e-04,\n",
       "          6.2164e-04, 9.8767e-01, 5.9190e-04, 1.3187e-03],\n",
       "         [7.9140e-01, 7.5429e-03, 8.9838e-02, 1.2576e-02, 4.0506e-02, 3.2818e-03,\n",
       "          3.5189e-02, 2.4496e-03, 6.9251e-03, 1.0287e-02],\n",
       "         [2.0463e-04, 1.8126e-03, 8.3937e-02, 8.9249e-03, 8.8233e-01, 1.7528e-03,\n",
       "          4.1334e-03, 1.5348e-02, 1.1808e-03, 3.7911e-04],\n",
       "         [5.6079e-03, 1.0801e-02, 1.4822e-02, 9.1372e-01, 1.2972e-02, 4.7307e-03,\n",
       "          2.3053e-03, 8.2809e-03, 4.7141e-03, 2.2046e-02],\n",
       "         [8.7280e-03, 1.6014e-02, 6.3631e-03, 8.1654e-04, 9.4964e-01, 3.6564e-03,\n",
       "          4.4856e-03, 5.0306e-03, 4.4932e-03, 7.6853e-04],\n",
       "         [3.3698e-02, 5.7032e-03, 6.1601e-03, 6.8148e-03, 5.2777e-03, 6.8782e-03,\n",
       "          1.1447e-02, 9.0709e-01, 5.0680e-03, 1.1861e-02],\n",
       "         [2.6332e-02, 9.9641e-03, 5.7896e-03, 1.8443e-02, 1.0160e-02, 1.6245e-02,\n",
       "          8.8396e-01, 1.8852e-03, 1.0418e-02, 1.6805e-02],\n",
       "         [8.8075e-04, 1.1555e-03, 9.6826e-01, 2.9165e-03, 4.4372e-03, 2.7935e-03,\n",
       "          8.2176e-04, 7.0984e-03, 1.1264e-02, 3.7272e-04],\n",
       "         [3.7980e-02, 2.3805e-02, 1.6596e-02, 8.2011e-01, 2.6948e-02, 1.6457e-02,\n",
       "          3.9354e-03, 1.1182e-02, 1.6041e-02, 2.6949e-02],\n",
       "         [6.1958e-03, 4.3541e-03, 1.8184e-02, 8.3522e-03, 8.7078e-01, 8.8031e-03,\n",
       "          1.3312e-02, 4.9858e-02, 1.6192e-02, 3.9734e-03],\n",
       "         [1.0328e-02, 8.9904e-03, 2.2227e-02, 3.9183e-02, 3.1119e-03, 8.7307e-01,\n",
       "          6.7614e-03, 9.1959e-03, 1.5947e-02, 1.1188e-02],\n",
       "         [4.7876e-03, 3.4720e-03, 1.0108e-02, 9.3956e-01, 2.7150e-03, 4.5520e-03,\n",
       "          2.0259e-03, 1.1349e-02, 5.2412e-03, 1.6187e-02],\n",
       "         [5.9557e-02, 2.4106e-01, 5.5365e-02, 4.7426e-02, 2.4976e-02, 4.6699e-02,\n",
       "          2.8118e-01, 1.0158e-02, 2.1527e-01, 1.8302e-02],\n",
       "         [8.5917e-03, 4.0131e-02, 1.7544e-02, 8.1264e-03, 1.0201e-01, 2.5694e-02,\n",
       "          1.0070e-02, 1.2355e-02, 4.6821e-01, 3.0727e-01],\n",
       "         [3.2066e-03, 5.6951e-03, 8.7733e-04, 8.2281e-03, 1.7754e-01, 4.4628e-03,\n",
       "          8.1717e-03, 2.4189e-01, 6.0963e-03, 5.4383e-01],\n",
       "         [1.2496e-02, 1.8398e-02, 1.5073e-02, 2.0302e-02, 8.8151e-01, 1.5019e-02,\n",
       "          9.4004e-03, 4.3884e-03, 1.1973e-02, 1.1441e-02],\n",
       "         [7.2083e-03, 7.4515e-03, 1.1224e-03, 1.6761e-02, 1.1796e-02, 9.0579e-01,\n",
       "          8.5017e-03, 4.0857e-03, 1.5253e-02, 2.2030e-02],\n",
       "         [8.7527e-01, 6.4493e-03, 3.8312e-02, 1.8312e-02, 7.4048e-03, 3.4743e-03,\n",
       "          1.6403e-02, 1.5994e-02, 1.1379e-02, 6.9966e-03],\n",
       "         [2.6327e-02, 8.1672e-02, 2.8347e-02, 3.0109e-02, 5.7164e-01, 5.2819e-02,\n",
       "          2.8168e-02, 4.3233e-02, 6.6264e-02, 7.1421e-02],\n",
       "         [2.0828e-02, 1.6152e-02, 1.4557e-02, 6.0932e-02, 1.4500e-02, 4.0877e-02,\n",
       "          7.5671e-01, 1.3061e-02, 1.8011e-02, 4.4374e-02],\n",
       "         [2.3073e-01, 5.2850e-02, 3.4696e-02, 3.9357e-02, 7.7942e-02, 1.9943e-01,\n",
       "          1.8201e-01, 5.0076e-02, 9.6349e-02, 3.6557e-02],\n",
       "         [1.8564e-02, 1.8635e-02, 1.6366e-02, 2.9893e-02, 2.6920e-02, 4.0149e-02,\n",
       "          7.7904e-01, 6.7130e-03, 4.1134e-02, 2.2587e-02],\n",
       "         [5.6432e-03, 5.9534e-03, 1.6995e-03, 1.6218e-02, 9.3873e-01, 1.1234e-02,\n",
       "          1.2377e-02, 2.9686e-03, 2.1598e-03, 3.0177e-03],\n",
       "         [4.6666e-01, 6.5731e-03, 2.8610e-02, 2.3205e-02, 1.7190e-02, 8.9166e-03,\n",
       "          2.6284e-02, 2.8694e-02, 8.2083e-03, 3.8566e-01],\n",
       "         [1.4416e-02, 5.6455e-03, 1.3679e-02, 1.8005e-02, 1.9144e-02, 6.7187e-03,\n",
       "          1.0931e-02, 2.0152e-02, 9.1991e-02, 7.9932e-01],\n",
       "         [1.1544e-02, 1.1976e-02, 4.8590e-03, 6.3302e-03, 4.0478e-02, 1.0553e-02,\n",
       "          3.4521e-02, 4.7525e-02, 5.8014e-01, 2.5208e-01],\n",
       "         [4.7184e-03, 2.7282e-03, 1.4300e-03, 3.5009e-02, 4.0773e-03, 9.4589e-01,\n",
       "          8.8244e-04, 9.1271e-04, 2.5490e-03, 1.8070e-03],\n",
       "         [4.3674e-02, 2.9022e-02, 3.9818e-02, 2.7239e-03, 8.8293e-02, 1.2798e-01,\n",
       "          6.7505e-02, 3.9188e-01, 2.1185e-02, 1.8792e-01],\n",
       "         [7.3767e-03, 4.1758e-03, 2.1444e-03, 3.7528e-03, 9.4651e-01, 4.0452e-03,\n",
       "          1.3907e-02, 4.1928e-03, 3.6269e-03, 1.0269e-02],\n",
       "         [3.5903e-02, 1.9624e-02, 3.5594e-02, 1.8433e-02, 1.2409e-01, 6.1554e-02,\n",
       "          6.4755e-01, 4.1369e-03, 2.8579e-02, 2.4536e-02],\n",
       "         [1.2089e-02, 2.0106e-03, 1.1658e-02, 6.3207e-03, 5.2149e-03, 6.3951e-03,\n",
       "          7.3115e-03, 3.4264e-03, 9.3507e-01, 1.0502e-02],\n",
       "         [1.9573e-02, 8.6483e-01, 2.9534e-02, 5.9568e-03, 1.4241e-02, 1.1237e-02,\n",
       "          7.4028e-03, 1.8471e-02, 2.0729e-02, 8.0265e-03],\n",
       "         [8.7038e-01, 6.9104e-03, 1.1233e-02, 1.0486e-02, 5.5014e-03, 1.1830e-02,\n",
       "          2.6771e-02, 7.7280e-03, 1.0691e-02, 3.8468e-02],\n",
       "         [3.4319e-02, 2.9737e-02, 3.3861e-03, 1.4575e-02, 1.1865e-02, 1.7712e-02,\n",
       "          8.5969e-01, 4.8906e-03, 5.1941e-03, 1.8628e-02],\n",
       "         [3.8919e-02, 3.5930e-02, 3.5143e-02, 1.9791e-02, 4.4448e-02, 6.5898e-02,\n",
       "          6.1642e-01, 5.0055e-03, 4.4490e-02, 9.3953e-02],\n",
       "         [1.4274e-02, 3.5647e-03, 2.4795e-03, 9.0785e-02, 9.7662e-03, 9.0451e-03,\n",
       "          9.8254e-03, 1.1934e-02, 8.4483e-03, 8.3988e-01],\n",
       "         [6.2902e-03, 3.8718e-03, 1.0336e-02, 1.0350e-02, 1.0726e-03, 3.8208e-03,\n",
       "          2.4222e-03, 9.5818e-01, 1.0443e-03, 2.6109e-03],\n",
       "         [1.1241e-03, 1.3705e-03, 7.8024e-03, 7.4385e-04, 9.7333e-01, 8.2334e-03,\n",
       "          2.2856e-03, 9.2607e-04, 1.9184e-03, 2.2635e-03],\n",
       "         [5.5339e-03, 7.9599e-03, 6.6268e-04, 5.0514e-03, 2.1685e-02, 9.1883e-01,\n",
       "          4.3295e-03, 9.8441e-03, 1.5400e-02, 1.0705e-02],\n",
       "         [3.9966e-02, 1.7929e-02, 3.9136e-02, 1.3432e-02, 6.3498e-02, 1.0340e-01,\n",
       "          6.0322e-01, 2.0572e-03, 8.3354e-02, 3.4010e-02],\n",
       "         [8.2321e-03, 1.4107e-02, 1.3054e-03, 1.0388e-02, 4.4050e-02, 4.1700e-03,\n",
       "          6.0811e-03, 1.4543e-02, 2.0625e-02, 8.7650e-01],\n",
       "         [3.9338e-03, 4.7134e-03, 1.1947e-03, 1.6261e-02, 1.4193e-03, 1.1600e-03,\n",
       "          9.1212e-04, 9.6720e-01, 1.0483e-03, 2.1569e-03],\n",
       "         [8.1667e-01, 2.3284e-02, 1.3581e-02, 3.3207e-02, 2.0648e-02, 2.1096e-02,\n",
       "          1.5402e-02, 2.6163e-03, 1.6830e-02, 3.6660e-02],\n",
       "         [3.6195e-03, 5.8262e-03, 1.8452e-02, 1.8900e-02, 8.3960e-03, 9.0434e-01,\n",
       "          3.5424e-03, 6.5897e-03, 2.0477e-02, 9.8611e-03],\n",
       "         [9.9867e-02, 1.1487e-02, 2.3181e-02, 2.2652e-02, 2.0939e-02, 2.0221e-02,\n",
       "          7.3220e-01, 6.2979e-03, 2.1714e-02, 4.1447e-02],\n",
       "         [3.5105e-02, 3.1732e-03, 2.2153e-03, 9.0767e-04, 9.4543e-01, 8.5724e-04,\n",
       "          3.6368e-03, 2.0921e-03, 3.7926e-03, 2.7892e-03],\n",
       "         [1.0717e-03, 1.5132e-02, 3.2456e-03, 7.0762e-04, 9.6759e-01, 3.8788e-03,\n",
       "          1.2610e-03, 4.1420e-03, 1.9649e-03, 1.0019e-03],\n",
       "         [3.9281e-02, 7.9565e-02, 5.2380e-01, 6.7993e-02, 5.6055e-03, 6.7117e-03,\n",
       "          2.8707e-02, 3.2113e-03, 2.3311e-01, 1.2017e-02],\n",
       "         [2.3879e-03, 9.5173e-01, 2.0242e-03, 6.1759e-03, 6.3809e-03, 6.0244e-03,\n",
       "          1.5816e-03, 1.7514e-03, 1.5563e-02, 6.3764e-03],\n",
       "         [6.9423e-03, 6.3849e-03, 1.8534e-03, 4.7127e-03, 2.9931e-02, 8.8270e-01,\n",
       "          3.1275e-02, 5.3549e-03, 7.8480e-03, 2.3002e-02],\n",
       "         [8.6466e-01, 1.2281e-02, 4.9608e-03, 2.7147e-02, 3.2922e-03, 1.9334e-02,\n",
       "          2.4065e-02, 8.4277e-03, 3.3890e-03, 3.2444e-02],\n",
       "         [6.3736e-01, 2.2688e-02, 3.5975e-02, 2.6726e-02, 1.1346e-02, 8.2336e-03,\n",
       "          1.0429e-01, 9.0338e-03, 5.3343e-03, 1.3901e-01],\n",
       "         [7.1195e-02, 6.9748e-03, 8.9234e-02, 6.9253e-01, 2.7974e-03, 2.5561e-02,\n",
       "          1.3843e-02, 5.5322e-02, 2.7755e-02, 1.4787e-02],\n",
       "         [5.0109e-03, 4.8639e-03, 1.6604e-02, 1.6960e-02, 7.6526e-03, 2.2027e-02,\n",
       "          7.0733e-03, 9.4523e-04, 8.9404e-01, 2.4818e-02],\n",
       "         [3.0602e-02, 3.5314e-02, 7.3562e-01, 4.4864e-02, 7.3621e-03, 2.0002e-02,\n",
       "          1.0485e-02, 6.5753e-03, 1.0369e-01, 5.4866e-03],\n",
       "         [2.3141e-02, 1.9988e-02, 5.2974e-03, 1.2234e-02, 4.0146e-02, 1.4692e-01,\n",
       "          6.8088e-01, 1.0396e-02, 1.9905e-02, 4.1097e-02],\n",
       "         [5.4946e-03, 1.3024e-02, 1.5387e-03, 1.3543e-02, 1.4943e-02, 9.2688e-01,\n",
       "          4.7612e-03, 8.8954e-03, 5.8081e-03, 5.1148e-03],\n",
       "         [1.0166e-02, 1.7739e-03, 9.0286e-01, 1.4988e-02, 7.3033e-03, 4.0253e-03,\n",
       "          3.8346e-03, 3.6702e-02, 1.6477e-02, 1.8714e-03],\n",
       "         [7.7960e-03, 5.8074e-03, 9.1370e-01, 6.6965e-03, 3.0023e-03, 1.3030e-03,\n",
       "          4.0666e-03, 1.2308e-02, 4.3361e-02, 1.9547e-03],\n",
       "         [1.9538e-02, 1.1212e-02, 1.0726e-02, 8.8086e-01, 8.4681e-03, 2.1871e-02,\n",
       "          6.8463e-03, 9.1635e-03, 2.3316e-02, 7.9987e-03],\n",
       "         [3.1409e-02, 3.2475e-02, 4.5828e-02, 2.2574e-02, 1.5293e-01, 3.4107e-02,\n",
       "          1.9083e-02, 2.0958e-02, 4.8657e-01, 1.5407e-01],\n",
       "         [9.3786e-03, 1.4782e-03, 3.1362e-03, 1.1483e-02, 8.8977e-03, 6.4600e-03,\n",
       "          7.5335e-03, 1.9172e-02, 1.9524e-02, 9.1294e-01],\n",
       "         [7.7341e-01, 8.6083e-03, 1.2642e-01, 8.3865e-03, 1.1664e-02, 3.4489e-03,\n",
       "          2.3767e-02, 3.8500e-03, 1.5865e-02, 2.4590e-02],\n",
       "         [1.4907e-02, 5.9430e-02, 4.6504e-02, 5.2011e-02, 3.0023e-03, 5.4789e-03,\n",
       "          4.7398e-03, 7.7883e-01, 6.6129e-03, 2.8484e-02],\n",
       "         [3.8223e-03, 9.4476e-01, 9.6714e-03, 7.3778e-03, 3.7968e-03, 2.7627e-03,\n",
       "          1.7593e-03, 3.6630e-03, 1.2935e-02, 9.4480e-03],\n",
       "         [3.9811e-02, 7.3352e-03, 3.7960e-02, 8.5468e-02, 7.5901e-02, 3.1184e-03,\n",
       "          2.9403e-02, 7.8333e-03, 7.0266e-01, 1.0507e-02],\n",
       "         [3.8428e-03, 3.0363e-02, 8.9915e-01, 6.5840e-03, 1.5497e-02, 2.6589e-03,\n",
       "          8.7246e-03, 1.7782e-02, 1.2305e-02, 3.0943e-03],\n",
       "         [4.0361e-03, 8.6764e-03, 1.0091e-02, 9.3595e-01, 7.2712e-03, 1.6861e-02,\n",
       "          2.0254e-03, 3.2606e-03, 5.0699e-03, 6.7615e-03],\n",
       "         [5.3143e-03, 9.1609e-02, 2.3716e-02, 2.8263e-02, 5.7988e-01, 1.6433e-02,\n",
       "          1.7741e-02, 2.9780e-02, 4.3464e-02, 1.6380e-01],\n",
       "         [4.3870e-03, 8.6630e-03, 9.7976e-03, 1.3391e-02, 6.4246e-03, 9.2998e-03,\n",
       "          4.4964e-03, 7.9723e-02, 3.1249e-02, 8.3257e-01],\n",
       "         [3.8227e-02, 2.7958e-01, 2.2795e-02, 4.7266e-02, 1.7609e-01, 4.2582e-02,\n",
       "          1.8003e-02, 2.7599e-01, 7.7282e-02, 2.2184e-02],\n",
       "         [3.8879e-04, 7.9866e-04, 1.9259e-04, 1.3539e-03, 1.8167e-03, 9.8684e-01,\n",
       "          2.1297e-03, 3.6483e-03, 1.5021e-03, 1.3320e-03],\n",
       "         [5.2455e-03, 6.2781e-03, 3.7271e-01, 6.1831e-02, 3.6775e-02, 6.3069e-03,\n",
       "          1.9770e-03, 4.6094e-01, 2.2313e-02, 2.5622e-02],\n",
       "         [1.4994e-02, 8.7208e-01, 1.5910e-02, 7.0858e-03, 3.1916e-02, 1.0434e-02,\n",
       "          1.2084e-02, 1.2523e-02, 1.7147e-02, 5.8248e-03]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(cnn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction number: [3 6 7 2 6 8 2 5 8 2]\n",
      "Actual number: [3 6 7 2 6 4 2 5 8 2]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(loaders_1['test']))\n",
    "imgs, lbls = sample\n",
    "actual_number = lbls[:10].numpy()\n",
    "test_output = cnn_1(imgs[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(f'Prediction number: {pred_y}')\n",
    "print(f'Actual number: {actual_number}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrices and Such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 0.99\n",
      "Recall of the model is 0.99\n",
      "Precision of the model is 0.98\n",
      "F1 Score of the model is 0.99\n"
     ]
    }
   ],
   "source": [
    "#Running on test data\n",
    "cnn_1.to(device)\n",
    "# preds,labels = test_predict(model, mnist_testLoader)\n",
    "labels, preds = get_outputs(cnn_1, loaders['test'], device)\n",
    "# Plot confusion matrix\n",
    "\n",
    "cm  = confusion_matrix(labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(6,4),cmap=plt.cm.Blues)\n",
    "plt.xticks(range(10), range(10), fontsize=16)\n",
    "plt.yticks(range(10), range(10), fontsize=16)\n",
    "plt.xlabel('Predicted Label',fontsize=18)\n",
    "plt.ylabel('True Label',fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# binarize this (for now)\n",
    "preds = (np.array(preds) < 5)\n",
    "labels = (np.array(labels) < 5)\n",
    "\n",
    "cm  = confusion_matrix(labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(6,4),cmap=plt.cm.Blues)\n",
    "# plt.xticks(range(10), range(10), fontsize=16)\n",
    "# plt.yticks(range(10), range(10), fontsize=16)\n",
    "plt.xticks(range(2), ['<5', '>=5'], fontsize=16)\n",
    "plt.yticks(range(2), ['<5', '>=5'], fontsize=16)\n",
    "plt.xlabel('Predicted Label',fontsize=18)\n",
    "plt.ylabel('True Label',fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compute Performance Metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy_float = (np.array(preds) == np.array(labels)).sum() / len(preds)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\"Accuracy of the model is {:.2f}\".format(accuracy_float))\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "print(\"F1 Score of the model is {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      ")\n",
      "feat_array.shape, y.shape: (60000, 32) (60000,)\n",
      "number of pca components: 9\n",
      "PCA explained variance: 0.9999998261111528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.664691902687366 > -136.010477300761067). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.687335600234306 > -137.222503916262667). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.022716157736440 > -135.692614996370679). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.323622968978441 > -137.001362198058132). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.120293816648655 > -135.913319785128067). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.879553384135676 > -137.964791219362326). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.835497374904833 > -137.430002711905217). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.059912242946211 > -144.325026611560389). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.517839545041539 > -126.372741915188712). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.330485879208510 > -138.022284934031916). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.351977000762361 > -137.986656475957972). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.549852196295618 > -138.860583397020378). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.706138685623614 > -140.784889920721099). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-136.470194543229496 > -140.826553824382529). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-139.770323147556553 > -141.464147877153863). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.031091611845227 > -141.801618226740459). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.302488003858286 > -141.260553551135331). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.929780522312768 > -139.134753701166858). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.120579204708008 > -140.480279139787541). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.605200665515966 > -140.872950066925569). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.291607442084072 > -138.711816585003277). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.056399971136855 > -140.345995877029338). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.458365955870192 > -140.929335639686798). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.941538407843808 > -140.204997005756212). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.662087505607957 > -140.177682080124953). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.971499386763128 > -140.019232369910441). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.863579338602790 > -141.727138613886893). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.238993425587410 > -139.291488321176189). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.295451919920993 > -140.208232288285330). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.539125661009635 > -139.697696595299732). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.770596154329127 > -138.919488671687418). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.737425325591317 > -139.971272426758446). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.886189032774951 > -139.325189799751143). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.929370023140592 > -138.633523200085477). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.556017659621006 > -136.535923236415897). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.879813616527684 > -125.221951946783420). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.967869031456928 > -138.350034030252090). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.271856510555367 > -138.034483638224657). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.307603135638715 > -135.699983921798804). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.678415243279773 > -125.400237881720429). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.624564782719716 > -135.179343147754025). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.917995107347309 > -136.519198839346870). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.621612110220596 > -139.765902672010299). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.785737408669092 > -140.657054778018988). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.459861344129791 > -140.061064514717799). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.165334172468050 > -140.457889839811230). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.770744882381521 > -140.707913704714258). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.639215134267602 > -140.854321367957368). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.674210260219326 > -139.989446850786749). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.699780679551793 > -140.812891441647565). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.992717104506369 > -139.918760692241477). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.943483057184380 > -138.622882786801540). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.442349939110628 > -139.363871817109640). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.465152098237638 > -140.537547649678373). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.769264929306246 > -139.147598094806625). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.717101832211853 > -139.473020148344858). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.718391858226056 > -123.114534908673519). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.199253523221188 > -139.900348606820188). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.321896697082849 > -140.351252397475918). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.172548759986256 > -140.502500988505773). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.775241998174408 > -137.364477747137613). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.590440733142245 > -125.400278096985218). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.941311570903551 > -138.567401887801537). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.557551537530969 > -123.963041781988863). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.675749207437221 > -137.887524006194639). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.858401482533566 > -137.920302388887904). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.184954386617221 > -137.954288253900643). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.012301953159749 > -136.436061655718760). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.730818869596263 > -137.237900352067243). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.925797701318260 > -137.235201985076429). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.570481164616538 > -136.985547108924209). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.577630739846242 > -145.774840466961450). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-112.900735040950508 > -186.260143221546230). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.796052503608919 > -147.601793251675247). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.270229621016028 > -151.483621026717088). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-121.948510892268658 > -148.911375379480319). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-127.555016621359385 > -153.684449698073308). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.039157687250054 > -147.505199725873467). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.452797946024873 > -149.813680810828032). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.368590784778604 > -146.847053586876171). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-122.184489519815344 > -148.524237870242814). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.003101944143509 > -146.442658119919685). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.060417033847301 > -182.241136549047354). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.060875078861528 > -183.204556507519641). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.484888970242480 > -183.203574265304070). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.603617380853336 > -181.796755852285656). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.541757812815746 > -148.185527078946905). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.944726514727620 > -187.626848505333413). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.877260957983083 > -152.611874744077511). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.944726514727620 > -187.519964160623090). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-127.216066116306536 > -156.495333627981665). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.996768103510419 > -186.948842479673118). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-165.636409025495254 > -194.266819494261597). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.127220507738741 > -188.853019268468131). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-112.391876702310313 > -186.650756370749860). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.647708546259764 > -146.104044333573029). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.887822988524107 > -186.339446316273438). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-112.130904682980571 > -188.373484729808922). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.705193665102414 > -148.282999398266440). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.313565961553465 > -150.063977948306274). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.059588097723150 > -147.837033191820950). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.180462832117144 > -147.152766237625229). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.051617429676199 > -139.108681523836367). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.396409037201693 > -150.718916778521503). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.853118863202809 > -146.326830691109251). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.275892363086911 > -147.268461335311201). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.852780256478439 > -146.464179173071329). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.818728874762016 > -140.639254233475583). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-125.945415538240610 > -150.223176593887615). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.192190973060093 > -150.178479274074277). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.400775603583611 > -183.256448665562317). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.312248332608959 > -148.913091730584426). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-135.847897817465281 > -154.480192719565395). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.337449079506030 > -189.794916585448732). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.888716953565265 > -188.680298081074312). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.143636457000781 > -148.758235342685566). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.569531780238606 > -185.157087585878259). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.925895387628444 > -148.607735009253418). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.190692839059835 > -147.260439336935406). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-123.756798476854954 > -152.154610386394722). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-125.292680308554210 > -152.185922765502283). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-125.953434992918801 > -150.426505366045973). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.944043118455170 > -148.128860413157923). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.234895089799835 > -147.915521279511665). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.180381427773085 > -147.665933098489830). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.151566547377740 > -148.139171824521497). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.936522522436007 > -148.563799345065121). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.673308906340523 > -140.696798722774332). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.699931284357532 > -142.616504884865918). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.186628261796585 > -187.057474520451450). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.318744850477145 > -186.800436010454149). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.317051799092198 > -187.302361504524100). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.510239932481397 > -140.356980672181493). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-153.110577246412134 > -155.511696099253584). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-112.295801304965920 > -141.603792628209590). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.353014486113523 > -146.450777669176773). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.410805092434003 > -147.847954873303934). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-112.728194146114888 > -187.723494240067964). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-134.594319703733504 > -178.814008641423641). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-218.489968712849333 > -222.995677697514054). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-183.444367710219410 > -218.687678164342572). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-215.628649876154981 > -216.804054546674934). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-219.187086357490159 > -219.692472890466689). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-216.285752053189242 > -216.977536836529396). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-184.602758343719586 > -218.019611610476431). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-216.973639509993660 > -218.730092651457255). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-216.493565214605837 > -219.101887464318168). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-217.423280055569023 > -218.668591000913523). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-217.649817854671227 > -217.743811398157419). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-216.213842666934340 > -218.161523274970932). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-176.366165887991741 > -220.377565255638387). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-177.050428071271199 > -219.410519344871147). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-174.954967765886323 > -219.117311574114410). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-174.717161178572951 > -217.877165562727185). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-219.440314603571267 > -220.054779880595078). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.514346058911144 > -187.861083639219174). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.630210898998655 > -217.844668858088681). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-155.745981974373819 > -217.887379898433409). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-187.426344000964519 > -220.849152978644952). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-186.370004147823835 > -220.864709209993379). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-186.439577521564843 > -218.581979772399023). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-187.861284859067410 > -219.239556838911255). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-187.121586414987519 > -219.566129802625227). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.645053228235696 > -186.477717951410739). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-187.002500088084759 > -219.175282803442940). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-185.213046690559906 > -219.395537425580301). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-187.046082770696671 > -188.967537943863903). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-186.509026867526302 > -187.370684080957801). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-189.697401883085405 > -218.085192585708967). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.946101900903173 > -124.180046879724387). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.650443232808897 > -120.318310389777764). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.287235199389116 > -119.962515951924814). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.292476670618669 > -120.092951869414179). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.420243618353894 > -120.303257696772718). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.087118524559315 > -122.569715369531792). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.206763240791929 > -123.358676937752904). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.240664831835801 > -106.263712725261485). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.392850671022259 > -136.589296092489064). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.454143730335687 > -138.231116224413597). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.493605782983437 > -137.233357109700421). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.465308837278457 > -138.231477360856843). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.415126864733992 > -137.547882865244560). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.920272638139224 > -137.525053110206812). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.581474271241461 > -137.653963586947697). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.390276966675600 > -137.124483785882319). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.374149535937988 > -138.111748522547487). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.625663220668713 > -135.351495483580862). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.479472986297964 > -136.864717562558951). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-132.765184775340003 > -133.415662683919237). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.312427529775988 > -134.152344837196239). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.061821411201151 > -135.655231446939155). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-130.348442247206663 > -135.618067521487319). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-132.327834876139434 > -134.615974452727556). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-131.450359557552474 > -134.537586360520720). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.743511447093596 > -122.630396746388925). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.263835963088809 > -123.254163816835927). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.908884143031116 > -121.912723422399594). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.155233037136256 > -122.947122426955517). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.482789267267492 > -134.632323288102555). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.338504525297253 > -135.152023521362480). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.710725220527621 > -135.525056452546465). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.943766378291812 > -132.620441605332644). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.660531115746295 > -135.481227859910518). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.491668324840390 > -134.641557569075530). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.574729553996818 > -134.604447165336609). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.770535360459036 > -134.883888784463750). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.875976513536344 > -133.095306914461929). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.520003955715950 > -136.067960628742753). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.521697736144944 > -136.416278992843047). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-132.910234226221064 > -136.425131412503362). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.065465158815101 > -139.266366645392736). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.693818741142280 > -136.915761118774583). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-132.699315238858787 > -136.845605054950852). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-131.459041461626839 > -137.402057745755002). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-131.652999057885154 > -138.370366511379984). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-130.287954427910734 > -137.740339037416589). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-132.066031016399421 > -138.032752288573562). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.355653320190299 > -125.084915844163561). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.166266066007012 > -157.397211094443037). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.549110232810676 > -125.152062079990486). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.644920034406624 > -155.933934937573355). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.816713703967835 > -125.292136820655770). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.236803472690838 > -125.000945502388220). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.120844623799073 > -125.468761094475454). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.538613508847078 > -125.095101879549219). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.034617994667812 > -158.195485457692115). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.543204217564181 > -126.728835020907027). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.088887902832511 > -126.423903580758079). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.040664988416523 > -126.817521366340429). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.816418812124098 > -160.678330081915874). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.903387980952999 > -126.107709645679051). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.788372649127524 > -126.019608186184186). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.588656316464522 > -126.852539603308543). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.662054553423900 > -125.468513149391924). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.796946340303947 > -125.634767356849622). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.615859156220026 > -125.226056811779742). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.126260892827133 > -125.530101337181634). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.005668398743040 > -125.439028026009055). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.764630736792981 > -125.284411031464089). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.614555983452220 > -125.213390377969915). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.320678817823179 > -126.051160487818962). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.060960034103729 > -125.475052889518807). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.039540007886217 > -160.289504189171254). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.166732292280045 > -156.900275872605931). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.166654502408278 > -159.385937873005616). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.753582970691554 > -156.261533140573135). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.167092105144150 > -159.221828582165870). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.488884337033255 > -160.533557578668905). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.896180543567226 > -159.953597404455479). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.196778258289072 > -159.543326457825401). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.403694098288639 > -125.695420637818756). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.227953675421290 > -126.348216821988728). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.275071587146840 > -125.029631516189227). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.107118619696593 > -125.466668521666065). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.502623925404293 > -125.134615102395713). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.452705041279970 > -125.762144330571431). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.359439429410358 > -125.643977960469897). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.628604804295861 > -125.246701061719250). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.341714238012386 > -125.705349293091103). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.784201818418822 > -126.027192042260324). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.783008133647499 > -161.299045582509819). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.927511452654699 > -159.960736046109929). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.766091072456163 > -126.009188079114949). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.490786978254675 > -124.629151328305255). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.509387385590728 > -125.765532989505928). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.520049624461848 > -125.149346383967782). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.637112466872992 > -120.584666525963499). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.687080919723570 > -120.702510174512497). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.197393950254565 > -160.098541683038746). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.753301237004862 > -155.461578961040118). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.977511565145207 > -153.603280127255033). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.753190276937914 > -157.394360134303696). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.495544137848043 > -124.643349291136957). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.136493117733295 > -124.307785253369445). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.439627522018867 > -159.744257495956134). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.857381673542307 > -154.935681389572835). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.644439839821416 > -155.625507669940419). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.605674758053610 > -124.686083324950857). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.149548310140787 > -158.761032443038829). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.205706031110495 > -158.791212283560327). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.928040038699791 > -124.919272496629816). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.798382403636509 > -124.792075414193846). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.505384148505073 > -160.626795506517993). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.344991709080915 > -121.712303961236529). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.605232178104814 > -124.706955752772132). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.644306242819482 > -157.183608997838064). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.753302407823327 > -155.250844496287897). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.983399904329190 > -125.439085204547979). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.637160019907924 > -125.280168750610841). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.000615606742002 > -125.399483949018290). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.852677432843251 > -155.095552554995294). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.634081476849047 > -126.792169309243519). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.981201591058380 > -125.435632407713626). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.114296855782271 > -155.945263911561540). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.913386912881862 > -155.126166398811620). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.251630486222240 > -126.365099867379584). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.816203078600267 > -154.502207852577556). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.975008603976946 > -126.106500963969268). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.553519285038504 > -126.149170479599860). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.207736884210448 > -132.556854936137711). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.996654234537331 > -126.165538310419180). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.302576725461563 > -126.551628596214812). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.654366377182953 > -153.438778530406040). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-91.289898738166997 > -157.830286264097310). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-91.203020091698491 > -157.766447378440517). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-90.816300497235289 > -160.250106546950292). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-91.154905251003129 > -157.277626682533992). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-91.540493477468090 > -157.661050409334223). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.984482948929312 > -124.903859762619661). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.644543918278316 > -155.653363163903236). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.644727975600318 > -155.601762404265656). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.897347255233797 > -124.875617511405636). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.860065687504374 > -124.829611827366307). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.969157162291552 > -124.929319812297308). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.753039963591789 > -126.364085369869329). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.475377790713225 > -124.596488419302062). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.753063311059833 > -126.301188331896924). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.605259053600349 > -124.694728427427975). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.150407835075271 > -158.483752289463553). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.233339231693236 > -126.555738706057980). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.480437883628269 > -124.641597301503239). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.686637666024382 > -126.256822818080479). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.752557945474067 > -162.153378165149462). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.917095823563045 > -160.708690122003588). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.699994078937323 > -161.441426989109459). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.038121859763976 > -159.662727705504977). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.540190762819819 > -161.118256195630721). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.547544907949060 > -163.327483696567441). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.544932346916994 > -162.758675338813418). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-91.410529012989102 > -162.765367215350807). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.944267796209232 > -166.429100681997625). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.377817589271274 > -142.326863380638230). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.005108355356285 > -164.833495027633148). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.829115870508801 > -161.185844966637291). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.040686633804313 > -155.506253989827144). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.204389057007518 > -150.934777305681621). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.253851917424527 > -147.584543699769284). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.013890789231993 > -155.190246318919549). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.291644971766416 > -149.326475268259117). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.693752250058765 > -153.959105533951117). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.288218499619376 > -150.381505541862879). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.648747784770435 > -125.042778183059255). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.900222325985482 > -184.220288223968225). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-136.974032272744495 > -183.447685707091637). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.123871858042875 > -150.304135720193841). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-149.789004783301209 > -150.355373987658595). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-148.872771530417424 > -149.222995743418551). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.116172146803592 > -146.433953359046086). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.314845195956281 > -148.146408749566604). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.343901002393480 > -148.820463336960330). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.076729263649241 > -129.262296675844368). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.384633400744519 > -148.937794307039127). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.763855379005619 > -147.629288237885589). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.819445376954377 > -148.218671648147506). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.810616443938386 > -148.820110345266073). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.338278580960107 > -134.885011515255030). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.895423251919780 > -129.483506856582352). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.834555159618589 > -129.326861409254604). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.441634621658380 > -147.569053085491902). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.749509950873474 > -128.925834217135332). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.882076863492799 > -126.623430233676459). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.331003737152074 > -125.294279200516996). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.381109580933099 > -128.302711456909492). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.031942413833121 > -146.157243990688528). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.033900179455713 > -184.559251713616277). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.868208683154165 > -186.191390006226982). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.842851442663218 > -186.184703376453569). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.900263377356850 > -185.907212772464732). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.875018469476089 > -185.778337951589577). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.909976399693889 > -185.240640839180401). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.845730591387053 > -182.265896311959438). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.296101622760844 > -126.435842273288330). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.033489165636070 > -145.643152333459994). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.105273279610628 > -144.897988366427938). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.243215578068032 > -127.240879940209254). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.880295025717970 > -185.674034703865260). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.774068562448178 > -184.556549716688011). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.539603337894150 > -147.516630404905442). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.957393219922125 > -142.920380381922882). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.965335604479023 > -143.063957752541484). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.228042192542091 > -145.614597342916966). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.277927313082188 > -146.539201533100538). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.269443797930265 > -145.638719994422473). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.276936779941991 > -147.550823532868151). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.275457606330932 > -144.823589837948163). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.275457606330932 > -146.478113603734272). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.256789197436234 > -146.801338742467237). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.366287123213283 > -147.643672817634894). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.525665220507733 > -148.341459221061768). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.246609114688425 > -146.494793175188420). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.698337350132647 > -148.167008141804075). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.112513053738155 > -183.017595972792492). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.369558372315126 > -184.912851197735847). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.511104628869916 > -187.298111734376505). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.138263531560284 > -184.329945539525966). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.609995971455334 > -149.622364346056713). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.348400415619892 > -147.628586426778895). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.981319543492134 > -147.505108219153556). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.269972148808918 > -128.608142690319767). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.276667502786935 > -130.830097729895243). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.329282525559520 > -146.524568427822430). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.978534648179163 > -148.538811007763968). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.956356735373447 > -147.553972014019394). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.934736075473495 > -147.411304457143757). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.660621000689432 > -184.101954344062079). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.686580623484289 > -183.158055710987128). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.130935483221961 > -127.594863460190254). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.388752919313376 > -128.192002251678389). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.522705159542099 > -127.203851658580135). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.579929960566147 > -126.557407516294560). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.044211205562931 > -125.706987893412716). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.164175151877259 > -185.382049981166574). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.155631444915301 > -187.607571651387161). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.986802743017790 > -148.029801699885013). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.268056878873296 > -148.668503391072761). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.876461120268402 > -130.083147439659371). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.778150945904258 > -146.927873354277438). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.956348856011743 > -147.950010836593265). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.940424502918631 > -145.464856194884561). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.448161143948596 > -144.864031348678424). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.329444849078314 > -147.613351847313936). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.644088194291115 > -219.090162796995287). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.327485667516811 > -145.469217400066100). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.234897543337084 > -144.661974144626583). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.698847489382047 > -183.666195495209053). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.707636226240567 > -183.187103080512145). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-156.779574051172830 > -162.647302053672206). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.234892634012624 > -145.213898829978632). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.246097020353943 > -144.303649927662661). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.678984687272163 > -220.924046213239819). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.252873199005478 > -136.169723618173549). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.248786844757461 > -136.190707572893075). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.247273458628868 > -136.191923927262224). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.715825722762048 > -181.214616678385283). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.711545891214172 > -147.593457582594681). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-156.525795217469607 > -160.923755793279241). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.670468021240993 > -138.162843554521800). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.266112290431096 > -136.506585594732343). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.278284984236294 > -141.568807230032718). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.254819313631401 > -136.429559113474738). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.652420481491419 > -218.664004586834977). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.644744696159506 > -218.798976321539385). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.679765707385513 > -223.420688210601782). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.657809120050047 > -221.312108294812873). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.264715432108062 > -133.547722946845170). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.856465894525314 > -137.811872213947140). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.700215167244551 > -139.663202800068291). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.246289106678006 > -136.167595621339501). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.238241391814341 > -144.537867306273711). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.238386478259343 > -136.164933351230900). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.673113999264331 > -220.272904344924626). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-151.662920145645160 > -152.749193025686679). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.253094092506615 > -136.203559588353016). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.255990421503853 > -136.217781312537625). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.641803675028143 > -219.677736814726387). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.642305073568309 > -219.905655288865717). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.676470480889577 > -220.975445064399878). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.538679857140181 > -181.088992764750287). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.634957498717810 > -219.924658215042683). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.244659386787973 > -136.176539654174178). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.649676712686926 > -221.987187554251250). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.762248118186506 > -144.733748228904716). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.581328535667069 > -182.999116100280816). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.580377254819666 > -182.291603553378934). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.639032239991039 > -218.290348780978093). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.640713908482809 > -220.594855471331016). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.639032239991039 > -222.266147477860443). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.643106425720120 > -219.901627879336246). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.859357453148519 > -180.969064842010823). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.644375680241836 > -218.648365474607942). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.963843168197101 > -191.428458931916879). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.641148036604733 > -219.491794671139331). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.641513926984416 > -220.879675194123706). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.243414259635870 > -136.174933540960183). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.275158618154734 > -136.248573190653929). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.242705668952738 > -136.178870898970303). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.258894929190291 > -136.226564969782430). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-152.217846459615458 > -154.523466514326714). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.686016214045196 > -222.303841300038869). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.268632410072954 > -144.240724805653372). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-151.840531787855667 > -155.316035314438579). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.680045031515036 > -220.239429940744913). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.685131103896083 > -222.999017115250723). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-127.223460357748934 > -160.090623674578438). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.331818290704859 > -182.990758231270064). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.712581833042009 > -143.826044970157056). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.583020176326897 > -221.013836491305199). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-147.582044165344115 > -179.300613554153415). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-179.691893966214366 > -182.738775438530922). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-181.804988562072083 > -183.257836737763228). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-148.375167358052238 > -177.707841080524815). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.213531862392927 > -168.359139635359440). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.870015781235679 > -178.616224082643782). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-134.351220909695144 > -167.932720098479621). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.260676597054157 > -177.382642743510132). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.204059084385619 > -177.774693369351326). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-136.324564061553218 > -176.469870468695092). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.238482448786925 > -177.640502293850460). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.914299391555573 > -178.963579255424094). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.527865270171901 > -178.688924620243284). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.568251428955449 > -168.929647531810815). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-170.521006847639882 > -179.159232400571256). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.859784767146749 > -179.306052263847931). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.871717710733407 > -176.560849612266992). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-150.374789242074570 > -178.668884382774479). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-147.185520679038120 > -177.322026123144212). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-148.389283492190827 > -181.518369443394789). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.576324055250268 > -173.451992063457197). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-140.856344508360962 > -177.780054813588208). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-175.180025760658282 > -182.700790285878128). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.004585719140948 > -171.736382216597065). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-179.054470238500727 > -183.979038939893996). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.568431834547425 > -179.948663959751343). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.441266840342109 > -214.220498013560700). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.582626574391867 > -181.084460183072679). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.730508095417903 > -180.214269438486099). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-134.778855185124911 > -138.211444733433382). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.061188571230076 > -138.654430400153331). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.212152508675743 > -125.214943946710164). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-92.973436318222070 > -173.693651341853098). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.361198785054455 > -137.675131169457700). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.491367548390883 > -136.807545820104451). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.989497702780113 > -135.393348375141187). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.945746070673209 > -134.593000276435077). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.066247409133467 > -124.260827260242337). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.990499566078711 > -136.134847778386472). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.080330906995002 > -125.425132998087605). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-96.510834923148437 > -126.258366741868002). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-92.043481463314833 > -155.316451201365396). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-91.771810493456030 > -155.290238663388294). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-92.101564940497354 > -154.225261325262892). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.937078409685284 > -119.947714615240272). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-91.875014358981687 > -154.206833575100291). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-92.028542370899942 > -155.108247460999678). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.186853325431230 > -173.672616402453116). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.865813188181008 > -137.088539239497777). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.173576845873242 > -123.821884442223308). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-133.150310968744662 > -145.576634634448283). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.037057091812130 > -124.926509664084051). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.183593506298536 > -123.010427501708136). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.180865538201019 > -124.226254961290152). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.214867338982359 > -125.556650200585310). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.098527073416648 > -125.875057029492595). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.774484805315595 > -139.103773653732674). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.266176508947709 > -139.054237904442118). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.997646384321186 > -127.688499670806749). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.134557082598647 > -137.349413305974423). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.032994416064867 > -137.840319401940349). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.208493527005004 > -139.042980686878707). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.280501618957246 > -139.038381270359139). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.671660392229981 > -137.805254771169814). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.960800123478961 > -126.143923752463394). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.861622700402023 > -126.123003558542536). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.095003080440080 > -137.828256979664729). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.472474846798633 > -138.625659533809880). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.246167120765023 > -135.340714654158035). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-113.407643350231183 > -136.335132109393584). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.587924561496678 > -135.930677274182131). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.696512449044974 > -135.375215451212625). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.415590718747424 > -135.345614047596030). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.318515265946104 > -135.690743724592863). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.218328429103252 > -127.643318778868320). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.001846309050151 > -136.335978811643116). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.127349844821751 > -136.696966409918616). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.118453143710980 > -138.011305307543864). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.329864921207431 > -137.310926802953759). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.017810869081913 > -136.986482005304453). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.628121736658599 > -139.451493920699932). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.404710661927325 > -145.337841861411079). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.640354724503212 > -177.050387770681823). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.780021518415154 > -144.863756519458775). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.273732808761821 > -176.194487863183070). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.419951789320962 > -175.589080705337892). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.763872293841303 > -134.808819063344515). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.744958314750605 > -176.576331253379948). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.741350788059250 > -176.042430451008727). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.100155678162935 > -175.425081474879363). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.716222612262342 > -174.695097056057136). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.521039656054029 > -175.967832865457439). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.599231695029047 > -146.115521959831312). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.596588834171200 > -145.836450743853618). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.105403277819207 > -176.670153313645244). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.320219912725022 > -134.416396002863365). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.356174112137666 > -133.207053904110580). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.314223190152262 > -134.031283648115789). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.810896466207822 > -180.614810536964228). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.242472941707874 > -139.545705363677030). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.638896361787658 > -145.520166020456088). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.249992152474022 > -140.153868528012538). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.417449018547501 > -140.000114312754590). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.979053137694251 > -140.155594493609840). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.732010632148146 > -175.412489656958940). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.070459146094407 > -144.415860308413585). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.484938718740480 > -176.373568529846921). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.044182529800764 > -144.631656115090294). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.705328221630964 > -177.151282847284790). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.743094761442563 > -176.786092926688184). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.335435549638106 > -141.984547345481502). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.550481621701749 > -181.163737407153548). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.660428530737846 > -177.114035063168785). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.802829401893362 > -145.626988154431501). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.765257593344217 > -176.270795552206096). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.191924589647499 > -174.429741388966960). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.307079629237734 > -176.259405094776866). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.436094646379431 > -175.795140306642253). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.107347111162625 > -174.547490703083838). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.351109668390137 > -175.572588799741538). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.067314788967607 > -174.885533676817261). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.765966419652983 > -176.521380073653233). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.777458040442241 > -144.857893728606030). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.446480655642802 > -176.351178261337424). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.345918911419730 > -144.774250314935102). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.824705133260068 > -174.782899778437468). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.877529586480904 > -139.771585515038396). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.808713390170453 > -176.537837413309916). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.320222126258173 > -176.946515660002717). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.717714266681725 > -144.426075882796283). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.345918911419730 > -144.803831229523496). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.316749096761768 > -138.639472445042031). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.718125479618251 > -145.523120442299273). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.588250871625718 > -143.000736504532597). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.546022312162222 > -175.736788869547865). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.230865495033498 > -175.735988611633246). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.639591255325584 > -144.243083994928384). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.537523616192587 > -175.968195645218600). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.670337845782683 > -176.454478387382892). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.397250567082494 > -176.323101616546353). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.323719291129350 > -176.256045550356362). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.740677516203959 > -177.874916058951953). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.192354255913273 > -138.628467117313505). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.341383264013970 > -128.492474218601728). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.583093732132795 > -127.643878126927859). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.046852695976213 > -137.698329941502550). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.045111962498297 > -127.951258532168822). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.807640919202072 > -127.766009867021040). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.663912414286827 > -127.590703550281575). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.675327835906387 > -128.821400478892826). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.786096216575885 > -179.743755002072675). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.891262585345288 > -181.279300408706717). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.820182761694724 > -180.839160491725124). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.822815754483997 > -181.156013828225213). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.292076637545676 > -179.895258448600202). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.169061209931925 > -180.844080949250724). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-139.609808962696889 > -142.236789582617746). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.635161550192606 > -180.397122631047637). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.007547777181287 > -179.678760625535233). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.614259995239181 > -180.283299838340042). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.907456472383103 > -143.086032599635047). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.893873676417186 > -178.418559519443846). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.316380560609815 > -145.163111538913824). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.692181214188452 > -180.888580006651040). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.264129623121306 > -178.715279125323065). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.683632086894463 > -126.170583263440250). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.189584226839671 > -125.895918376319045). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.781496300534613 > -126.981924958500045). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.836239349058388 > -125.584993299671709). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.936782988924548 > -141.378479929071062). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.962238185529188 > -144.627264827982430). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.951603696371748 > -131.863332973857410). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.713347717096099 > -143.332123859720014). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.939987345617752 > -141.698792519023698). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.964009288725521 > -144.491489418181033). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.514160456170188 > -131.056374395272769). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.342345180471938 > -180.934515138862196). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.912627538554688 > -179.882734241457570). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.160384891287421 > -181.277773993430202). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.167481016969234 > -180.909199906238825). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.453869489453666 > -180.654023099661742). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.705897459030467 > -178.822417005981123). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.635467056633530 > -179.851413189069604). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-139.611896336344955 > -180.010301823392155). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.075257559616773 > -178.548576446069063). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.718156811423242 > -178.999111257718056). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.298366165095047 > -179.332933967140406). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-174.144471443097103 > -183.085902489562130). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.809515865191941 > -180.117649785228593). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.816745834528206 > -179.640301962111124). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.307654878710053 > -171.681967157563179). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.190667483396041 > -217.558500806485938). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.189500990721641 > -216.579431585247391). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.210454244707620 > -217.677623712653229). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.210113631703308 > -216.292045754925539). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.285624598726628 > -190.555797909943209). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.226251215838886 > -216.987307191843968). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.188785221079911 > -184.121421249121596). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.966003981704631 > -181.508583282619782). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.192198601306671 > -217.677402735029204). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.291695840826520 > -190.567800765607359). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.786041119196682 > -140.363839056806512). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.974611993422229 > -216.863922496504387). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.974216018474536 > -217.677978252175279). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.977149245849375 > -216.575299654230747). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.281955334153878 > -186.619883346185077). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.587600595071606 > -142.744986148422356). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.588899170343097 > -142.604875849884792). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.322945848630908 > -186.206920020525217). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-121.726324446812754 > -144.370660379597638). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.160186709617676 > -216.294555313073829). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.094737315070589 > -182.857263913196618). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.758902266321428 > -183.191434855100880). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.763094305428268 > -182.521798226758477). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.978055127736297 > -215.187223833152359). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.286451585828786 > -193.637408861814492). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.977697963977278 > -216.980397140522086). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.978211044665443 > -219.751274708225594). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.013052142695173 > -216.291177597648300). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.319023397019365 > -184.409254562936297). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.007409364385524 > -216.288111180367991). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.975598928360029 > -216.979926460564229). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.978534033584268 > -217.266400616426949). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.193752778843304 > -217.269915153482430). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.191427964206810 > -215.482867398444228). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.281370459489381 > -189.812024746346424). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.975807710475891 > -218.656905942387169). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.285713306239160 > -191.570678074955197). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.151558894965632 > -216.577006114085208). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.150436906254555 > -217.558760559026837). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.854198618313049 > -139.319565959946459). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.099538578589190 > -182.257454376162855). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.626402335175896 > -183.760350873101572). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.286849131154810 > -189.858331864792575). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.787904610671987 > -144.822501414747876). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.786105441266670 > -143.265260614844237). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.976272381013189 > -217.962695223905371). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.976355553716189 > -217.558026454883390). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.289346473805551 > -187.336463296809541). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.284188165894022 > -187.712890497998785). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-129.290812001291300 > -191.570175210104964). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.153032466169265 > -215.883674667562076). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.153338560358179 > -216.576479460621755). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.772765429861821 > -128.038084349764631). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.760974753085350 > -128.037161927637982). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.981681170191038 > -185.275245747376744). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.768671178957504 > -128.033004013495599). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-149.835631476876870 > -181.883952768736208). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.581417851154356 > -180.000934449240845). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.284598596132412 > -180.376007103464332). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.237690223521867 > -180.478650343587475). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-151.298432678111567 > -181.440099002108411). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-146.274945661780293 > -170.745193781510295). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.625074118896123 > -170.451953881695033). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.054322652716621 > -180.604712711329114). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-147.152806288500500 > -181.221081953319356). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-147.218160235206142 > -180.534705830601780). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-147.152806288500500 > -180.822265704688277). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.174150279685733 > -181.881529179660248). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.980305929133124 > -179.489606973893160). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-140.377989811195022 > -178.915338828770786). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.651946896268157 > -180.877511623454922). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.565480244324533 > -166.013034301059321). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-139.282325131531167 > -180.662615738462279). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-140.602928561053062 > -180.644580779389344). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.674297363815640 > -167.846726178308302). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.021428572483927 > -166.678791465290288). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.871048179569783 > -182.472900712362673). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-147.616926470290309 > -181.442977302684170). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-136.520545731601942 > -180.713606413074501). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.951507292790097 > -180.573086671999278). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.544872651248795 > -181.493226015265009). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.456021253314589 > -179.918079779112190). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.033120709077082 > -181.102773002439790). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.919477992823602 > -180.367172754371524). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.246816234550607 > -181.582944643025883). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.854256644738570 > -182.729851194945411). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.797198455104336 > -180.078912955010139). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.721445074214230 > -179.890611575361504). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-136.530032570345526 > -189.512457893441763). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.753005314368366 > -187.683405056171722). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.477384242746012 > -182.798762665385340). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.865894409094153 > -179.510457342317778). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.334377213344837 > -180.312952234817942). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.219883987686046 > -179.200389149347359). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.022184270159059 > -183.913924700371808). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.094098391610117 > -183.211778218161101). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.518800901458704 > -188.227707376446205). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.300182642551036 > -219.481151741750921). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.318663530301620 > -187.176391166904438). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-135.982158864303869 > -192.056142065553928). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.320397661302039 > -219.760370296830700). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-136.115653058855429 > -191.348259567294519). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-136.806365234419786 > -189.227420715422681). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.333497571282933 > -182.083058966789395). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.346276382541760 > -217.218006369227652). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.432062762359635 > -179.874090720200030). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.181586077694988 > -190.456294297659156). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.525267157928553 > -181.957473812024034). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.713192861022264 > -187.820585835870389). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.663030394584950 > -193.645259118503361). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-137.084358786097027 > -193.644946258358345). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.613948661727207 > -182.558752835914049). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.807157570375892 > -158.319971893050280). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.154633336910521 > -134.916880482711008). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.618788522680731 > -125.295726201426930). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-139.429588224015617 > -140.792173938347304). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.289427373432133 > -124.578220165687938). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.239045304484293 > -125.111991931419610). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.270744726558860 > -138.198803542650865). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.837285252837631 > -139.857834498211815). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.171587584894993 > -123.274153745332626). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.275912718151119 > -127.128707607258193). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.285151895857595 > -138.881596855470121). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.554458462132118 > -123.963536737009576). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.569463415149201 > -139.229193026853920). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.334385333802373 > -144.304654203921018). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.662792209331286 > -124.359436077264476). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-101.684385797916377 > -123.351962545159353). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.018482953561588 > -138.710238179377427). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.126522425708657 > -142.730528368895108). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.213142230319875 > -142.653848517133952). You may want to try with a higher value of support_fraction (current value: 0.503).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.463257018645436 > -187.091599645321594). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-148.817568391355849 > -153.324902656956453). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.606756968422104 > -141.067153172178905). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.506458828832820 > -185.219904982390148). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.480365155774408 > -186.498700134513541). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.449302411345030 > -185.909041797784170). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.261337261321330 > -150.152722908445185). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.344019285616426 > -138.066904201614989). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.444959809457288 > -147.295262068031548). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.452759128391492 > -187.518749346831754). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.627954762034605 > -137.131385384330912). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.443521955032139 > -186.809208697497752). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-142.345773684254397 > -145.872507953651393). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-138.869131505741791 > -142.057296503814683). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.546978704608463 > -140.172643500052402). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.584050846665662 > -142.433346229866487). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.440192507266914 > -137.891112981702719). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.367869122179940 > -137.904532987119410). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.526991477306396 > -140.708794120186383). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.116007646347668 > -148.191248446433463). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.437899446382033 > -186.394843685479088). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-131.425225000268824 > -190.023133087906444). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.883097007294708 > -138.482408464846685). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.017498960497861 > -137.126885631796625). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.241921522475522 > -139.222201840672057). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.385166053467131 > -137.439384785859403). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.681431394141725 > -137.665100830082281). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.174577193860614 > -141.405667226774653). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.047311337210687 > -140.092999352123826). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-105.103237835863482 > -135.451837375526907). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.402921500182984 > -139.415585429833584). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.497836430579696 > -184.803656584612668). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.872018563458639 > -137.740062188303170). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.090083724923772 > -140.128259758568390). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.974589402138193 > -138.244368055042344). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.456590979970670 > -186.422688625522255). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.557989850580668 > -143.169720203046893). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-140.164204344335531 > -151.236187502998035). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-114.993238101162760 > -147.257609316026389). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-149.592218711472697 > -151.250066566781697). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.687936590306663 > -137.892351858341783). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-152.046960254058433 > -158.762756272387776). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.626930042591212 > -175.046467098157194). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-102.624166384434830 > -176.427665615449627). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.831574514769144 > -143.107102099371332). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-109.029002409230372 > -138.858720371726747). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.397401068211764 > -143.313702843770074). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.081748454034084 > -138.716883017143601). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.464682252618758 > -138.931600046467594). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.442360712731627 > -141.916056333837787). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.571814474916664 > -138.733954490851943). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-107.447279457751762 > -137.126167734075807). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.748802067055536 > -124.507523771893190). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.538746651663331 > -123.736085391884387). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-97.765635272182010 > -124.123729288709839). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-98.489641153527288 > -124.649520816979035). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.035610057532637 > -122.621434861026984). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.980885763846757 > -123.679347081450814). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.365046328408496 > -137.218824842631960). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.920794089156658 > -124.122537082570929). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.099016875758366 > -122.114101330992384). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.332327968228554 > -135.257326955674330). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.193802879293187 > -136.540376698211162). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-100.316327436660075 > -135.608656584877139). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-94.850946102716449 > -125.889314328210318). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.568605248880061 > -137.024907392436603). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-99.560640193525899 > -136.079173118209241). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.048204774496668 > -124.917830062979263). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.305775369670798 > -124.081823487206137). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.346965213187985 > -124.244621280639933). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.233669416077262 > -125.048248549578247). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.761711933506760 > -125.486254881952959). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.052078625927109 > -127.605994418173893). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.151353907917624 > -123.103711122332143). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.506069865250950 > -124.078465253876686). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.468594826205504 > -124.804500908873891). You may want to try with a higher value of support_fraction (current value: 0.502).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.222912422824777 > -182.266781116277400). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.733359759016196 > -155.383191546144275). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.426738575924205 > -143.991806495353728). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.447212773886989 > -150.678363034342880). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.950216097697961 > -180.222856806593882). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.447351563436769 > -156.012575990159434). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.568626720896361 > -157.382940619532292). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.923091176462961 > -151.774073672349232). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.705613470753889 > -140.703907809884072). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.498013765255337 > -143.148689846215746). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.194486618751924 > -144.818348426565478). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.044270143205992 > -150.463331711419301). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.524132747974534 > -149.497686137116915). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.951862487131777 > -180.383694845277319). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-103.679120623414462 > -181.722323754470438). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.271476930158613 > -149.367274781003971). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.025368263726449 > -144.290218803853406). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-149.430978098882747 > -158.407467790484930). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.275507286128075 > -143.476805230751978). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.294896185842234 > -141.416787858770419). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.922348451105648 > -150.178431756445178). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.369999726441236 > -143.564565280135469). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.594627134537177 > -142.752648542099820). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.769921620864750 > -153.435207812926393). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.514529883348075 > -153.712634525403018). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.388165379808669 > -142.381164396983422). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-112.131174277224304 > -142.749215834811281). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.006707344578913 > -138.441494426690156). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.851363950010509 > -142.946992890589570). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-108.536775051306009 > -184.962884727657439). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.183634494614878 > -150.456199164316388). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.970890274728106 > -150.720348353344548). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-112.165534284625679 > -144.583497226530966). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.306548347155683 > -150.124585519665203). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.097726760825509 > -154.300035349500490). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.453600069461714 > -143.668052156118733). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.468247648034705 > -143.408686757535435). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-140.868536004031853 > -155.289080682556602). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-141.858606561844795 > -156.275138713071215). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-106.322965035271778 > -182.465658458978766). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.887395196734573 > -151.097606440050384). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.956381088908032 > -150.161006281236723). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.670531243876042 > -155.949545422360529). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.389287577541481 > -144.324198525041339). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.965682450802078 > -151.054630073455513). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.881346505591893 > -152.154691468628812). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.514520626570985 > -144.697083737209539). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.819681167796219 > -143.708022147174745). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.909727046256151 > -145.412224279655476). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.130559276295401 > -150.459672208932147). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.515989806853739 > -144.699467131385575). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.394850600527690 > -145.179284393125101). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.618125740707740 > -144.088985452006114). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.465084715667970 > -150.298205429783025). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.768695142872730 > -150.974326647208159). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.336038353398365 > -149.950928088197998). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.499812912912930 > -142.468963872133315). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-143.982662294174958 > -157.627918343842168). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-145.115078563169561 > -157.515623632241073). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.499143401925309 > -144.118627900600330). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-110.426636398307039 > -142.932872650701654). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-144.837459581312572 > -152.434205054167734). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.925992812784727 > -143.949782463184107). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.398162559275946 > -142.724452321434626). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.968604349111629 > -152.392934160084138). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-104.357812519845211 > -178.797310847277600). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\covariance\\_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-111.232712541896021 > -140.960253705352216). You may want to try with a higher value of support_fraction (current value: 0.501).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:37: RuntimeWarning: invalid value encountered in sqrt\n",
      "  sqrt_det = np.sqrt(np.linalg.det(cov_matrix))\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n",
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\4054457778.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  prob_x_f = ( 1 / ( (2*np.pi)**(n/2) * sqrt_det ) ) * np.exp(-0.5*mahalanobis_squared_dist)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "0                 NaN             NaN             NaN             NaN   \n",
       "1                 NaN             NaN             NaN             NaN   \n",
       "2                 NaN             NaN             NaN             NaN   \n",
       "3                 NaN             NaN             NaN             NaN   \n",
       "4                 NaN             NaN             NaN             NaN   \n",
       "...               ...             ...             ...             ...   \n",
       "59995             NaN             NaN             NaN             NaN   \n",
       "59996             NaN             NaN             NaN             NaN   \n",
       "59997             NaN             NaN             NaN             NaN   \n",
       "59998             NaN             NaN             NaN             NaN   \n",
       "59999             NaN             NaN             NaN             NaN   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "0                 NaN             NaN             NaN             NaN   \n",
       "1                 NaN             NaN             NaN             NaN   \n",
       "2                 NaN             NaN             NaN             NaN   \n",
       "3                 NaN             NaN             NaN             NaN   \n",
       "4                 NaN             NaN             NaN             NaN   \n",
       "...               ...             ...             ...             ...   \n",
       "59995             NaN             NaN             NaN             NaN   \n",
       "59996             NaN             NaN             NaN             NaN   \n",
       "59997             NaN             NaN             NaN             NaN   \n",
       "59998             NaN             NaN             NaN             NaN   \n",
       "59999             NaN             NaN             NaN             NaN   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \n",
       "0                 NaN             NaN                 5.0        5.0  \n",
       "1                 NaN             NaN                 0.0        0.0  \n",
       "2                 NaN             NaN                 4.0        4.0  \n",
       "3                 NaN             NaN                 1.0        1.0  \n",
       "4                 NaN             NaN                 9.0        9.0  \n",
       "...               ...             ...                 ...        ...  \n",
       "59995             NaN             NaN                 8.0        8.0  \n",
       "59996             NaN             NaN                 3.0        3.0  \n",
       "59997             NaN             NaN                 5.0        5.0  \n",
       "59998             NaN             NaN                 6.0        6.0  \n",
       "59999             NaN             NaN                 8.0        8.0  \n",
       "\n",
       "[60000 rows x 12 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aled = ALED()\n",
    "prob_df = aled.fit_predict(model=cnn_1, dataset=mislabeled_train_data, device=device, batch_size=1000, max_pca_variance=0.999999, max_pca_components=32)\n",
    "# aled.prediction_stats.to_excel(\"drive/MyDrive/'Colab Notebooks'/MNIST/aled_prediction_stats.xlsx\")\n",
    "aled.prediction_stats[(aled.prediction_stats.iloc[:,:10] > 1).values.any(axis=1)]\n",
    "aled.prediction_stats.iloc[:,10:]\n",
    "\n",
    "# When the explained variance gets too high, subsequent principal components are highly correlated, it seems, which may lead to failure in calculating determinant of the covariance matrix. Check this error out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels in the ALED DF the same as the original dataset: True\n"
     ]
    }
   ],
   "source": [
    "posterior_probs_df = aled.prediction_stats.iloc[:,10:]\n",
    "\n",
    "#label checking\n",
    "aled_labels = posterior_probs_df[\"given label (name)\"].to_numpy()\n",
    "dataset_labels = mislabeled_train_data.labels.numpy()\n",
    "print(\"The labels in the ALED DF the same as the original dataset:\", np.array_equal(aled_labels, dataset_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\880120251.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  posterior_probs_df[(posterior_probs_df[\"given label (name)\"] != posterior_probs_df[\"out-label\"]) & (posterior_probs_df[posterior_probs_df.columns[:-2]] > 0.95).any(1)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.269205e-10</td>\n",
       "      <td>9.992463e-01</td>\n",
       "      <td>3.329976e-15</td>\n",
       "      <td>1.030791e-77</td>\n",
       "      <td>1.555483e-05</td>\n",
       "      <td>3.030660e-13</td>\n",
       "      <td>7.378853e-04</td>\n",
       "      <td>1.827494e-08</td>\n",
       "      <td>1.459256e-07</td>\n",
       "      <td>1.453907e-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7.435680e-03</td>\n",
       "      <td>1.247559e-05</td>\n",
       "      <td>3.946596e-07</td>\n",
       "      <td>9.415508e-38</td>\n",
       "      <td>3.244248e-02</td>\n",
       "      <td>2.446648e-07</td>\n",
       "      <td>9.570464e-01</td>\n",
       "      <td>3.619377e-04</td>\n",
       "      <td>2.696192e-03</td>\n",
       "      <td>4.186700e-06</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>8.849525e-06</td>\n",
       "      <td>1.576918e-126</td>\n",
       "      <td>1.960900e-02</td>\n",
       "      <td>9.537306e-01</td>\n",
       "      <td>2.541323e-08</td>\n",
       "      <td>2.660893e-02</td>\n",
       "      <td>4.611096e-21</td>\n",
       "      <td>4.256230e-05</td>\n",
       "      <td>1.324340e-08</td>\n",
       "      <td>2.938722e-11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>3.950358e-07</td>\n",
       "      <td>9.970011e-01</td>\n",
       "      <td>4.289693e-09</td>\n",
       "      <td>1.657657e-28</td>\n",
       "      <td>2.345170e-04</td>\n",
       "      <td>9.593188e-12</td>\n",
       "      <td>2.617426e-03</td>\n",
       "      <td>1.409982e-04</td>\n",
       "      <td>5.539686e-06</td>\n",
       "      <td>4.317431e-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3.399690e-06</td>\n",
       "      <td>9.949026e-01</td>\n",
       "      <td>4.329431e-10</td>\n",
       "      <td>3.975365e-37</td>\n",
       "      <td>1.814730e-04</td>\n",
       "      <td>5.460486e-14</td>\n",
       "      <td>4.883656e-03</td>\n",
       "      <td>2.678546e-05</td>\n",
       "      <td>2.072428e-06</td>\n",
       "      <td>1.108989e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59706</th>\n",
       "      <td>4.822904e-03</td>\n",
       "      <td>3.483978e-90</td>\n",
       "      <td>9.620180e-01</td>\n",
       "      <td>2.216668e-03</td>\n",
       "      <td>5.096130e-04</td>\n",
       "      <td>2.958561e-03</td>\n",
       "      <td>2.835307e-10</td>\n",
       "      <td>2.744612e-02</td>\n",
       "      <td>1.161535e-05</td>\n",
       "      <td>1.647778e-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59738</th>\n",
       "      <td>4.730511e-07</td>\n",
       "      <td>9.987775e-01</td>\n",
       "      <td>3.994495e-10</td>\n",
       "      <td>1.657689e-31</td>\n",
       "      <td>2.424353e-04</td>\n",
       "      <td>1.371576e-14</td>\n",
       "      <td>7.414240e-04</td>\n",
       "      <td>2.362822e-04</td>\n",
       "      <td>1.854317e-06</td>\n",
       "      <td>5.723574e-09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59796</th>\n",
       "      <td>4.237761e-05</td>\n",
       "      <td>9.938361e-01</td>\n",
       "      <td>3.018435e-10</td>\n",
       "      <td>7.425285e-37</td>\n",
       "      <td>5.977230e-04</td>\n",
       "      <td>2.253163e-15</td>\n",
       "      <td>5.382429e-03</td>\n",
       "      <td>1.377870e-04</td>\n",
       "      <td>3.589561e-06</td>\n",
       "      <td>6.470075e-10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59958</th>\n",
       "      <td>1.408244e-07</td>\n",
       "      <td>9.990704e-01</td>\n",
       "      <td>4.236850e-10</td>\n",
       "      <td>1.539638e-27</td>\n",
       "      <td>2.323653e-04</td>\n",
       "      <td>2.739273e-13</td>\n",
       "      <td>4.938011e-04</td>\n",
       "      <td>1.998554e-04</td>\n",
       "      <td>3.482036e-06</td>\n",
       "      <td>1.681998e-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59984</th>\n",
       "      <td>5.652871e-06</td>\n",
       "      <td>9.997265e-01</td>\n",
       "      <td>3.959834e-13</td>\n",
       "      <td>5.198732e-42</td>\n",
       "      <td>1.179644e-04</td>\n",
       "      <td>1.074778e-19</td>\n",
       "      <td>1.023562e-04</td>\n",
       "      <td>4.730652e-05</td>\n",
       "      <td>2.396516e-07</td>\n",
       "      <td>2.608767e-12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "40       1.269205e-10    9.992463e-01    3.329976e-15    1.030791e-77   \n",
       "90       7.435680e-03    1.247559e-05    3.946596e-07    9.415508e-38   \n",
       "179      8.849525e-06   1.576918e-126    1.960900e-02    9.537306e-01   \n",
       "269      3.950358e-07    9.970011e-01    4.289693e-09    1.657657e-28   \n",
       "290      3.399690e-06    9.949026e-01    4.329431e-10    3.975365e-37   \n",
       "...               ...             ...             ...             ...   \n",
       "59706    4.822904e-03    3.483978e-90    9.620180e-01    2.216668e-03   \n",
       "59738    4.730511e-07    9.987775e-01    3.994495e-10    1.657689e-31   \n",
       "59796    4.237761e-05    9.938361e-01    3.018435e-10    7.425285e-37   \n",
       "59958    1.408244e-07    9.990704e-01    4.236850e-10    1.539638e-27   \n",
       "59984    5.652871e-06    9.997265e-01    3.959834e-13    5.198732e-42   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "40       1.555483e-05    3.030660e-13    7.378853e-04    1.827494e-08   \n",
       "90       3.244248e-02    2.446648e-07    9.570464e-01    3.619377e-04   \n",
       "179      2.541323e-08    2.660893e-02    4.611096e-21    4.256230e-05   \n",
       "269      2.345170e-04    9.593188e-12    2.617426e-03    1.409982e-04   \n",
       "290      1.814730e-04    5.460486e-14    4.883656e-03    2.678546e-05   \n",
       "...               ...             ...             ...             ...   \n",
       "59706    5.096130e-04    2.958561e-03    2.835307e-10    2.744612e-02   \n",
       "59738    2.424353e-04    1.371576e-14    7.414240e-04    2.362822e-04   \n",
       "59796    5.977230e-04    2.253163e-15    5.382429e-03    1.377870e-04   \n",
       "59958    2.323653e-04    2.739273e-13    4.938011e-04    1.998554e-04   \n",
       "59984    1.179644e-04    1.074778e-19    1.023562e-04    4.730652e-05   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \n",
       "40       1.459256e-07    1.453907e-07                 5.0        1.0  \n",
       "90       2.696192e-03    4.186700e-06                 5.0        6.0  \n",
       "179      1.324340e-08    2.938722e-11                 4.0        3.0  \n",
       "269      5.539686e-06    4.317431e-08                 3.0        1.0  \n",
       "290      2.072428e-06    1.108989e-09                 0.0        1.0  \n",
       "...               ...             ...                 ...        ...  \n",
       "59706    1.161535e-05    1.647778e-05                 4.0        2.0  \n",
       "59738    1.854317e-06    5.723574e-09                 4.0        1.0  \n",
       "59796    3.589561e-06    6.470075e-10                 9.0        1.0  \n",
       "59958    3.482036e-06    1.681998e-09                 3.0        1.0  \n",
       "59984    2.396516e-07    2.608767e-12                 9.0        1.0  \n",
       "\n",
       "[1514 rows x 12 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_probs_df[(posterior_probs_df[\"given label (name)\"] != posterior_probs_df[\"Aled label\"]) & (posterior_probs_df[posterior_probs_df.columns[:-2]] > 0.95).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_labels, pred_probs = get_output_probs(cnn_1, loaders_1[\"train\"], device)\n",
    "comp_labels, model_labels = get_outputs(cnn_1, loaders_1[\"train\"], device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the sklearn Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(roc_labels)\n",
    "y_onehot_test = label_binarizer.transform(roc_labels)\n",
    "class_id = label_binarizer.classes_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    pred_probs[:, class_id],\n",
    "    name=f\"{class_id} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    #plot_chance_level=True,\n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"One-vs-Rest ROC curves:\\n{} vs rest\".format(class_id))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test.ravel(),\n",
    "    pred_probs.ravel(),\n",
    "    name=\"micro-average OvR\",\n",
    "    color=\"darkorange\",\n",
    "    #plot_chance_level=True,\n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Micro-averaged One-vs-Rest\\nReceiver Operating Characteristic\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9474720184104939\n",
      "Best F1 score: 0.8780678938241964; threshold: 0.3195878565311432\n"
     ]
    }
   ],
   "source": [
    "def find_best_F1(y, x, ret=False):\n",
    "  # ret determines whether to return or print best F1 and threshold\n",
    "  print(\"AUC:\", sklearn.metrics.roc_auc_score(y, x))\n",
    "  precisions, recalls, thresholds = sklearn.metrics.precision_recall_curve(y, x)\n",
    "  f1_scores = 2*precisions*recalls/(precisions+recalls)\n",
    "  # f1_scores = 2/(1/precisions + 1/recalls)\n",
    "  best_F1 = np.nanmax(f1_scores)\n",
    "  best_F1_threshold = thresholds[np.nanargmax(f1_scores)]\n",
    "  if not ret:\n",
    "    print(f\"Best F1 score: {best_F1}; threshold: {best_F1_threshold}\")\n",
    "    #print_classification_report(y, x>=best_F1_threshold)\n",
    "  else: return best_F1, best_F1_threshold\n",
    "\n",
    "find_best_F1(y_onehot_test.ravel(), pred_probs.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\1697124016.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posterior_probs_df[\"model pred labels\"] = model_labels\n"
     ]
    }
   ],
   "source": [
    "posterior_probs_df[\"model pred labels\"] = model_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\3860588679.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  posterior_probs_df[\"true labels\"] = mislabeled_train_data.true_labels\n"
     ]
    }
   ],
   "source": [
    "posterior_probs_df[\"true labels\"] = mislabeled_train_data.true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.994484e-06</td>\n",
       "      <td>1.425344e-88</td>\n",
       "      <td>4.525460e-02</td>\n",
       "      <td>2.914956e-02</td>\n",
       "      <td>5.087696e-07</td>\n",
       "      <td>9.254864e-01</td>\n",
       "      <td>1.868124e-17</td>\n",
       "      <td>9.750478e-05</td>\n",
       "      <td>7.416739e-06</td>\n",
       "      <td>3.664137e-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.894261e-01</td>\n",
       "      <td>3.289228e-24</td>\n",
       "      <td>2.945764e-07</td>\n",
       "      <td>1.552987e-42</td>\n",
       "      <td>1.534656e-02</td>\n",
       "      <td>4.241667e-09</td>\n",
       "      <td>9.503997e-02</td>\n",
       "      <td>1.042224e-07</td>\n",
       "      <td>1.869386e-04</td>\n",
       "      <td>6.980511e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.587006e-02</td>\n",
       "      <td>8.648416e-27</td>\n",
       "      <td>5.024709e-02</td>\n",
       "      <td>4.228416e-10</td>\n",
       "      <td>3.615738e-01</td>\n",
       "      <td>1.877209e-02</td>\n",
       "      <td>2.180250e-02</td>\n",
       "      <td>1.476694e-02</td>\n",
       "      <td>4.996565e-01</td>\n",
       "      <td>7.311073e-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.619604e-07</td>\n",
       "      <td>9.997735e-01</td>\n",
       "      <td>6.832654e-12</td>\n",
       "      <td>7.724481e-37</td>\n",
       "      <td>3.312210e-05</td>\n",
       "      <td>2.502205e-18</td>\n",
       "      <td>1.790781e-04</td>\n",
       "      <td>1.362546e-05</td>\n",
       "      <td>8.083372e-08</td>\n",
       "      <td>1.896149e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.821214e-04</td>\n",
       "      <td>1.909752e-35</td>\n",
       "      <td>1.766941e-02</td>\n",
       "      <td>1.157720e-14</td>\n",
       "      <td>6.992237e-03</td>\n",
       "      <td>1.745821e-05</td>\n",
       "      <td>7.405138e-04</td>\n",
       "      <td>2.518708e-03</td>\n",
       "      <td>9.810380e-02</td>\n",
       "      <td>8.737758e-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>1.246863e-04</td>\n",
       "      <td>1.056369e-11</td>\n",
       "      <td>1.314167e-03</td>\n",
       "      <td>3.912042e-13</td>\n",
       "      <td>1.264216e-01</td>\n",
       "      <td>7.595670e-04</td>\n",
       "      <td>9.316682e-02</td>\n",
       "      <td>9.239334e-02</td>\n",
       "      <td>3.098150e-01</td>\n",
       "      <td>3.760048e-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>4.190393e-05</td>\n",
       "      <td>1.673895e-94</td>\n",
       "      <td>3.168869e-02</td>\n",
       "      <td>9.271175e-01</td>\n",
       "      <td>1.605972e-06</td>\n",
       "      <td>4.071756e-02</td>\n",
       "      <td>6.017904e-16</td>\n",
       "      <td>4.321706e-04</td>\n",
       "      <td>5.456811e-07</td>\n",
       "      <td>1.806257e-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>2.468189e-03</td>\n",
       "      <td>2.164803e-61</td>\n",
       "      <td>1.190551e-01</td>\n",
       "      <td>2.497795e-03</td>\n",
       "      <td>2.562898e-04</td>\n",
       "      <td>8.737391e-01</td>\n",
       "      <td>3.824165e-09</td>\n",
       "      <td>9.989200e-04</td>\n",
       "      <td>9.843031e-04</td>\n",
       "      <td>3.199554e-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>1.565787e-01</td>\n",
       "      <td>7.656495e-36</td>\n",
       "      <td>1.814124e-02</td>\n",
       "      <td>1.257741e-16</td>\n",
       "      <td>5.833353e-01</td>\n",
       "      <td>3.829435e-04</td>\n",
       "      <td>5.166533e-02</td>\n",
       "      <td>3.965610e-03</td>\n",
       "      <td>1.716500e-01</td>\n",
       "      <td>1.428087e-02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>5.331295e-05</td>\n",
       "      <td>4.221030e-17</td>\n",
       "      <td>4.289579e-03</td>\n",
       "      <td>1.531420e-08</td>\n",
       "      <td>7.237405e-02</td>\n",
       "      <td>7.286495e-04</td>\n",
       "      <td>2.104197e-02</td>\n",
       "      <td>7.395199e-02</td>\n",
       "      <td>1.788303e-01</td>\n",
       "      <td>6.487302e-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "0        3.994484e-06    1.425344e-88    4.525460e-02    2.914956e-02   \n",
       "1        8.894261e-01    3.289228e-24    2.945764e-07    1.552987e-42   \n",
       "2        2.587006e-02    8.648416e-27    5.024709e-02    4.228416e-10   \n",
       "3        5.619604e-07    9.997735e-01    6.832654e-12    7.724481e-37   \n",
       "4        1.821214e-04    1.909752e-35    1.766941e-02    1.157720e-14   \n",
       "...               ...             ...             ...             ...   \n",
       "59995    1.246863e-04    1.056369e-11    1.314167e-03    3.912042e-13   \n",
       "59996    4.190393e-05    1.673895e-94    3.168869e-02    9.271175e-01   \n",
       "59997    2.468189e-03    2.164803e-61    1.190551e-01    2.497795e-03   \n",
       "59998    1.565787e-01    7.656495e-36    1.814124e-02    1.257741e-16   \n",
       "59999    5.331295e-05    4.221030e-17    4.289579e-03    1.531420e-08   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "0        5.087696e-07    9.254864e-01    1.868124e-17    9.750478e-05   \n",
       "1        1.534656e-02    4.241667e-09    9.503997e-02    1.042224e-07   \n",
       "2        3.615738e-01    1.877209e-02    2.180250e-02    1.476694e-02   \n",
       "3        3.312210e-05    2.502205e-18    1.790781e-04    1.362546e-05   \n",
       "4        6.992237e-03    1.745821e-05    7.405138e-04    2.518708e-03   \n",
       "...               ...             ...             ...             ...   \n",
       "59995    1.264216e-01    7.595670e-04    9.316682e-02    9.239334e-02   \n",
       "59996    1.605972e-06    4.071756e-02    6.017904e-16    4.321706e-04   \n",
       "59997    2.562898e-04    8.737391e-01    3.824165e-09    9.989200e-04   \n",
       "59998    5.833353e-01    3.829435e-04    5.166533e-02    3.965610e-03   \n",
       "59999    7.237405e-02    7.286495e-04    2.104197e-02    7.395199e-02   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "0        7.416739e-06    3.664137e-08                 5.0        5.0   \n",
       "1        1.869386e-04    6.980511e-13                 0.0        0.0   \n",
       "2        4.996565e-01    7.311073e-03                 4.0        4.0   \n",
       "3        8.083372e-08    1.896149e-11                 1.0        1.0   \n",
       "4        9.810380e-02    8.737758e-01                 9.0        9.0   \n",
       "...               ...             ...                 ...        ...   \n",
       "59995    3.098150e-01    3.760048e-01                 8.0        8.0   \n",
       "59996    5.456811e-07    1.806257e-08                 3.0        3.0   \n",
       "59997    9.843031e-04    3.199554e-07                 5.0        5.0   \n",
       "59998    1.716500e-01    1.428087e-02                 6.0        4.0   \n",
       "59999    1.788303e-01    6.487302e-01                 8.0        9.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "0                      5            5  \n",
       "1                      0            0  \n",
       "2                      4            4  \n",
       "3                      1            1  \n",
       "4                      9            9  \n",
       "...                  ...          ...  \n",
       "59995                  8            8  \n",
       "59996                  3            3  \n",
       "59997                  5            5  \n",
       "59998                  6            6  \n",
       "59999                  8            8  \n",
       "\n",
       "[60000 rows x 14 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11992</th>\n",
       "      <td>1.039513e-06</td>\n",
       "      <td>6.935316e-07</td>\n",
       "      <td>3.080565e-04</td>\n",
       "      <td>1.170538e-14</td>\n",
       "      <td>0.111587</td>\n",
       "      <td>3.986384e-04</td>\n",
       "      <td>6.199272e-02</td>\n",
       "      <td>0.046513</td>\n",
       "      <td>2.791149e-01</td>\n",
       "      <td>5.000843e-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14337</th>\n",
       "      <td>1.805431e-05</td>\n",
       "      <td>3.072395e-33</td>\n",
       "      <td>3.070499e-02</td>\n",
       "      <td>2.642737e-02</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>8.438086e-03</td>\n",
       "      <td>4.961216e-05</td>\n",
       "      <td>0.723785</td>\n",
       "      <td>2.998202e-03</td>\n",
       "      <td>1.871127e-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14664</th>\n",
       "      <td>2.491910e-02</td>\n",
       "      <td>1.219756e-47</td>\n",
       "      <td>7.250838e-02</td>\n",
       "      <td>2.722183e-16</td>\n",
       "      <td>0.226033</td>\n",
       "      <td>8.335077e-02</td>\n",
       "      <td>1.919278e-06</td>\n",
       "      <td>0.249660</td>\n",
       "      <td>3.348941e-01</td>\n",
       "      <td>8.632665e-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15717</th>\n",
       "      <td>3.634307e-07</td>\n",
       "      <td>6.736700e-57</td>\n",
       "      <td>1.094892e-02</td>\n",
       "      <td>8.740681e-01</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.145622e-01</td>\n",
       "      <td>1.488690e-12</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>3.774981e-06</td>\n",
       "      <td>7.161682e-06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17808</th>\n",
       "      <td>4.031571e-02</td>\n",
       "      <td>4.669940e-32</td>\n",
       "      <td>6.675146e-02</td>\n",
       "      <td>1.859561e-11</td>\n",
       "      <td>0.339874</td>\n",
       "      <td>1.012110e-03</td>\n",
       "      <td>4.284974e-02</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>4.713122e-01</td>\n",
       "      <td>3.495965e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19869</th>\n",
       "      <td>2.492650e-03</td>\n",
       "      <td>3.382537e-81</td>\n",
       "      <td>2.137535e-01</td>\n",
       "      <td>9.358438e-04</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>8.555048e-03</td>\n",
       "      <td>5.276236e-09</td>\n",
       "      <td>0.771206</td>\n",
       "      <td>8.358617e-06</td>\n",
       "      <td>1.568560e-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20735</th>\n",
       "      <td>3.401115e-03</td>\n",
       "      <td>1.059652e-18</td>\n",
       "      <td>1.232106e-03</td>\n",
       "      <td>1.223090e-18</td>\n",
       "      <td>0.127192</td>\n",
       "      <td>2.609534e-04</td>\n",
       "      <td>4.070321e-02</td>\n",
       "      <td>0.070766</td>\n",
       "      <td>3.147084e-01</td>\n",
       "      <td>4.417359e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21918</th>\n",
       "      <td>3.945002e-02</td>\n",
       "      <td>2.391628e-08</td>\n",
       "      <td>1.812536e-09</td>\n",
       "      <td>2.921429e-57</td>\n",
       "      <td>0.047504</td>\n",
       "      <td>1.295940e-08</td>\n",
       "      <td>9.124566e-01</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>5.761666e-04</td>\n",
       "      <td>1.885472e-06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21982</th>\n",
       "      <td>9.127342e-04</td>\n",
       "      <td>1.012957e-108</td>\n",
       "      <td>8.664255e-01</td>\n",
       "      <td>1.913276e-02</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.090601e-01</td>\n",
       "      <td>3.613939e-17</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>1.816087e-05</td>\n",
       "      <td>4.686668e-09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22212</th>\n",
       "      <td>2.117998e-03</td>\n",
       "      <td>6.361477e-03</td>\n",
       "      <td>6.586160e-06</td>\n",
       "      <td>7.067651e-22</td>\n",
       "      <td>0.242389</td>\n",
       "      <td>2.619279e-07</td>\n",
       "      <td>6.581885e-01</td>\n",
       "      <td>0.051691</td>\n",
       "      <td>3.921890e-02</td>\n",
       "      <td>2.630647e-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22803</th>\n",
       "      <td>2.079086e-01</td>\n",
       "      <td>1.422044e-15</td>\n",
       "      <td>4.774121e-05</td>\n",
       "      <td>1.605036e-25</td>\n",
       "      <td>0.047178</td>\n",
       "      <td>2.687067e-06</td>\n",
       "      <td>7.359547e-01</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>8.588052e-03</td>\n",
       "      <td>6.180013e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24569</th>\n",
       "      <td>1.051092e-01</td>\n",
       "      <td>5.052540e-03</td>\n",
       "      <td>2.456787e-11</td>\n",
       "      <td>7.016015e-56</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>1.858430e-19</td>\n",
       "      <td>8.823757e-01</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.209201e-06</td>\n",
       "      <td>4.811310e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26516</th>\n",
       "      <td>1.029442e-05</td>\n",
       "      <td>2.447844e-07</td>\n",
       "      <td>2.866782e-09</td>\n",
       "      <td>2.631995e-62</td>\n",
       "      <td>0.184686</td>\n",
       "      <td>2.007042e-05</td>\n",
       "      <td>4.598514e-01</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>1.445833e-02</td>\n",
       "      <td>3.387037e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26733</th>\n",
       "      <td>2.070881e-02</td>\n",
       "      <td>5.815727e-91</td>\n",
       "      <td>6.533880e-01</td>\n",
       "      <td>3.452039e-03</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>1.993881e-01</td>\n",
       "      <td>3.138081e-10</td>\n",
       "      <td>0.121066</td>\n",
       "      <td>1.888177e-05</td>\n",
       "      <td>3.216964e-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26850</th>\n",
       "      <td>4.288895e-02</td>\n",
       "      <td>1.418965e-46</td>\n",
       "      <td>6.461337e-01</td>\n",
       "      <td>3.475279e-08</td>\n",
       "      <td>0.102679</td>\n",
       "      <td>2.256468e-03</td>\n",
       "      <td>1.149550e-03</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>7.044316e-02</td>\n",
       "      <td>1.220860e-01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>1.779452e-04</td>\n",
       "      <td>1.335575e-109</td>\n",
       "      <td>1.162321e-01</td>\n",
       "      <td>8.773551e-01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.503428e-03</td>\n",
       "      <td>8.883269e-17</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>1.946303e-07</td>\n",
       "      <td>1.574428e-09</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28132</th>\n",
       "      <td>6.279417e-07</td>\n",
       "      <td>3.393678e-66</td>\n",
       "      <td>6.382212e-02</td>\n",
       "      <td>9.281051e-01</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>3.406558e-04</td>\n",
       "      <td>4.998516e-11</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>1.436431e-06</td>\n",
       "      <td>1.286889e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31284</th>\n",
       "      <td>9.189197e-07</td>\n",
       "      <td>9.303503e-33</td>\n",
       "      <td>2.422507e-02</td>\n",
       "      <td>3.416114e-20</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>2.382840e-02</td>\n",
       "      <td>9.119695e-04</td>\n",
       "      <td>0.675849</td>\n",
       "      <td>2.858054e-02</td>\n",
       "      <td>2.381039e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33484</th>\n",
       "      <td>1.952085e-01</td>\n",
       "      <td>1.667886e-21</td>\n",
       "      <td>3.739358e-06</td>\n",
       "      <td>9.033027e-38</td>\n",
       "      <td>0.335796</td>\n",
       "      <td>7.035527e-05</td>\n",
       "      <td>4.589223e-01</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>3.497275e-03</td>\n",
       "      <td>2.476547e-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34644</th>\n",
       "      <td>7.113709e-05</td>\n",
       "      <td>9.635356e-41</td>\n",
       "      <td>1.758126e-01</td>\n",
       "      <td>6.632632e-01</td>\n",
       "      <td>0.023074</td>\n",
       "      <td>2.936322e-03</td>\n",
       "      <td>2.667191e-06</td>\n",
       "      <td>0.123045</td>\n",
       "      <td>4.135977e-03</td>\n",
       "      <td>7.659191e-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36309</th>\n",
       "      <td>2.987986e-03</td>\n",
       "      <td>4.650357e-57</td>\n",
       "      <td>9.926053e-02</td>\n",
       "      <td>3.026292e-03</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>8.763195e-01</td>\n",
       "      <td>1.770483e-08</td>\n",
       "      <td>0.017031</td>\n",
       "      <td>6.106991e-04</td>\n",
       "      <td>4.153333e-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36934</th>\n",
       "      <td>1.600833e-08</td>\n",
       "      <td>6.297082e-06</td>\n",
       "      <td>9.457111e-04</td>\n",
       "      <td>5.867185e-09</td>\n",
       "      <td>0.291002</td>\n",
       "      <td>4.251201e-03</td>\n",
       "      <td>1.187276e-02</td>\n",
       "      <td>0.147148</td>\n",
       "      <td>5.229240e-02</td>\n",
       "      <td>4.924818e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37502</th>\n",
       "      <td>1.273813e-03</td>\n",
       "      <td>3.615769e-10</td>\n",
       "      <td>3.809311e-06</td>\n",
       "      <td>1.242390e-38</td>\n",
       "      <td>0.220533</td>\n",
       "      <td>6.564171e-04</td>\n",
       "      <td>4.614837e-01</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>7.977622e-02</td>\n",
       "      <td>2.273104e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38658</th>\n",
       "      <td>1.422303e-02</td>\n",
       "      <td>2.993748e-36</td>\n",
       "      <td>1.045385e-01</td>\n",
       "      <td>6.408577e-06</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>7.393036e-01</td>\n",
       "      <td>1.289935e-04</td>\n",
       "      <td>0.088804</td>\n",
       "      <td>2.267930e-02</td>\n",
       "      <td>1.580129e-03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41396</th>\n",
       "      <td>8.896975e-04</td>\n",
       "      <td>6.979465e-22</td>\n",
       "      <td>9.883482e-05</td>\n",
       "      <td>7.317982e-22</td>\n",
       "      <td>0.068116</td>\n",
       "      <td>1.090387e-06</td>\n",
       "      <td>1.120034e-02</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>9.175066e-01</td>\n",
       "      <td>2.048449e-03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41594</th>\n",
       "      <td>9.747419e-02</td>\n",
       "      <td>9.180616e-44</td>\n",
       "      <td>2.924745e-05</td>\n",
       "      <td>4.804961e-46</td>\n",
       "      <td>0.025603</td>\n",
       "      <td>4.838663e-06</td>\n",
       "      <td>9.145349e-04</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.183764e-01</td>\n",
       "      <td>7.575760e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43042</th>\n",
       "      <td>1.100731e-01</td>\n",
       "      <td>3.412066e-21</td>\n",
       "      <td>8.325027e-06</td>\n",
       "      <td>2.318219e-43</td>\n",
       "      <td>0.212734</td>\n",
       "      <td>9.301092e-05</td>\n",
       "      <td>1.046221e-01</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>4.845116e-01</td>\n",
       "      <td>8.791364e-02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44822</th>\n",
       "      <td>8.402249e-07</td>\n",
       "      <td>2.896399e-07</td>\n",
       "      <td>2.222027e-03</td>\n",
       "      <td>1.288853e-06</td>\n",
       "      <td>0.124165</td>\n",
       "      <td>1.449030e-02</td>\n",
       "      <td>2.848409e-02</td>\n",
       "      <td>0.349197</td>\n",
       "      <td>4.482362e-02</td>\n",
       "      <td>4.366157e-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48494</th>\n",
       "      <td>1.758610e-03</td>\n",
       "      <td>9.515932e-31</td>\n",
       "      <td>3.723264e-03</td>\n",
       "      <td>6.743378e-15</td>\n",
       "      <td>0.079098</td>\n",
       "      <td>1.009261e-06</td>\n",
       "      <td>1.421249e-02</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>8.989956e-01</td>\n",
       "      <td>2.205375e-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50086</th>\n",
       "      <td>1.453999e-02</td>\n",
       "      <td>1.906713e-11</td>\n",
       "      <td>3.154619e-07</td>\n",
       "      <td>1.352930e-41</td>\n",
       "      <td>0.092611</td>\n",
       "      <td>2.631787e-06</td>\n",
       "      <td>8.883980e-01</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>2.193690e-03</td>\n",
       "      <td>7.705651e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50618</th>\n",
       "      <td>6.387910e-03</td>\n",
       "      <td>1.858009e-09</td>\n",
       "      <td>1.646112e-05</td>\n",
       "      <td>1.576830e-29</td>\n",
       "      <td>0.132263</td>\n",
       "      <td>6.383835e-05</td>\n",
       "      <td>8.222898e-01</td>\n",
       "      <td>0.020462</td>\n",
       "      <td>1.106016e-02</td>\n",
       "      <td>7.456772e-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52232</th>\n",
       "      <td>6.712647e-06</td>\n",
       "      <td>1.870316e-14</td>\n",
       "      <td>1.141628e-03</td>\n",
       "      <td>4.200838e-08</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>3.171154e-04</td>\n",
       "      <td>1.389963e-02</td>\n",
       "      <td>0.109151</td>\n",
       "      <td>1.430470e-01</td>\n",
       "      <td>6.743115e-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53131</th>\n",
       "      <td>1.144857e-02</td>\n",
       "      <td>1.947976e-26</td>\n",
       "      <td>2.133447e-02</td>\n",
       "      <td>2.101160e-13</td>\n",
       "      <td>0.166982</td>\n",
       "      <td>2.354788e-01</td>\n",
       "      <td>3.689663e-03</td>\n",
       "      <td>0.018560</td>\n",
       "      <td>5.409501e-01</td>\n",
       "      <td>1.555603e-03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53306</th>\n",
       "      <td>7.688452e-02</td>\n",
       "      <td>2.327638e-65</td>\n",
       "      <td>1.931511e-01</td>\n",
       "      <td>3.727228e-11</td>\n",
       "      <td>0.016572</td>\n",
       "      <td>6.866646e-01</td>\n",
       "      <td>1.380055e-07</td>\n",
       "      <td>0.016199</td>\n",
       "      <td>1.044637e-02</td>\n",
       "      <td>8.219540e-05</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53680</th>\n",
       "      <td>1.236713e-06</td>\n",
       "      <td>2.966101e-15</td>\n",
       "      <td>9.893489e-03</td>\n",
       "      <td>1.812802e-08</td>\n",
       "      <td>0.085864</td>\n",
       "      <td>2.489877e-02</td>\n",
       "      <td>4.329549e-03</td>\n",
       "      <td>0.401364</td>\n",
       "      <td>3.011536e-02</td>\n",
       "      <td>4.435328e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54586</th>\n",
       "      <td>2.916471e-06</td>\n",
       "      <td>7.354392e-13</td>\n",
       "      <td>6.579420e-03</td>\n",
       "      <td>3.013886e-07</td>\n",
       "      <td>0.099372</td>\n",
       "      <td>1.658937e-02</td>\n",
       "      <td>9.653928e-03</td>\n",
       "      <td>0.302985</td>\n",
       "      <td>4.757670e-02</td>\n",
       "      <td>5.172405e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54878</th>\n",
       "      <td>3.431756e-05</td>\n",
       "      <td>8.448305e-08</td>\n",
       "      <td>5.965179e-12</td>\n",
       "      <td>9.548182e-75</td>\n",
       "      <td>0.485194</td>\n",
       "      <td>5.237933e-10</td>\n",
       "      <td>1.180727e-02</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.783370e-01</td>\n",
       "      <td>2.461585e-02</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56224</th>\n",
       "      <td>5.576437e-02</td>\n",
       "      <td>3.600371e-53</td>\n",
       "      <td>1.347052e-02</td>\n",
       "      <td>1.139443e-15</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>9.155286e-01</td>\n",
       "      <td>8.829177e-06</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>5.059247e-03</td>\n",
       "      <td>1.100527e-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "11992    1.039513e-06    6.935316e-07    3.080565e-04    1.170538e-14   \n",
       "14337    1.805431e-05    3.072395e-33    3.070499e-02    2.642737e-02   \n",
       "14664    2.491910e-02    1.219756e-47    7.250838e-02    2.722183e-16   \n",
       "15717    3.634307e-07    6.736700e-57    1.094892e-02    8.740681e-01   \n",
       "17808    4.031571e-02    4.669940e-32    6.675146e-02    1.859561e-11   \n",
       "19869    2.492650e-03    3.382537e-81    2.137535e-01    9.358438e-04   \n",
       "20735    3.401115e-03    1.059652e-18    1.232106e-03    1.223090e-18   \n",
       "21918    3.945002e-02    2.391628e-08    1.812536e-09    2.921429e-57   \n",
       "21982    9.127342e-04   1.012957e-108    8.664255e-01    1.913276e-02   \n",
       "22212    2.117998e-03    6.361477e-03    6.586160e-06    7.067651e-22   \n",
       "22803    2.079086e-01    1.422044e-15    4.774121e-05    1.605036e-25   \n",
       "24569    1.051092e-01    5.052540e-03    2.456787e-11    7.016015e-56   \n",
       "26516    1.029442e-05    2.447844e-07    2.866782e-09    2.631995e-62   \n",
       "26733    2.070881e-02    5.815727e-91    6.533880e-01    3.452039e-03   \n",
       "26850    4.288895e-02    1.418965e-46    6.461337e-01    3.475279e-08   \n",
       "27645    1.779452e-04   1.335575e-109    1.162321e-01    8.773551e-01   \n",
       "28132    6.279417e-07    3.393678e-66    6.382212e-02    9.281051e-01   \n",
       "31284    9.189197e-07    9.303503e-33    2.422507e-02    3.416114e-20   \n",
       "33484    1.952085e-01    1.667886e-21    3.739358e-06    9.033027e-38   \n",
       "34644    7.113709e-05    9.635356e-41    1.758126e-01    6.632632e-01   \n",
       "36309    2.987986e-03    4.650357e-57    9.926053e-02    3.026292e-03   \n",
       "36934    1.600833e-08    6.297082e-06    9.457111e-04    5.867185e-09   \n",
       "37502    1.273813e-03    3.615769e-10    3.809311e-06    1.242390e-38   \n",
       "38658    1.422303e-02    2.993748e-36    1.045385e-01    6.408577e-06   \n",
       "41396    8.896975e-04    6.979465e-22    9.883482e-05    7.317982e-22   \n",
       "41594    9.747419e-02    9.180616e-44    2.924745e-05    4.804961e-46   \n",
       "43042    1.100731e-01    3.412066e-21    8.325027e-06    2.318219e-43   \n",
       "44822    8.402249e-07    2.896399e-07    2.222027e-03    1.288853e-06   \n",
       "48494    1.758610e-03    9.515932e-31    3.723264e-03    6.743378e-15   \n",
       "50086    1.453999e-02    1.906713e-11    3.154619e-07    1.352930e-41   \n",
       "50618    6.387910e-03    1.858009e-09    1.646112e-05    1.576830e-29   \n",
       "52232    6.712647e-06    1.870316e-14    1.141628e-03    4.200838e-08   \n",
       "53131    1.144857e-02    1.947976e-26    2.133447e-02    2.101160e-13   \n",
       "53306    7.688452e-02    2.327638e-65    1.931511e-01    3.727228e-11   \n",
       "53680    1.236713e-06    2.966101e-15    9.893489e-03    1.812802e-08   \n",
       "54586    2.916471e-06    7.354392e-13    6.579420e-03    3.013886e-07   \n",
       "54878    3.431756e-05    8.448305e-08    5.965179e-12    9.548182e-75   \n",
       "56224    5.576437e-02    3.600371e-53    1.347052e-02    1.139443e-15   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "11992        0.111587    3.986384e-04    6.199272e-02        0.046513   \n",
       "14337        0.020466    8.438086e-03    4.961216e-05        0.723785   \n",
       "14664        0.226033    8.335077e-02    1.919278e-06        0.249660   \n",
       "15717        0.000033    1.145622e-01    1.488690e-12        0.000377   \n",
       "17808        0.339874    1.012110e-03    4.284974e-02        0.002925   \n",
       "19869        0.001480    8.555048e-03    5.276236e-09        0.771206   \n",
       "20735        0.127192    2.609534e-04    4.070321e-02        0.070766   \n",
       "21918        0.047504    1.295940e-08    9.124566e-01        0.000011   \n",
       "21982        0.000016    1.090601e-01    3.613939e-17        0.004435   \n",
       "22212        0.242389    2.619279e-07    6.581885e-01        0.051691   \n",
       "22803        0.047178    2.687067e-06    7.359547e-01        0.000320   \n",
       "24569        0.007450    1.858430e-19    8.823757e-01        0.000011   \n",
       "26516        0.184686    2.007042e-05    4.598514e-01        0.002270   \n",
       "26733        0.001946    1.993881e-01    3.138081e-10        0.121066   \n",
       "26850        0.102679    2.256468e-03    1.149550e-03        0.012363   \n",
       "27645        0.000003    5.503428e-03    8.883269e-17        0.000728   \n",
       "28132        0.000053    3.406558e-04    4.998516e-11        0.007676   \n",
       "31284        0.008500    2.382840e-02    9.119695e-04        0.675849   \n",
       "33484        0.335796    7.035527e-05    4.589223e-01        0.004026   \n",
       "34644        0.023074    2.936322e-03    2.667191e-06        0.123045   \n",
       "36309        0.000722    8.763195e-01    1.770483e-08        0.017031   \n",
       "36934        0.291002    4.251201e-03    1.187276e-02        0.147148   \n",
       "37502        0.220533    6.564171e-04    4.614837e-01        0.008963   \n",
       "38658        0.028736    7.393036e-01    1.289935e-04        0.088804   \n",
       "41396        0.068116    1.090387e-06    1.120034e-02        0.000139   \n",
       "41594        0.025603    4.838663e-06    9.145349e-04        0.000021   \n",
       "43042        0.212734    9.301092e-05    1.046221e-01        0.000044   \n",
       "44822        0.124165    1.449030e-02    2.848409e-02        0.349197   \n",
       "48494        0.079098    1.009261e-06    1.421249e-02        0.000006   \n",
       "50086        0.092611    2.631787e-06    8.883980e-01        0.001484   \n",
       "50618        0.132263    6.383835e-05    8.222898e-01        0.020462   \n",
       "52232        0.058125    3.171154e-04    1.389963e-02        0.109151   \n",
       "53131        0.166982    2.354788e-01    3.689663e-03        0.018560   \n",
       "53306        0.016572    6.866646e-01    1.380055e-07        0.016199   \n",
       "53680        0.085864    2.489877e-02    4.329549e-03        0.401364   \n",
       "54586        0.099372    1.658937e-02    9.653928e-03        0.302985   \n",
       "54878        0.485194    5.237933e-10    1.180727e-02        0.000012   \n",
       "56224        0.007806    9.155286e-01    8.829177e-06        0.002351   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "11992    2.791149e-01    5.000843e-01                 4.0        9.0   \n",
       "14337    2.998202e-03    1.871127e-01                 5.0        7.0   \n",
       "14664    3.348941e-01    8.632665e-03                 5.0        8.0   \n",
       "15717    3.774981e-06    7.161682e-06                 4.0        3.0   \n",
       "17808    4.713122e-01    3.495965e-02                 5.0        8.0   \n",
       "19869    8.358617e-06    1.568560e-03                 4.0        7.0   \n",
       "20735    3.147084e-01    4.417359e-01                 2.0        9.0   \n",
       "21918    5.761666e-04    1.885472e-06                 9.0        6.0   \n",
       "21982    1.816087e-05    4.686668e-09                 4.0        2.0   \n",
       "22212    3.921890e-02    2.630647e-05                 4.0        6.0   \n",
       "22803    8.588052e-03    6.180013e-09                 8.0        6.0   \n",
       "24569    1.209201e-06    4.811310e-12                 0.0        6.0   \n",
       "26516    1.445833e-02    3.387037e-01                 1.0        6.0   \n",
       "26733    1.888177e-05    3.216964e-05                 4.0        2.0   \n",
       "26850    7.044316e-02    1.220860e-01                 6.0        2.0   \n",
       "27645    1.946303e-07    1.574428e-09                 4.0        3.0   \n",
       "28132    1.436431e-06    1.286889e-06                 1.0        3.0   \n",
       "31284    2.858054e-02    2.381039e-01                 2.0        7.0   \n",
       "33484    3.497275e-03    2.476547e-03                 5.0        6.0   \n",
       "34644    4.135977e-03    7.659191e-03                 8.0        3.0   \n",
       "36309    6.106991e-04    4.153333e-05                 4.0        5.0   \n",
       "36934    5.229240e-02    4.924818e-01                 1.0        9.0   \n",
       "37502    7.977622e-02    2.273104e-01                 2.0        6.0   \n",
       "38658    2.267930e-02    1.580129e-03                 9.0        5.0   \n",
       "41396    9.175066e-01    2.048449e-03                 7.0        8.0   \n",
       "41594    1.183764e-01    7.575760e-01                 2.0        9.0   \n",
       "43042    4.845116e-01    8.791364e-02                 7.0        8.0   \n",
       "44822    4.482362e-02    4.366157e-01                 3.0        9.0   \n",
       "48494    8.989956e-01    2.205375e-03                 2.0        8.0   \n",
       "50086    2.193690e-03    7.705651e-04                 0.0        6.0   \n",
       "50618    1.106016e-02    7.456772e-03                 4.0        6.0   \n",
       "52232    1.430470e-01    6.743115e-01                 5.0        9.0   \n",
       "53131    5.409501e-01    1.555603e-03                 7.0        8.0   \n",
       "53306    1.044637e-02    8.219540e-05                 8.0        5.0   \n",
       "53680    3.011536e-02    4.435328e-01                 2.0        9.0   \n",
       "54586    4.757670e-02    5.172405e-01                 2.0        9.0   \n",
       "54878    4.783370e-01    2.461585e-02                 5.0        4.0   \n",
       "56224    5.059247e-03    1.100527e-05                 4.0        5.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "11992                  1            9  \n",
       "14337                  2            7  \n",
       "14664                  6            8  \n",
       "15717                  2            3  \n",
       "17808                  3            8  \n",
       "19869                  3            7  \n",
       "20735                  0            9  \n",
       "21918                  0            6  \n",
       "21982                  7            2  \n",
       "22212                  1            6  \n",
       "22803                  0            6  \n",
       "24569                  0            6  \n",
       "26516                  8            6  \n",
       "26733                  9            2  \n",
       "26850                  7            2  \n",
       "27645                  2            3  \n",
       "28132                  7            3  \n",
       "31284                  9            7  \n",
       "33484                  0            6  \n",
       "34644                  5            3  \n",
       "36309                  3            5  \n",
       "36934                  4            9  \n",
       "37502                  8            6  \n",
       "38658                  3            5  \n",
       "41396                  4            8  \n",
       "41594                  4            9  \n",
       "43042                  9            8  \n",
       "44822                  4            9  \n",
       "48494                  7            8  \n",
       "50086                  2            6  \n",
       "50618                  8            6  \n",
       "52232                  1            9  \n",
       "53131                  5            8  \n",
       "53306                  3            5  \n",
       "53680                  7            9  \n",
       "54586                  3            9  \n",
       "54878                  1            4  \n",
       "56224                  3            5  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking_df = posterior_probs_df[(posterior_probs_df[\"given label (name)\"] != posterior_probs_df[\"true labels\"])]\n",
    "checking_df[(checking_df[\"Aled label\"] == checking_df[\"true labels\"]) & (checking_df[\"model pred labels\"] != checking_df[\"true labels\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.734830e-04</td>\n",
       "      <td>2.495620e-113</td>\n",
       "      <td>2.132880e-01</td>\n",
       "      <td>7.759419e-01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.576285e-03</td>\n",
       "      <td>6.348387e-17</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>4.065776e-07</td>\n",
       "      <td>9.245935e-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.308090e-04</td>\n",
       "      <td>2.158752e-15</td>\n",
       "      <td>4.388864e-05</td>\n",
       "      <td>7.469825e-19</td>\n",
       "      <td>0.082615</td>\n",
       "      <td>8.368808e-07</td>\n",
       "      <td>3.925786e-02</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>8.778078e-01</td>\n",
       "      <td>1.115197e-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.609320e-01</td>\n",
       "      <td>4.981734e-68</td>\n",
       "      <td>4.772575e-03</td>\n",
       "      <td>6.383826e-28</td>\n",
       "      <td>0.169279</td>\n",
       "      <td>4.186479e-02</td>\n",
       "      <td>4.024867e-06</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>1.087438e-02</td>\n",
       "      <td>2.944740e-03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.369060e-04</td>\n",
       "      <td>1.481799e-128</td>\n",
       "      <td>7.856074e-01</td>\n",
       "      <td>2.098135e-01</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.672926e-05</td>\n",
       "      <td>1.176075e-15</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>8.170328e-09</td>\n",
       "      <td>2.272453e-09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.386463e-07</td>\n",
       "      <td>4.640152e-21</td>\n",
       "      <td>2.361626e-04</td>\n",
       "      <td>6.320194e-10</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>5.568385e-05</td>\n",
       "      <td>3.948409e-04</td>\n",
       "      <td>0.115501</td>\n",
       "      <td>2.469831e-02</td>\n",
       "      <td>8.541958e-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59958</th>\n",
       "      <td>1.408244e-07</td>\n",
       "      <td>9.990704e-01</td>\n",
       "      <td>4.236850e-10</td>\n",
       "      <td>1.539638e-27</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>2.739273e-13</td>\n",
       "      <td>4.938011e-04</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.482036e-06</td>\n",
       "      <td>1.681998e-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59960</th>\n",
       "      <td>5.479534e-08</td>\n",
       "      <td>6.263755e-66</td>\n",
       "      <td>1.240379e-02</td>\n",
       "      <td>3.109172e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.766610e-01</td>\n",
       "      <td>3.725526e-15</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6.940118e-07</td>\n",
       "      <td>1.667069e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59968</th>\n",
       "      <td>3.336922e-05</td>\n",
       "      <td>1.635882e-75</td>\n",
       "      <td>8.050663e-02</td>\n",
       "      <td>4.099218e-02</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>8.760280e-01</td>\n",
       "      <td>3.074661e-13</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>1.900567e-05</td>\n",
       "      <td>1.146985e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59981</th>\n",
       "      <td>8.356487e-05</td>\n",
       "      <td>3.329801e-14</td>\n",
       "      <td>6.464941e-04</td>\n",
       "      <td>4.701677e-10</td>\n",
       "      <td>0.122039</td>\n",
       "      <td>3.749115e-04</td>\n",
       "      <td>2.570520e-02</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>7.641504e-02</td>\n",
       "      <td>3.489294e-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59984</th>\n",
       "      <td>5.652871e-06</td>\n",
       "      <td>9.997265e-01</td>\n",
       "      <td>3.959834e-13</td>\n",
       "      <td>5.198732e-42</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.074778e-19</td>\n",
       "      <td>1.023562e-04</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.396516e-07</td>\n",
       "      <td>2.608767e-12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5593 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "12       2.734830e-04   2.495620e-113    2.132880e-01    7.759419e-01   \n",
       "17       1.308090e-04    2.158752e-15    4.388864e-05    7.469825e-19   \n",
       "20       7.609320e-01    4.981734e-68    4.772575e-03    6.383826e-28   \n",
       "28       3.369060e-04   1.481799e-128    7.856074e-01    2.098135e-01   \n",
       "33       6.386463e-07    4.640152e-21    2.361626e-04    6.320194e-10   \n",
       "...               ...             ...             ...             ...   \n",
       "59958    1.408244e-07    9.990704e-01    4.236850e-10    1.539638e-27   \n",
       "59960    5.479534e-08    6.263755e-66    1.240379e-02    3.109172e-01   \n",
       "59968    3.336922e-05    1.635882e-75    8.050663e-02    4.099218e-02   \n",
       "59981    8.356487e-05    3.329801e-14    6.464941e-04    4.701677e-10   \n",
       "59984    5.652871e-06    9.997265e-01    3.959834e-13    5.198732e-42   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "12           0.000003    9.576285e-03    6.348387e-17        0.000917   \n",
       "17           0.082615    8.368808e-07    3.925786e-02        0.000032   \n",
       "20           0.169279    4.186479e-02    4.024867e-06        0.009329   \n",
       "28           0.000004    4.672926e-05    1.176075e-15        0.004192   \n",
       "33           0.004917    5.568385e-05    3.948409e-04        0.115501   \n",
       "...               ...             ...             ...             ...   \n",
       "59958        0.000232    2.739273e-13    4.938011e-04        0.000200   \n",
       "59960        0.000002    6.766610e-01    3.725526e-15        0.000013   \n",
       "59968        0.000019    8.760280e-01    3.074661e-13        0.002390   \n",
       "59981        0.122039    3.749115e-04    2.570520e-02        0.425806   \n",
       "59984        0.000118    1.074778e-19    1.023562e-04        0.000047   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "12       4.065776e-07    9.245935e-10                 4.0        3.0   \n",
       "17       8.778078e-01    1.115197e-04                 3.0        8.0   \n",
       "20       1.087438e-02    2.944740e-03                 9.0        0.0   \n",
       "28       8.170328e-09    2.272453e-09                 9.0        2.0   \n",
       "33       2.469831e-02    8.541958e-01                 4.0        9.0   \n",
       "...               ...             ...                 ...        ...   \n",
       "59958    3.482036e-06    1.681998e-09                 3.0        1.0   \n",
       "59960    6.940118e-07    1.667069e-06                 0.0        5.0   \n",
       "59968    1.900567e-05    1.146985e-05                 1.0        5.0   \n",
       "59981    7.641504e-02    3.489294e-01                 5.0        7.0   \n",
       "59984    2.396516e-07    2.608767e-12                 9.0        1.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "12                     3            3  \n",
       "17                     8            8  \n",
       "20                     4            4  \n",
       "28                     2            2  \n",
       "33                     9            9  \n",
       "...                  ...          ...  \n",
       "59958                  1            1  \n",
       "59960                  5            5  \n",
       "59968                  5            5  \n",
       "59981                  6            6  \n",
       "59984                  1            1  \n",
       "\n",
       "[5593 rows x 14 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking_df[(checking_df[\"given label (name)\"] != checking_df[\"true labels\"]) & (checking_df[\"Aled label\"] != checking_df[\"given label (name)\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.313415e-06</td>\n",
       "      <td>1.448515e-38</td>\n",
       "      <td>7.883591e-03</td>\n",
       "      <td>7.713772e-01</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>2.175485e-01</td>\n",
       "      <td>4.063427e-09</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>3.174048e-04</td>\n",
       "      <td>2.002388e-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.734830e-04</td>\n",
       "      <td>2.495620e-113</td>\n",
       "      <td>2.132880e-01</td>\n",
       "      <td>7.759419e-01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.576285e-03</td>\n",
       "      <td>6.348387e-17</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>4.065776e-07</td>\n",
       "      <td>9.245935e-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.308090e-04</td>\n",
       "      <td>2.158752e-15</td>\n",
       "      <td>4.388864e-05</td>\n",
       "      <td>7.469825e-19</td>\n",
       "      <td>0.082615</td>\n",
       "      <td>8.368808e-07</td>\n",
       "      <td>3.925786e-02</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>8.778078e-01</td>\n",
       "      <td>1.115197e-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.609320e-01</td>\n",
       "      <td>4.981734e-68</td>\n",
       "      <td>4.772575e-03</td>\n",
       "      <td>6.383826e-28</td>\n",
       "      <td>0.169279</td>\n",
       "      <td>4.186479e-02</td>\n",
       "      <td>4.024867e-06</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>1.087438e-02</td>\n",
       "      <td>2.944740e-03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.369060e-04</td>\n",
       "      <td>1.481799e-128</td>\n",
       "      <td>7.856074e-01</td>\n",
       "      <td>2.098135e-01</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.672926e-05</td>\n",
       "      <td>1.176075e-15</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>8.170328e-09</td>\n",
       "      <td>2.272453e-09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59958</th>\n",
       "      <td>1.408244e-07</td>\n",
       "      <td>9.990704e-01</td>\n",
       "      <td>4.236850e-10</td>\n",
       "      <td>1.539638e-27</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>2.739273e-13</td>\n",
       "      <td>4.938011e-04</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.482036e-06</td>\n",
       "      <td>1.681998e-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59960</th>\n",
       "      <td>5.479534e-08</td>\n",
       "      <td>6.263755e-66</td>\n",
       "      <td>1.240379e-02</td>\n",
       "      <td>3.109172e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.766610e-01</td>\n",
       "      <td>3.725526e-15</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6.940118e-07</td>\n",
       "      <td>1.667069e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59968</th>\n",
       "      <td>3.336922e-05</td>\n",
       "      <td>1.635882e-75</td>\n",
       "      <td>8.050663e-02</td>\n",
       "      <td>4.099218e-02</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>8.760280e-01</td>\n",
       "      <td>3.074661e-13</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>1.900567e-05</td>\n",
       "      <td>1.146985e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59981</th>\n",
       "      <td>8.356487e-05</td>\n",
       "      <td>3.329801e-14</td>\n",
       "      <td>6.464941e-04</td>\n",
       "      <td>4.701677e-10</td>\n",
       "      <td>0.122039</td>\n",
       "      <td>3.749115e-04</td>\n",
       "      <td>2.570520e-02</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>7.641504e-02</td>\n",
       "      <td>3.489294e-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59984</th>\n",
       "      <td>5.652871e-06</td>\n",
       "      <td>9.997265e-01</td>\n",
       "      <td>3.959834e-13</td>\n",
       "      <td>5.198732e-42</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.074778e-19</td>\n",
       "      <td>1.023562e-04</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.396516e-07</td>\n",
       "      <td>2.608767e-12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5980 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "11       1.313415e-06    1.448515e-38    7.883591e-03    7.713772e-01   \n",
       "12       2.734830e-04   2.495620e-113    2.132880e-01    7.759419e-01   \n",
       "17       1.308090e-04    2.158752e-15    4.388864e-05    7.469825e-19   \n",
       "20       7.609320e-01    4.981734e-68    4.772575e-03    6.383826e-28   \n",
       "28       3.369060e-04   1.481799e-128    7.856074e-01    2.098135e-01   \n",
       "...               ...             ...             ...             ...   \n",
       "59958    1.408244e-07    9.990704e-01    4.236850e-10    1.539638e-27   \n",
       "59960    5.479534e-08    6.263755e-66    1.240379e-02    3.109172e-01   \n",
       "59968    3.336922e-05    1.635882e-75    8.050663e-02    4.099218e-02   \n",
       "59981    8.356487e-05    3.329801e-14    6.464941e-04    4.701677e-10   \n",
       "59984    5.652871e-06    9.997265e-01    3.959834e-13    5.198732e-42   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "11           0.000969    2.175485e-01    4.063427e-09        0.001703   \n",
       "12           0.000003    9.576285e-03    6.348387e-17        0.000917   \n",
       "17           0.082615    8.368808e-07    3.925786e-02        0.000032   \n",
       "20           0.169279    4.186479e-02    4.024867e-06        0.009329   \n",
       "28           0.000004    4.672926e-05    1.176075e-15        0.004192   \n",
       "...               ...             ...             ...             ...   \n",
       "59958        0.000232    2.739273e-13    4.938011e-04        0.000200   \n",
       "59960        0.000002    6.766610e-01    3.725526e-15        0.000013   \n",
       "59968        0.000019    8.760280e-01    3.074661e-13        0.002390   \n",
       "59981        0.122039    3.749115e-04    2.570520e-02        0.425806   \n",
       "59984        0.000118    1.074778e-19    1.023562e-04        0.000047   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "11       3.174048e-04    2.002388e-04                 3.0        3.0   \n",
       "12       4.065776e-07    9.245935e-10                 4.0        3.0   \n",
       "17       8.778078e-01    1.115197e-04                 3.0        8.0   \n",
       "20       1.087438e-02    2.944740e-03                 9.0        0.0   \n",
       "28       8.170328e-09    2.272453e-09                 9.0        2.0   \n",
       "...               ...             ...                 ...        ...   \n",
       "59958    3.482036e-06    1.681998e-09                 3.0        1.0   \n",
       "59960    6.940118e-07    1.667069e-06                 0.0        5.0   \n",
       "59968    1.900567e-05    1.146985e-05                 1.0        5.0   \n",
       "59981    7.641504e-02    3.489294e-01                 5.0        7.0   \n",
       "59984    2.396516e-07    2.608767e-12                 9.0        1.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "11                     5            5  \n",
       "12                     3            3  \n",
       "17                     8            8  \n",
       "20                     4            4  \n",
       "28                     2            2  \n",
       "...                  ...          ...  \n",
       "59958                  1            1  \n",
       "59960                  5            5  \n",
       "59968                  5            5  \n",
       "59981                  6            6  \n",
       "59984                  1            1  \n",
       "\n",
       "[5980 rows x 14 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking_df[(checking_df[\"model pred labels\"] != checking_df[\"given label (name)\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.313415e-06</td>\n",
       "      <td>1.448515e-38</td>\n",
       "      <td>7.883591e-03</td>\n",
       "      <td>7.713772e-01</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>2.175485e-01</td>\n",
       "      <td>4.063427e-09</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>3.174048e-04</td>\n",
       "      <td>2.002388e-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.734830e-04</td>\n",
       "      <td>2.495620e-113</td>\n",
       "      <td>2.132880e-01</td>\n",
       "      <td>7.759419e-01</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.576285e-03</td>\n",
       "      <td>6.348387e-17</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>4.065776e-07</td>\n",
       "      <td>9.245935e-10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.308090e-04</td>\n",
       "      <td>2.158752e-15</td>\n",
       "      <td>4.388864e-05</td>\n",
       "      <td>7.469825e-19</td>\n",
       "      <td>0.082615</td>\n",
       "      <td>8.368808e-07</td>\n",
       "      <td>3.925786e-02</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>8.778078e-01</td>\n",
       "      <td>1.115197e-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.609320e-01</td>\n",
       "      <td>4.981734e-68</td>\n",
       "      <td>4.772575e-03</td>\n",
       "      <td>6.383826e-28</td>\n",
       "      <td>0.169279</td>\n",
       "      <td>4.186479e-02</td>\n",
       "      <td>4.024867e-06</td>\n",
       "      <td>0.009329</td>\n",
       "      <td>1.087438e-02</td>\n",
       "      <td>2.944740e-03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.369060e-04</td>\n",
       "      <td>1.481799e-128</td>\n",
       "      <td>7.856074e-01</td>\n",
       "      <td>2.098135e-01</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.672926e-05</td>\n",
       "      <td>1.176075e-15</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>8.170328e-09</td>\n",
       "      <td>2.272453e-09</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59958</th>\n",
       "      <td>1.408244e-07</td>\n",
       "      <td>9.990704e-01</td>\n",
       "      <td>4.236850e-10</td>\n",
       "      <td>1.539638e-27</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>2.739273e-13</td>\n",
       "      <td>4.938011e-04</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.482036e-06</td>\n",
       "      <td>1.681998e-09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59960</th>\n",
       "      <td>5.479534e-08</td>\n",
       "      <td>6.263755e-66</td>\n",
       "      <td>1.240379e-02</td>\n",
       "      <td>3.109172e-01</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.766610e-01</td>\n",
       "      <td>3.725526e-15</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6.940118e-07</td>\n",
       "      <td>1.667069e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59968</th>\n",
       "      <td>3.336922e-05</td>\n",
       "      <td>1.635882e-75</td>\n",
       "      <td>8.050663e-02</td>\n",
       "      <td>4.099218e-02</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>8.760280e-01</td>\n",
       "      <td>3.074661e-13</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>1.900567e-05</td>\n",
       "      <td>1.146985e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59981</th>\n",
       "      <td>8.356487e-05</td>\n",
       "      <td>3.329801e-14</td>\n",
       "      <td>6.464941e-04</td>\n",
       "      <td>4.701677e-10</td>\n",
       "      <td>0.122039</td>\n",
       "      <td>3.749115e-04</td>\n",
       "      <td>2.570520e-02</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>7.641504e-02</td>\n",
       "      <td>3.489294e-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59984</th>\n",
       "      <td>5.652871e-06</td>\n",
       "      <td>9.997265e-01</td>\n",
       "      <td>3.959834e-13</td>\n",
       "      <td>5.198732e-42</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.074778e-19</td>\n",
       "      <td>1.023562e-04</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.396516e-07</td>\n",
       "      <td>2.608767e-12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5812 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "11       1.313415e-06    1.448515e-38    7.883591e-03    7.713772e-01   \n",
       "12       2.734830e-04   2.495620e-113    2.132880e-01    7.759419e-01   \n",
       "17       1.308090e-04    2.158752e-15    4.388864e-05    7.469825e-19   \n",
       "20       7.609320e-01    4.981734e-68    4.772575e-03    6.383826e-28   \n",
       "28       3.369060e-04   1.481799e-128    7.856074e-01    2.098135e-01   \n",
       "...               ...             ...             ...             ...   \n",
       "59958    1.408244e-07    9.990704e-01    4.236850e-10    1.539638e-27   \n",
       "59960    5.479534e-08    6.263755e-66    1.240379e-02    3.109172e-01   \n",
       "59968    3.336922e-05    1.635882e-75    8.050663e-02    4.099218e-02   \n",
       "59981    8.356487e-05    3.329801e-14    6.464941e-04    4.701677e-10   \n",
       "59984    5.652871e-06    9.997265e-01    3.959834e-13    5.198732e-42   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "11           0.000969    2.175485e-01    4.063427e-09        0.001703   \n",
       "12           0.000003    9.576285e-03    6.348387e-17        0.000917   \n",
       "17           0.082615    8.368808e-07    3.925786e-02        0.000032   \n",
       "20           0.169279    4.186479e-02    4.024867e-06        0.009329   \n",
       "28           0.000004    4.672926e-05    1.176075e-15        0.004192   \n",
       "...               ...             ...             ...             ...   \n",
       "59958        0.000232    2.739273e-13    4.938011e-04        0.000200   \n",
       "59960        0.000002    6.766610e-01    3.725526e-15        0.000013   \n",
       "59968        0.000019    8.760280e-01    3.074661e-13        0.002390   \n",
       "59981        0.122039    3.749115e-04    2.570520e-02        0.425806   \n",
       "59984        0.000118    1.074778e-19    1.023562e-04        0.000047   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "11       3.174048e-04    2.002388e-04                 3.0        3.0   \n",
       "12       4.065776e-07    9.245935e-10                 4.0        3.0   \n",
       "17       8.778078e-01    1.115197e-04                 3.0        8.0   \n",
       "20       1.087438e-02    2.944740e-03                 9.0        0.0   \n",
       "28       8.170328e-09    2.272453e-09                 9.0        2.0   \n",
       "...               ...             ...                 ...        ...   \n",
       "59958    3.482036e-06    1.681998e-09                 3.0        1.0   \n",
       "59960    6.940118e-07    1.667069e-06                 0.0        5.0   \n",
       "59968    1.900567e-05    1.146985e-05                 1.0        5.0   \n",
       "59981    7.641504e-02    3.489294e-01                 5.0        7.0   \n",
       "59984    2.396516e-07    2.608767e-12                 9.0        1.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "11                     5            5  \n",
       "12                     3            3  \n",
       "17                     8            8  \n",
       "20                     4            4  \n",
       "28                     2            2  \n",
       "...                  ...          ...  \n",
       "59958                  1            1  \n",
       "59960                  5            5  \n",
       "59968                  5            5  \n",
       "59981                  6            6  \n",
       "59984                  1            1  \n",
       "\n",
       "[5812 rows x 14 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checking_df[(checking_df[\"model pred labels\"] == checking_df[\"true labels\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.994484e-06</td>\n",
       "      <td>1.425344e-88</td>\n",
       "      <td>4.525460e-02</td>\n",
       "      <td>2.914956e-02</td>\n",
       "      <td>5.087696e-07</td>\n",
       "      <td>9.254864e-01</td>\n",
       "      <td>1.868124e-17</td>\n",
       "      <td>9.750478e-05</td>\n",
       "      <td>7.416739e-06</td>\n",
       "      <td>3.664137e-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.894261e-01</td>\n",
       "      <td>3.289228e-24</td>\n",
       "      <td>2.945764e-07</td>\n",
       "      <td>1.552987e-42</td>\n",
       "      <td>1.534656e-02</td>\n",
       "      <td>4.241667e-09</td>\n",
       "      <td>9.503997e-02</td>\n",
       "      <td>1.042224e-07</td>\n",
       "      <td>1.869386e-04</td>\n",
       "      <td>6.980511e-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.587006e-02</td>\n",
       "      <td>8.648416e-27</td>\n",
       "      <td>5.024709e-02</td>\n",
       "      <td>4.228416e-10</td>\n",
       "      <td>3.615738e-01</td>\n",
       "      <td>1.877209e-02</td>\n",
       "      <td>2.180250e-02</td>\n",
       "      <td>1.476694e-02</td>\n",
       "      <td>4.996565e-01</td>\n",
       "      <td>7.311073e-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.619604e-07</td>\n",
       "      <td>9.997735e-01</td>\n",
       "      <td>6.832654e-12</td>\n",
       "      <td>7.724481e-37</td>\n",
       "      <td>3.312210e-05</td>\n",
       "      <td>2.502205e-18</td>\n",
       "      <td>1.790781e-04</td>\n",
       "      <td>1.362546e-05</td>\n",
       "      <td>8.083372e-08</td>\n",
       "      <td>1.896149e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.821214e-04</td>\n",
       "      <td>1.909752e-35</td>\n",
       "      <td>1.766941e-02</td>\n",
       "      <td>1.157720e-14</td>\n",
       "      <td>6.992237e-03</td>\n",
       "      <td>1.745821e-05</td>\n",
       "      <td>7.405138e-04</td>\n",
       "      <td>2.518708e-03</td>\n",
       "      <td>9.810380e-02</td>\n",
       "      <td>8.737758e-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>1.246863e-04</td>\n",
       "      <td>1.056369e-11</td>\n",
       "      <td>1.314167e-03</td>\n",
       "      <td>3.912042e-13</td>\n",
       "      <td>1.264216e-01</td>\n",
       "      <td>7.595670e-04</td>\n",
       "      <td>9.316682e-02</td>\n",
       "      <td>9.239334e-02</td>\n",
       "      <td>3.098150e-01</td>\n",
       "      <td>3.760048e-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>4.190393e-05</td>\n",
       "      <td>1.673895e-94</td>\n",
       "      <td>3.168869e-02</td>\n",
       "      <td>9.271175e-01</td>\n",
       "      <td>1.605972e-06</td>\n",
       "      <td>4.071756e-02</td>\n",
       "      <td>6.017904e-16</td>\n",
       "      <td>4.321706e-04</td>\n",
       "      <td>5.456811e-07</td>\n",
       "      <td>1.806257e-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>2.468189e-03</td>\n",
       "      <td>2.164803e-61</td>\n",
       "      <td>1.190551e-01</td>\n",
       "      <td>2.497795e-03</td>\n",
       "      <td>2.562898e-04</td>\n",
       "      <td>8.737391e-01</td>\n",
       "      <td>3.824165e-09</td>\n",
       "      <td>9.989200e-04</td>\n",
       "      <td>9.843031e-04</td>\n",
       "      <td>3.199554e-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>1.565787e-01</td>\n",
       "      <td>7.656495e-36</td>\n",
       "      <td>1.814124e-02</td>\n",
       "      <td>1.257741e-16</td>\n",
       "      <td>5.833353e-01</td>\n",
       "      <td>3.829435e-04</td>\n",
       "      <td>5.166533e-02</td>\n",
       "      <td>3.965610e-03</td>\n",
       "      <td>1.716500e-01</td>\n",
       "      <td>1.428087e-02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>5.331295e-05</td>\n",
       "      <td>4.221030e-17</td>\n",
       "      <td>4.289579e-03</td>\n",
       "      <td>1.531420e-08</td>\n",
       "      <td>7.237405e-02</td>\n",
       "      <td>7.286495e-04</td>\n",
       "      <td>2.104197e-02</td>\n",
       "      <td>7.395199e-02</td>\n",
       "      <td>1.788303e-01</td>\n",
       "      <td>6.487302e-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58551 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "0        3.994484e-06    1.425344e-88    4.525460e-02    2.914956e-02   \n",
       "1        8.894261e-01    3.289228e-24    2.945764e-07    1.552987e-42   \n",
       "2        2.587006e-02    8.648416e-27    5.024709e-02    4.228416e-10   \n",
       "3        5.619604e-07    9.997735e-01    6.832654e-12    7.724481e-37   \n",
       "4        1.821214e-04    1.909752e-35    1.766941e-02    1.157720e-14   \n",
       "...               ...             ...             ...             ...   \n",
       "59995    1.246863e-04    1.056369e-11    1.314167e-03    3.912042e-13   \n",
       "59996    4.190393e-05    1.673895e-94    3.168869e-02    9.271175e-01   \n",
       "59997    2.468189e-03    2.164803e-61    1.190551e-01    2.497795e-03   \n",
       "59998    1.565787e-01    7.656495e-36    1.814124e-02    1.257741e-16   \n",
       "59999    5.331295e-05    4.221030e-17    4.289579e-03    1.531420e-08   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "0        5.087696e-07    9.254864e-01    1.868124e-17    9.750478e-05   \n",
       "1        1.534656e-02    4.241667e-09    9.503997e-02    1.042224e-07   \n",
       "2        3.615738e-01    1.877209e-02    2.180250e-02    1.476694e-02   \n",
       "3        3.312210e-05    2.502205e-18    1.790781e-04    1.362546e-05   \n",
       "4        6.992237e-03    1.745821e-05    7.405138e-04    2.518708e-03   \n",
       "...               ...             ...             ...             ...   \n",
       "59995    1.264216e-01    7.595670e-04    9.316682e-02    9.239334e-02   \n",
       "59996    1.605972e-06    4.071756e-02    6.017904e-16    4.321706e-04   \n",
       "59997    2.562898e-04    8.737391e-01    3.824165e-09    9.989200e-04   \n",
       "59998    5.833353e-01    3.829435e-04    5.166533e-02    3.965610e-03   \n",
       "59999    7.237405e-02    7.286495e-04    2.104197e-02    7.395199e-02   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "0        7.416739e-06    3.664137e-08                 5.0        5.0   \n",
       "1        1.869386e-04    6.980511e-13                 0.0        0.0   \n",
       "2        4.996565e-01    7.311073e-03                 4.0        4.0   \n",
       "3        8.083372e-08    1.896149e-11                 1.0        1.0   \n",
       "4        9.810380e-02    8.737758e-01                 9.0        9.0   \n",
       "...               ...             ...                 ...        ...   \n",
       "59995    3.098150e-01    3.760048e-01                 8.0        8.0   \n",
       "59996    5.456811e-07    1.806257e-08                 3.0        3.0   \n",
       "59997    9.843031e-04    3.199554e-07                 5.0        5.0   \n",
       "59998    1.716500e-01    1.428087e-02                 6.0        4.0   \n",
       "59999    1.788303e-01    6.487302e-01                 8.0        9.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "0                      5            5  \n",
       "1                      0            0  \n",
       "2                      4            4  \n",
       "3                      1            1  \n",
       "4                      9            9  \n",
       "...                  ...          ...  \n",
       "59995                  8            8  \n",
       "59996                  3            3  \n",
       "59997                  5            5  \n",
       "59998                  6            6  \n",
       "59999                  8            8  \n",
       "\n",
       "[58551 rows x 14 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_probs_df[posterior_probs_df[\"model pred labels\"] == posterior_probs_df[\"true labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.738387e-05</td>\n",
       "      <td>2.188596e-89</td>\n",
       "      <td>0.097686</td>\n",
       "      <td>8.994777e-01</td>\n",
       "      <td>1.554034e-05</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>2.197961e-14</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>9.429386e-07</td>\n",
       "      <td>4.021167e-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.412664e-04</td>\n",
       "      <td>2.464885e-19</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>3.936592e-10</td>\n",
       "      <td>2.909750e-01</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>2.206852e-02</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>6.777124e-01</td>\n",
       "      <td>1.112020e-03</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.262939e-04</td>\n",
       "      <td>5.570471e-62</td>\n",
       "      <td>0.104290</td>\n",
       "      <td>7.821591e-01</td>\n",
       "      <td>5.878870e-04</td>\n",
       "      <td>0.092843</td>\n",
       "      <td>6.523039e-10</td>\n",
       "      <td>0.019539</td>\n",
       "      <td>1.086663e-04</td>\n",
       "      <td>4.639350e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.747888e-08</td>\n",
       "      <td>4.613171e-27</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>9.044125e-01</td>\n",
       "      <td>4.000819e-03</td>\n",
       "      <td>0.036459</td>\n",
       "      <td>1.976344e-06</td>\n",
       "      <td>0.042549</td>\n",
       "      <td>1.602044e-04</td>\n",
       "      <td>6.769759e-03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.454744e-02</td>\n",
       "      <td>7.266596e-16</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>9.829198e-19</td>\n",
       "      <td>3.693660e-01</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>2.512173e-01</td>\n",
       "      <td>0.131444</td>\n",
       "      <td>1.503722e-01</td>\n",
       "      <td>7.193147e-02</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59983</th>\n",
       "      <td>5.598403e-05</td>\n",
       "      <td>2.588437e-111</td>\n",
       "      <td>0.107872</td>\n",
       "      <td>8.905200e-01</td>\n",
       "      <td>1.315930e-06</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>8.602708e-18</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>9.534556e-08</td>\n",
       "      <td>3.541492e-10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59985</th>\n",
       "      <td>3.988798e-05</td>\n",
       "      <td>1.222788e-117</td>\n",
       "      <td>0.067728</td>\n",
       "      <td>2.808243e-01</td>\n",
       "      <td>3.299403e-08</td>\n",
       "      <td>0.651402</td>\n",
       "      <td>6.174675e-19</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.224836e-07</td>\n",
       "      <td>1.450772e-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59988</th>\n",
       "      <td>1.558823e-04</td>\n",
       "      <td>1.079368e-31</td>\n",
       "      <td>0.056512</td>\n",
       "      <td>3.807482e-01</td>\n",
       "      <td>5.806706e-02</td>\n",
       "      <td>0.297612</td>\n",
       "      <td>1.142505e-05</td>\n",
       "      <td>0.179596</td>\n",
       "      <td>8.990364e-03</td>\n",
       "      <td>1.830745e-02</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>1.565787e-01</td>\n",
       "      <td>7.656495e-36</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>1.257741e-16</td>\n",
       "      <td>5.833353e-01</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>5.166533e-02</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>1.716500e-01</td>\n",
       "      <td>1.428087e-02</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>5.331295e-05</td>\n",
       "      <td>4.221030e-17</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>1.531420e-08</td>\n",
       "      <td>7.237405e-02</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>2.104197e-02</td>\n",
       "      <td>0.073952</td>\n",
       "      <td>1.788303e-01</td>\n",
       "      <td>6.487302e-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12779 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "5        5.738387e-05    2.188596e-89        0.097686    8.994777e-01   \n",
       "18       8.412664e-04    2.464885e-19        0.004320    3.936592e-10   \n",
       "24       4.262939e-04    5.570471e-62        0.104290    7.821591e-01   \n",
       "29       6.747888e-08    4.613171e-27        0.005647    9.044125e-01   \n",
       "31       2.454744e-02    7.266596e-16        0.000902    9.829198e-19   \n",
       "...               ...             ...             ...             ...   \n",
       "59983    5.598403e-05   2.588437e-111        0.107872    8.905200e-01   \n",
       "59985    3.988798e-05   1.222788e-117        0.067728    2.808243e-01   \n",
       "59988    1.558823e-04    1.079368e-31        0.056512    3.807482e-01   \n",
       "59998    1.565787e-01    7.656495e-36        0.018141    1.257741e-16   \n",
       "59999    5.331295e-05    4.221030e-17        0.004290    1.531420e-08   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "5        1.554034e-05        0.000824    2.197961e-14        0.001939   \n",
       "18       2.909750e-01        0.000833    2.206852e-02        0.002138   \n",
       "24       5.878870e-04        0.092843    6.523039e-10        0.019539   \n",
       "29       4.000819e-03        0.036459    1.976344e-06        0.042549   \n",
       "31       3.693660e-01        0.000219    2.512173e-01        0.131444   \n",
       "...               ...             ...             ...             ...   \n",
       "59983    1.315930e-06        0.001008    8.602708e-18        0.000542   \n",
       "59985    3.299403e-08        0.651402    6.174675e-19        0.000006   \n",
       "59988    5.806706e-02        0.297612    1.142505e-05        0.179596   \n",
       "59998    5.833353e-01        0.000383    5.166533e-02        0.003966   \n",
       "59999    7.237405e-02        0.000729    2.104197e-02        0.073952   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "5        9.429386e-07    4.021167e-08                 2.0        3.0   \n",
       "18       6.777124e-01    1.112020e-03                 6.0        8.0   \n",
       "24       1.086663e-04    4.639350e-05                 1.0        3.0   \n",
       "29       1.602044e-04    6.769759e-03                 7.0        3.0   \n",
       "31       1.503722e-01    7.193147e-02                 8.0        4.0   \n",
       "...               ...             ...                 ...        ...   \n",
       "59983    9.534556e-08    3.541492e-10                 2.0        3.0   \n",
       "59985    3.224836e-07    1.450772e-12                 2.0        5.0   \n",
       "59988    8.990364e-03    1.830745e-02                 7.0        3.0   \n",
       "59998    1.716500e-01    1.428087e-02                 6.0        4.0   \n",
       "59999    1.788303e-01    6.487302e-01                 8.0        9.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "5                      2            2  \n",
       "18                     6            6  \n",
       "24                     2            1  \n",
       "29                     7            7  \n",
       "31                     8            8  \n",
       "...                  ...          ...  \n",
       "59983                  2            2  \n",
       "59985                  2            2  \n",
       "59988                  7            7  \n",
       "59998                  6            6  \n",
       "59999                  8            8  \n",
       "\n",
       "[12779 rows x 14 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_probs_df[(posterior_probs_df[\"Aled label\"] != posterior_probs_df[\"given label (name)\"]) & (posterior_probs_df[\"given label (name)\"] == posterior_probs_df[\"true labels\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142588084777116"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aled.pca_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aled.num_pca_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9420924135802469\n",
      "Threshold for best F1: 0.9932597320484021\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_ROC(df_Y, df_X, title=None, plot_f1_max=True):\n",
    "  fpr, tpr, thresholds = sklearn.metrics.roc_curve(df_Y, df_X)\n",
    "  # print(thresholds)\n",
    "  auc = sklearn.metrics.roc_auc_score(df_Y, df_X)\n",
    "  plt.plot(fpr, tpr, scaley=False, scalex=False)\n",
    "  plt.plot((0,1), linestyle='dashed')\n",
    "  plt.title(f\"ROC Curve of method {title}; AUC={auc:.3f}\")\n",
    "  plt.xlabel(\"False Positive Rate\")\n",
    "  plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "  # plot max f1\n",
    "  if plot_f1_max:\n",
    "    f1_max, threshold_f1_max = find_best_F1(df_Y, df_X, ret=True)\n",
    "    print(\"Threshold for best F1:\", threshold_f1_max)\n",
    "    fpr_f1_max, tpr_f1_max = fpr[thresholds==threshold_f1_max], tpr[thresholds==threshold_f1_max]\n",
    "    plt.scatter(fpr_f1_max, tpr_f1_max)\n",
    "    plt.text(fpr_f1_max * (1 + 0.01), tpr_f1_max * (1 + 0.01) , f'F1_max={f1_max:.2f}', fontsize=12)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "plot_ROC(posterior_probs_df[\"given label (name)\"] != posterior_probs_df[\"true labels\"], 1 - posterior_probs_df.apply(lambda row: row.iloc[int(row[\"given label (name)\"])], axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8376455370370371\n",
      "Threshold for best F1: 640.5018280590868\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/N0lEQVR4nO3deZzM9R/A8dfM7M7eh7V2LdZ9H1lH5A6bI2dyFLkK5SiRCpWroiKpiBAqikTxiyhKjpTCily5cu6y1t73zOf3x9hh2l121+x+d2ffz8djHub7mc/3O+/5Yue9n1OnlFIIIYQQQjgIvdYBCCGEEELYkyQ3QgghhHAoktwIIYQQwqFIciOEEEIIhyLJjRBCCCEciiQ3QgghhHAoktwIIYQQwqFIciOEEEIIhyLJjRBCCCEciiQ3Qji4zz//nJo1a+Ls7Iyvr6/W4dzRkCFD8PT0LJD30ul0TJs2rUDeSwhRsCS5EXmyYsUKdDqd9eHk5ETZsmUZMmQIly5dyvIcpRSff/45rVu3xtfXF3d3d+rVq8eMGTNISEjI9r2++eYbOnfujL+/P0ajkTJlytC3b19++umnHMWanJzMe++9R9OmTfHx8cHV1ZXq1aszZswYTp48mafPX1QcP36cIUOGUKVKFZYsWcLixYu1DonExESmTZvGjh07tA7lrs6dO2f9N75u3bpMr0+bNg2dTkdkZKQG0dlPkyZN0Ol0LFy4MMvX7/Y569aty4MPPpipPDY2lunTp1O/fn08PT1xc3Ojbt26vPzyy1y+fNkusR87doxOnTrh6emJn58fAwcO5Nq1azk6Nzk5mVmzZlG7dm3c3d0pW7Ysffr04e+//7apt3PnTrp3705wcDCurq6ULl2aTp06sWfPnkzXNJvNLFq0iJCQEDw9PQkMDKRz5878+uuvdvm8ImectA5AFG0zZsygUqVKJCcn89tvv7FixQp2797NkSNHcHV1tdYzmUz079+fr776ilatWjFt2jTc3d3ZtWsX06dPZ+3atWzbto3AwEDrOUopnnzySVasWEGDBg0YP348pUuX5sqVK3zzzTe0b9+ePXv20Lx582zji4yMpFOnTuzfv5+uXbvSv39/PD09OXHiBKtXr2bx4sWkpqbm6z3S0o4dOzCbzbz//vtUrVpV63AAS3Izffp0gCy/EAurGTNm0KtXL3Q6ndah2NU///zDH3/8QcWKFVm1ahUjR460y3XPnDlDaGgo58+fp0+fPowYMQKj0chff/3FJ598wjfffHPPv1xcvHiR1q1b4+Pjw8yZM4mPj2fOnDkcPnyYffv2YTQa73j+gAED2LhxI8OHD6dhw4ZcvnyZBQsW0KxZMw4fPkyFChUAOHnyJHq9nmeeeYbSpUtz48YNVq5cSevWrdm0aROdOnWyXvPFF19k7ty5PPHEE4waNYro6Gg+/vhj2rRpw549e2jSpMk9fWaRQ0qIPFi+fLkC1B9//GFT/vLLLytArVmzxqZ85syZClATJkzIdK2NGzcqvV6vOnXqZFM+e/ZsBajnn39emc3mTOd99tln6vfff79jnF26dFF6vV59/fXXmV5LTk5WL7zwwh3Pz6m0tDSVkpJil2vZ0/Tp0xWgrl27pnUoVteuXVOAmjp1aqbXBg8erDw8PAokjuxiuN3Zs2cVoEJCQhSg1q1bZ/P61KlTC939za0pU6aogIAAtW7dOqXT6dTZs2cz1bnb56xTp45q06aN9TgtLU3Vr19fubu7q127dmWqHxMToyZPnnzPsY8cOVK5ubmpf//911r2448/KkB9/PHHdzz34sWLWf5M+umnnxSg5s6de8fzExISVGBgoOrYsaO1LC0tTbm5uanevXvb1D1z5owC1HPPPZfTjybukXRLCbtq1aoVAKdPn7aWJSUlMXv2bKpXr86sWbMyndOtWzcGDx7Mli1b+O2336znzJo1i5o1azJnzpwsf1seOHDgHX8L+v3339m0aRNPPfUUjz76aKbXXVxcmDNnjvX4wQcfzLIlYciQIVSsWNF6nNFVMWfOHObNm0eVKlVwcXHh4MGDODk5WVslbnfixAl0Oh3z58+3lkVHR/P8888THByMi4sLVatW5e2338ZsNmf7mW730UcfUadOHVxcXChTpgyjR48mOjra+nrFihWZOnUqAKVKlbrrGJOM8S7nz5+na9eueHp6UrZsWRYsWADA4cOHadeuHR4eHlSoUIEvvvgi0zXu9pnOnTtHqVKlAJg+fbq1y+e/cV26dImePXvi6elJqVKlmDBhAiaTyaZOQkICL7zwgvW9atSowZw5c1BK2dRLSUlh3LhxlCpVCi8vL7p3787FixdzdI8zPPbYY1SvXp0ZM2Zkun5W1q5dS6NGjXBzc8Pf358nnngiU3dtxv3OyWc1m83MmzePOnXq4OrqSmBgIE8//TQ3btywqRcTE8Px48eJiYnJ8Wf74osv6N27N127dsXHxyfLv9fcWrduHYcOHeKVV16hZcuWmV739vbmzTfftMv7dO3alfLly1vLQkNDqV69Ol999dUdz42LiwOwaS0GCAoKAsDNze2O57u7u1OqVCmb/3NpaWkkJSVlumZAQAB6vf6u1xT2I8mNsKtz584BUKJECWvZ7t27uXHjBv3798fJKeue0EGDBgHw3XffWc+Jioqif//+GAyGPMWyceNGwJIE5Yfly5fz4YcfMmLECN59912CgoJo06ZNlj9U16xZg8FgoE+fPoCla6ZNmzasXLmSQYMG8cEHH9CiRQsmTZrE+PHj7/re06ZNY/To0ZQpU4Z3332XRx99lI8//pgOHTqQlpYGwLx583jkkUcAWLhwIZ9//jm9evW643VNJhOdO3cmODiYd955h4oVKzJmzBhWrFhBp06daNy4MW+//TZeXl4MGjSIs2fPWs/NyWcqVaqUdVzHI488wueff54pLpPJRMeOHSlZsiRz5syhTZs2vPvuuzbjhZRSdO/enffee49OnToxd+5catSowYsvvpjp/g0bNox58+bRoUMH3nrrLZydnenSpctd7/HtDAYDr776KocOHeKbb765Y90VK1bQt29fDAYDs2bNYvjw4axfv56WLVvafBHm9LMCPP3007z44ou0aNGC999/n6FDh7Jq1So6duxo/fsGy/i0WrVq3TXGDL///junTp3i8ccfx2g00qtXL1atWpWzm3IHuf2/l5iYSGRk5F0ftydzly5d4urVqzRu3DjT9Zo0acLBgwfv+J5VqlShXLlyvPvuu/zvf//j4sWL7Nu3j2eeeYZKlSrx2GOPZTonNjaWyMhIjh8/zuTJkzly5Ajt27e3vu7m5kbTpk1ZsWIFq1at4vz58/z1118MGTKEEiVKMGLEiBzdD2EHGrcciSIqo1tq27Zt6tq1a+rChQvq66+/VqVKlVIuLi7qwoUL1rrz5s1TgPrmm2+yvV5UVJQCVK9evZRSSr3//vt3PeduHnnkEQWoGzdu5Kh+mzZtbJrWMwwePFhVqFDBepzRVeHt7a2uXr1qU/fjjz9WgDp8+LBNee3atVW7du2sx6+//rry8PBQJ0+etKk3ceJEZTAY1Pnz57ON8+rVq8poNKoOHTook8lkLZ8/f74C1LJly6xluek2GTx4sALUzJkzrWU3btxQbm5uSqfTqdWrV1vLjx8/nqlbJ6ef6W7dUoCaMWOGTXmDBg1Uo0aNrMfffvutAtQbb7xhU693795Kp9OpU6dOKaWUCgsLU4AaNWqUTb3+/fvnqltq9uzZKj09XVWrVk3Vr1/f2k363/ubmpqqAgICVN26dVVSUpL1Ot99950C1JQpU3L9WXft2qUAtWrVKpt6W7ZsyVSe8f9y+fLld/xcGcaMGaOCg4Otn+eHH35QgDp48KBNvdx2SzVo0ED5+PjkKIbbr3+3x+3/D//44w8FqM8++yzT9V588UUFqOTk5Du+7++//66qVKli8x6NGjVSV65cybJ+x44drfWMRqN6+umnbf6elVLqn3/+UQ0bNrS5ZuXKldXx48dzfD/EvZOWG3FPQkNDKVWqFMHBwfTu3RsPDw82btxIuXLlrHUymn+9vLyyvU7Ga7GxsTZ/3umcu7HHNe7k0UcftXaxZOjVqxdOTk6sWbPGWnbkyBGOHj1Kv379rGVr166lVatWlChRwuY309DQUEwmEzt37sz2fbdt20ZqairPP/88ev2t/8LDhw/H29ubTZs23dPnGjZsmPW5r68vNWrUwMPDg759+1rLa9Soga+vL2fOnLHLZ/qvZ555xua4VatWNu+1efNmDAYDzz33nE29F154AaUU33//vbUekKne888/n+NYMtzeevPtt99mWefPP//k6tWrjBo1ymZAfZcuXahZs2aWfzd3+6xr167Fx8eHhx56yOa+NmrUCE9PT37++Wdr3SFDhqCUYsiQIXf9POnp6axZs4Z+/fpZu33btWtHQEDAPbfexMbG5ur/3aBBg/jxxx/v+rg9rqSkJMDSvfxfGfc+o052SpQoQUhICBMnTuTbb79lzpw5nDt3jj59+pCcnJyp/ltvvcUPP/zAJ598wgMPPEBqairp6ek2dby8vKhTpw6jR49m/fr1fPTRR6Snp9OzZ88iP6uuKJHZUuKeLFiwgOrVqxMTE8OyZcvYuXNnph82GT/kMpKcrPw3AfL29r7rOXdz+zXyY32XSpUqZSrz9/enffv2fPXVV7z++uuApUvKycnJpuvln3/+4a+//sqUHGW4evVqtu/777//ApYE43ZGo5HKlStbX88LV1fXTDH5+PhQrly5TOOefHx8bLoJ7uUz3S2GEiVK2LzXv//+S5kyZTJ9gdaqVcv6esafer2eKlWq2NT7773LqQEDBvD6668zY8YMevbsmen17P5uAGrWrMnu3bttynLyWf/55x9iYmIICAjIMqac3tf/+uGHH7h27RpNmjTh1KlT1vK2bdvy5Zdf8vbbb9skz3dz+78Pb29vmwTtbipXrkzlypVzXB9ujYlJSUnJ9FpGYnKnMS4xMTG0atWKF198kRdeeMFa3rhxYx588EGWL1+eaeZYSEiI9fkTTzxBw4YNGTJkCF9//TVgSRhDQ0N58MEH+fDDD611Q0NDqVOnDrNnz+btt9/O1ecUeSPJjbgnTZo0sfZ59+zZk5YtW9K/f39OnDhhXYwt4wvnr7/+yvILIeM1gNq1awOWLwKwDGLN7py7uf0aGQOd70Sn02U5WPS/gzszZPeD87HHHmPo0KGEhYUREhLCV199Rfv27fH397fWMZvNPPTQQ7z00ktZXqN69ep3jTc/ZDe+Kbvy2++XvT5TXsdYFYSM1pshQ4awYcMGu1zvbsxm8x1bU7JLJu8m43q3t8jd7pdffqFt27bA3VtCEhMTbVqqatasycGDB7lw4QLBwcF3jSU+Pp74+Pi71jMYDNbPmzHw98qVK5nqXblyBT8/vyxbdTKsW7eOiIgIunfvblPepk0bvL292bNnzx2nxRuNRrp3785bb71FUlISbm5u7Ny5kyNHjjB37lybutWqVaNWrVpZrosj8od0Swm7yRhAefnyZZtZQS1btsTX15cvvvgi20Ths88+A6Br167Wc0qUKMGXX36Z7Tl3061bNwBWrlyZo/olSpTINOATyHVLSM+ePTEajaxZs4awsDBOnjyZaXBilSpViI+PJzQ0NMvH7bM//itj7Y0TJ07YlKempnL27Fnr6wUtp5/JHuvEVKhQgcuXL2dq2Tt+/Lj19Yw/zWazzew9yHzvcuOJJ56gatWqTJ8+PVMynN3fTUZZXv5uqlSpwvXr12nRokWW97V+/fq5vmZCQgIbNmygX79+rF27NtMjKCjIJpm60+dKTEzkwoULNp8tt//35syZQ1BQ0F0f999/v/WcsmXLUqpUKf78889M19u3b59NK0tWIiIigMy/vCilMJlMmbqbspKUlIRSyvrvMLtrgmUmVU6uKexDkhthVw8++CBNmjRh3rx51qZhd3d3JkyYwIkTJ3jllVcynbNp0yZWrFhBx44deeCBB6znvPzyyxw7doyXX345yxaVlStXsm/fvmxjadasGZ06dWLp0qVZjpFITU1lwoQJ1uMqVapw/Phxm9VNDx06lOvftnx9fenYsSNfffUVq1evxmg0Zmp96tu3L3v37mXr1q2Zzo+Ojr7jD8HQ0FCMRiMffPCBzX355JNPiImJyfVMIHvJ6Wdyd3e3luXVww8/jMlkskmiAd577z10Oh2dO3cGsP75wQcf2NSbN29ent87o/UmLCzMOisoQ+PGjQkICGDRokU23SXff/89x44dy9PfTd++fTGZTNZuztulp6fn6T5+8803JCQkMHr0aHr37p3p0bVrV9atW2f9DO3bt8doNLJw4cJMSxUsXryY9PR0670G6N27N/Xq1ePNN99k7969md4/Li7O5mdBXsbcgGXc23fffceFCxesZdu3b+fkyZPWmYlgSSyOHz9u08qT0ZK4evVqm2tu3LiRhIQEGjRoYC3LqusvOjqadevWERwcbO0yzO6aBw4c4MSJEzbXFPlMs6HMokjLbhE/pZRau3atAtTChQutZenp6erRRx9VgGrdurV6//331eLFi9WgQYOUXq9XderUUeHh4TbXMZlMauDAgQpQDRs2VDNnzlTLli1TM2fOVE2aNFGA+vXXX+8Y59WrV1VISIjS6XSqe/fu6v3331dLly5VL7/8sqpQoYIyGo3WukePHlV6vV41aNBAzZ8/37q4Wb169bKcLTV79uxs33flypUKUF5eXqpbt26ZXk9ISFANGzZUTk5OatiwYWrhwoVqzpw51kXs7ja7KWN2SYcOHdT8+fPVs88+qwwGg7r//vtVampqpno5nS2V1QJ6bdq0UXXq1MlUXqFCBdWlS5c8fabatWur0qVLqwULFqgvv/zSOrssuxgyPkcGk8mk2rZtq3Q6nRoxYoRasGCB6tGjh3XRx9s9/vjjClADBgxQCxYsUL169VL33XdfrmdL3S4tLc1mls3tny3j/0bTpk3VvHnz1KRJk5S7u7uqWLGizcy9nH5WpZR6+umnFaA6d+6s3nvvPTV//nw1duxYVaZMGbV27dpM73232VKdOnVSJUuWVOnp6Vm+/r///S/TooVvvPGGAlSLFi3U22+/rT788EPrvf3vzD2lLLOGKlSooJycnFT//v3VggUL1OLFi9XYsWNVqVKlVPXq1e8YY06cP39elSxZUlWpUkV98MEHaubMmapEiRKqXr16NjOlMv4eBw8ebC1LSUlRderUUTqdTg0ZMkQtWrRITZgwQbm6uqqgoCCbv9OGDRuq7t27qzfffFMtWbJEvfbaa6pcuXJKr9fb3H+llHrooYcUoB555BG1cOFCNWXKFFWiRAnl4eEhM6YKkCQ3Ik/ulNyYTCZVpUoVVaVKFZsfniaTSS1fvly1aNFCeXt7K1dXV1WnTh01ffp0FR8fn+17ff3116pDhw7Kz89POTk5qaCgINWvXz+1Y8eOHMWamJio5syZo+6//37l6empjEajqlatmnr22WetU4YzrFy5UlWuXFkZjUYVEhKitm7dmu1U8DslN7GxscrNzU0BauXKlVnWiYuLU5MmTVJVq1ZVRqNR+fv7q+bNm6s5c+bYJCjZmT9/vqpZs6ZydnZWgYGBauTIkZmmvRdkcpObz/Trr7+qRo0aKaPRaJNk5OYLPy4uTo0bN06VKVNGOTs7q2rVqqnZs2dnWs06KSlJPffcc6pkyZLKw8NDdevWTV24cOGekhulbv0fyOr+rlmzRjVo0EC5uLgoPz8/NWDAAHXx4kWbOrn5rEoptXjxYtWoUSPl5uamvLy8VL169dRLL72kLl++bK3z4YcfKkBt2bIl288UERGhnJyc1MCBA7Otk5iYqNzd3dUjjzxiU75y5Ur1wAMPKA8PD+Xi4qJq1qyppk+fnu2U6xs3bqgpU6aoevXqKXd3d+Xq6qrq1q2rJk2alO1069w6cuSI6tChg3J3d1e+vr5qwIABmX5Ryiq5UcqyBMW4ceNU9erVlYuLi/L391ePPfaYOnPmjE29+fPnq5YtWyp/f3/l5OSkSpUqpbp166Z27tyZKZ7ExEQ1Y8YMVbt2beXm5qZ8fHxU165dM02vF/lLp1QOltsUQghR6PXt25dz587dsbtWiOJAZksJIYQDUEqxY8eOHA/iFcKRScuNEEIIIRyKzJYSQgghhEOR5EYIIYQQDkWSGyGEEEI4FEluhBBCCOFQit1sKbPZzOXLl/Hy8rLLMvBCCCGEyH/q5lYXZcqUueumrsUuubl8+XKONnITQgghROFz4cIFypUrd8c6xS658fLyAiw3x9vbW+NohBBCCJETsbGxBAcHW7/H76TYJTcZXVHe3t6S3AghhBBFTE6GlMiAYiGEEEI4FEluhBBCCOFQJLkRQgghhEOR5EYIIYQQDkWSGyGEEEI4FEluhBBCCOFQJLkRQgghhEOR5EYIIYQQDkWSGyGEEEI4FEluhBBCCOFQNE1udu7cSbdu3ShTpgw6nY5vv/32rufs2LGDhg0b4uLiQtWqVVmxYkW+xymEEEKIokPT5CYhIYH69euzYMGCHNU/e/YsXbp0oW3btoSFhfH8888zbNgwtm7dms+RCiGEEKKo0HTjzM6dO9O5c+cc11+0aBGVKlXi3XffBaBWrVrs3r2b9957j44dO+ZXmEIIIYTIoT/PRVGllCclPIyaxVCkxtzs3buX0NBQm7KOHTuyd+/ebM9JSUkhNjbW5iGEEEII+1JK8cnus/Rb/Btj14RhMivNYilSyU14eDiBgYE2ZYGBgcTGxpKUlJTlObNmzcLHx8f6CA4OLohQhRBCiGIjMTqCySt/5vXvjmIyK0q4O5NmMmsWT5FKbvJi0qRJxMTEWB8XLlzQOiQhhBDCYVw5tJ3E9x+gy8lXMeoV07rVZl6/EFydDZrFpOmYm9wqXbo0ERERNmURERF4e3vj5uaW5TkuLi64uLgURHhCCCFE8WE2c2r9DCodnodBpyhrcOOrx6sSUruS1pEVreSmWbNmbN682absxx9/pFmzZhpFJIQQQhQ/ptgILnwykKoxv4MOdri2p86wJVTyL6l1aIDG3VLx8fGEhYURFhYGWKZ6h4WFcf78ecDSpTRo0CBr/WeeeYYzZ87w0ksvcfz4cT766CO++uorxo0bp0X4QgghRLETd3Q7cfMeoGLM7yQqF76t+CotXvyaUoUksQGNW27+/PNP2rZtaz0eP348AIMHD2bFihVcuXLFmugAVKpUiU2bNjFu3Djef/99ypUrx9KlS2UauBBCCFEADp+/jufa56ikovhHleNC+4/o2bqN1mFlolNKaTdXSwOxsbH4+PgQExODt7e31uEIIYQQRcJXf1zg1Q1HqGI6yzMev1Bz8AfUCA68+4l2kpvv7yI15kYIIYQQBSv1xI98t3MfL50OAaBsrft5sO9wfNyctQ3sDiS5EUIIIURmpnTitszA448P6Kr0LNPPoFNoR0Y9WBW9Xqd1dHckyY0QQgghbMVcInblILyv/QnAt7p2vDSwJ61rldM4sJyR5EYIIYQQVurkVpLXjsA7LZo45cZ8z+d44qnnCfZz1zq0HJPkRgghhBAApP4wDeOv7+EGHDZX5LsasxjXt6Omqw3nhSQ3QgghhODU1Ti27Y/mGeAzU0ecOr/JxGZV0ekK9/iarEhyI4QQQhRnqQl8fyKWCWsPkZAaykHPqjzz5AAalC+hdWR5JsmNEEIIURylp2L+4TWi/vqeF6KnkogrD1QuyZv9H8Lfs2jvySjJjRBCCFHcRJ0lbc0QnCPC8AdC9QcIavkEL3asgZNB052Z7EKSGyGEEKI4OboB0zejcU6LI1p58IoaTZfHn+ThekFaR2Y3ktwIIYQQxUFaMuqHV9H9sQQD8Ke5OnO8XuKNwZ2oGuCldXR2JcmNEEIIUQykb30Vpz+XALAwvRuHqz/Lkr4N8XItvNso5FXR71gTQgghxB1diEpkyOnWHDcHMyT1ZQidzoKBTRwysQFpuRFCCCEcU1oSHPuOna4P8tzqg0QnGhjg/i4fDGpEi6r+WkeXryS5EUIIIRzNtZOotYPRXT3KV2nPEW16gPrlfPjoiUaU9XXTOrp8J8mNEEII4UjCvkRtGo8uLZFrypsbyoPHm5RnarfaRW4bhbyS5EYIIYRwBKkJsPklCFuJDthjqsNLagxjH2lF3/uDtY6uQElyI4QQQhR1V4/B2iFw7TgmpeP99Ef5xvMxFg68n/vK+WodXYGT5EYIIYQo4tIjT+N07TgRypexaWNwrtKaDY81wM/DqHVompDkRgghhCiKlAKdjqtxyYzZWZKKacPZbmrIY20bMv6hGhj0RW83b3uR5EYIIYQoasIPw6YXOPTAXIZ/G87VuBSOuTzEnP716VintNbRaU6SGyGEEKKoUAr2L0d9PxGdKYVL58ZzNW0s1QI8+XhgIyqX8tQ6wkJBkhshhBCiKEiOhf+Nhb/XowO2mxrwStpQut4XxNuP3oeHi3ylZ5A7IYQQQhR2l8Pg66EQdYZ0DLyd1o/lqgsTu9TmqZaV0OmK7/iarEhyI4QQQhRmZ3fCykfBlMpl/Bmd8iwXPOqwsn9DHqhcUuvoCiVJboQQQohCzFymMdddynMwzocX056mSvlyfDegEaV9XLUOrdCS5EYIIYQobK4eA//qRCebeH7NEcKiXiQaTwY1q8irXWpjdNJrHWGhJsmNEEIIUVgoBb99BD9OJaLhWHofbcGFqCRcnHx495F6PNqonNYRFgmS3AghhBCFQWIUfDsKTn4PwJ/79nAhtQHBfu4seqIRdcr4aBxg0SHJjRBCCKG187/D109C7EXSdc5MS32ClaZQ2tYIYF6/Bvi4O2sdYZEiyY0QQgihFbMZfv0Ats8AZeKyoQzDE8fwt6rI2PbVGNu+GvpivI1CXklyI4QQQlNpJjOxSWlcjk4mLjkNk1KYzIqI2GQMesvAWbNSKKUwK8vzy9FJOOn11oG1Simba/7nkP8c2ryuyMW5/32fe7xuiaTzPPnXmzgpE1t0LXkhYSgGVy+WPRZCu5qBiLyR5EYIIYRVmslMSrqZqPhU0s1mTGZFTFIaqSYzaSbFhahEPFwMmM0ZCYflz5ikNKISU/EwOnE8PBaDXo9eh/V1pSxf9mYzxCSlcTYyAS9XJ/65Gq/1R9bcacNgdChWm9pSs7Q3Hw9sRIWSHlqHVaRJciOEEA5MKcXFG0mcvhbPPxHx/BuVgJerM3tORRLg5cLuU5Ekp5kp4e7MjcS0Ao0tPDbr8sr+HrgZDTjpdRwPj6NJJT+cDZZkSafTodeBXqfjfFQilfw98DBavsr+u0iv7bEu29f+2+lj+1rOzrvTCsE2LykzrcI/54z3/Vz2qHPztUoATPJyYVCzirgZDdleS+SMJDdCCKERdbP7xaQsLRompbiRkMrFG0lcvJGITqfjn6tx+LoZra0jp67G4+PmzOFLMfi5G3Ey6G61jNxsJTErRURsCpeik3IcS3aJTQl3Zwx6PZHxKdQK8kbd7BJqUL6ENcnISDhik9MwOhmoWNKd6/Gp1CvnY01K9DfrcPNPs1lhdNJTK8ibAC9X/DyMOBt0jr2NQPxVWD8CLv9Mu8TvYdRvYJQWmvwgyY0QQuSQ2axIM5uJSUrjQlQSZqVIM5m5GGVJRjxcnPjrYgw3ElPxcnXCZIbT1+ItXTAuTrgaDZhvJjPRBdxKkqG8nzulvFy4v6IfcclpNKpQAoCyvm6U8nLB3eiEr7szRoNeBrLa05lfYP1wiI8AJzdoM1ESm3wkyY0QolgwmRXRiamkmsykmyytG8lpZq7FpZBmMhOXks6FqEROX4u3tpQkpZo4cP4GiakmktNMXE9IzfP7x6WkE5eSnqtzSnu7Ui3Qk8j4VO4r64PBoMNsVjgb9FQu5UFsUjrlS7rhpNffbEHB2nWjw9JaEuTrSrUAL1nRVitmE/zyDvzyNqCgVC3oswICamodmUOT5EYIoZnkNNPNbpSbg05vDlJNSTcTn5JOutlMTGIaaSZ1cwaNmUs3knB1NmBWCtPNrpzr8SkkpKRjMkNyuomD56M5diWWkh5GdDqIjM97UnInni5OBPm4otPBlehkypZwIyTYl8RUEyU9jdQI9MKg15FmUvh5GAn2syQiBr0lATEa9Hi5OqHX6zDodBj0OpwNegzSYuIYkmNhdX84t8ty3OAJ6DwbjO7axlUMSHIjhMiR1HQzSWkmohJSLQnJze6VhJR0/jx3g5R0MyfC4/BwMXD0Siy+bkZ+P3udKqU8reNKzlxLwMVJj7NBT3wuWzHyIruWFhcnSwJh0OnwdnPGz8MydsXTxQlfdyNms6JyKQ9ra4jJrKhX1of7yvni7mLAaNDj6iyDPsVdGD3B2R2cPaDre1C/n9YRFRuS3AhRTCmluBCVRHRSKpejk9DpdKSbFP9cjePSjSS2H79KJX8PToTH3VMicjw8zuY4Jd0y1TgnSt5MOiJiLYNZnQ069DodJ8LjaF6l5K0WD4MOXzdnfNyccbL0y5BmMlOuhBv1y/lidNJbXnd3xsVJkhKRj0zpYE4DZzfQ6+GRRZB4HfyraR1ZsSLJjRAOIt1k5lJ0ErtPRXLkUixmsyI8NpmI2GTrtNo/zt2gvJ8756MSc3TNqDuMMbHMorEkG1fjUgjycaVD7UCuxadQs7Q3yWkmqgV6YjZDkI+rpaVEb2kJKenhYm0pcXEy3Bwrortt9s2dp9YKUSjFXIJ1w6BEBUtSA+DuZ3mIAiXJjRBFQFxyGqnplkXUwi5Eczk6iV9PXycmKZXYpHRORMTd/SI3ZZXYlPV143JMEvdX9MNJryM8JplK/h6U8nKhdfVS+Lg5Uy3QEx83yywaSTyE+I+TP8A3T0NSFIQfhgf/tSQ5QhOS3AhRSCilSDWZOXMtge/+uszJiHh+PBqRp2s56XU0qlCC2mW8cXU24OniRLCfO27OBpRSlPZxxdmgp0opT5lFI8S9MKVZ9oX69QPLcVB96L1cEhuNSXIjRAFLSTex/98brPrtPDFJacSnpBN2ITpH5xr0OkxmywY1IcG+eLgYqFvGhwolPQj2c6N5FX+ZaSNEQYm+YNnJ++I+y3GTp6HD6+Dkom1cQpIbIfKLUorT1xKYtfkY4bHJnI1MIDHVlKNz9Tq4v6IfbWsGEOTjyoPVA6xThoUQhYDZDCsfhcgT4OIDPeZD7e5aRyVukuRGiHtkNiuOh8ex659rnL+5CNxvZ6Luel7N0l7odDo61gmkhLsRbzcnWlcrha+7UVpfhCjs9Hro/Bb8PBMeXQolKmodkbiNJDdC5FBquplr8SnsO3ud7ceucik6iYPno3N0rtFJz6xH6uHnYaSivwcV/NylFUaIoibqLNw4C1XaWY6rtINKD1oSHVGoSHIjRDYOX4xhy99X2H7saqa1WrJTysuFGoFe1C7jTd2yPnSsEyjrqgjhCI5ugA1jLM+f/gX8KlueS2JTKElyIwSWrqWE1HS+3n+RTX9d4c9/b2Rb18vFidI+rtQr60Ownzshwb40r1pSkhghHFFaMvzwKvyxxHJcrgnonbWNSdyVJDei2ElOM/Hr6Ui+PXiZf6MSOXSXmUpNKvnxaMOyPFgjgBLuRpk6LURxcf00rB0C4X9ZjluMhXavgUGSm8JOkhvh0JJSLYnM+oOX2PTXlRyd4+XqxPiHqtO5bhClfVzzOUIhRKF0+Gv43/OQGgdufvDIx1C9g9ZRiRyS5EY4nGkb/+bijUQOXYzhWlxKtvV83Z25r5wvrav5Uz3Qi4YVSuDmbJCZSkIIuLTfktiUb26ZDeVTVuuIRC5IciOKvKtxyWw/dpXJ3xxGqezrPdeuKu1rBVKuhBt+HkbZQkAIYUspyPi5EDrdMmi40VAwyFdlUSN/Y6JIiktOY93+i0z739Fs60zvXofmVUpSNcBTEhkhxJ0dWgOH18Ljqy3JjJMRmgzXOiqRR5LciCJj9z+RLN51ht9OXyfVZLZ5zdmgo0JJD0p6GHm9Z12qB3ppFKUQokhJTYDNL0HYSstx2EpoNETTkMS9k+RGFGpHLsXw8rq/+PtybJavG530LBnUmDbVSxVwZEKIIu/qMctsqGvHAR08OBEaDNQ6KmEHms9pXbBgARUrVsTV1ZWmTZuyb9++O9afN28eNWrUwM3NjeDgYMaNG0dycnIBRSsKyr/XE2gz+2e6frg7U2LToLwvP4xrzbm3unDyjc6S2AghckcpOLgSFre1JDaegTB4oyW50ct6VY5A05abNWvWMH78eBYtWkTTpk2ZN28eHTt25MSJEwQEBGSq/8UXXzBx4kSWLVtG8+bNOXnyJEOGDEGn0zF37lwNPoGwl+Q0E+sOXGTz4SvsOXU90+utq5firV71KOPrpkF0QgiHsuMt+OUty/PKbaHXEvCUX5IciU6pO80vyV9Nmzbl/vvvZ/78+QCYzWaCg4N59tlnmThxYqb6Y8aM4dixY2zfvt1a9sILL/D777+ze/fuHL1nbGwsPj4+xMTE4O3tbZ8PIvLEZFbsORXJaxuO8O/1xCzrVCnlwfdjW8vCeUII+7l2ApaGWhblazletlAoInLz/a1Zy01qair79+9n0qRJ1jK9Xk9oaCh79+7N8pzmzZuzcuVK9u3bR5MmTThz5gybN29m4MDs+0hTUlJISbm11klsbNZjN0TB+vV0JP2X/J7la62q+TOidWVaVvWXWU5CiHunFIQfhqD7LMelasDYQ+Dup21cIt9oltxERkZiMpkIDAy0KQ8MDOT48eNZntO/f38iIyNp2bIlSinS09N55plnmDx5crbvM2vWLKZPn27X2EXeHbkUQ59Fe0lKM9mUP9miEi92rIGbUfq7hRB2lBwL3z0Pf38DQzZBheaWcklsHFqRmi21Y8cOZs6cyUcffUTTpk05deoUY8eO5fXXX+e1117L8pxJkyYxfvx463FsbCzBwcEFFbIAElPTeev742w5Es7V/6wYvOiJRnSqW1qjyIQQDu3KIctsqKgzoDNYuqMykhvh0DRLbvz9/TEYDERERNiUR0REULp01l92r732GgMHDmTYsGEA1KtXj4SEBEaMGMErr7yCPot+UxcXF1xcXOz/AcRdXYtLYcHPp1jx6zmb8tpB3tQs7cXMXvVwdZaWGiGEnSkFfyyFrZPBlAo+wdB7GQQ30ToyUUA0S26MRiONGjVi+/bt9OzZE7AMKN6+fTtjxozJ8pzExMRMCYzBYPly1HBctLhNcpqJ97f/w8/Hr3I8PM7mtdBaAczqdR+lvCTZFELkk6Ro2PgsHNtoOa7xMPRYIN1QxYym3VLjx49n8ODBNG7cmCZNmjBv3jwSEhIYOnQoAIMGDaJs2bLMmjULgG7dujF37lwaNGhg7ZZ67bXX6NatmzXJEdo5F5nAg3N2ZCpvXb0Ur3WpRTVZNVgIkd+Ob7IkNnpneGgGPDDy1n5RotjQNLnp168f165dY8qUKYSHhxMSEsKWLVusg4zPnz9v01Lz6quvotPpePXVV7l06RKlSpWiW7duvPnmm1p9hGIvMTWdsavD+PGobfdiaW9XBjQtz4g2lXFxksRTCFFAQvpDxN9Q71Eo20jraIRGNF3nRguyzo19KKVYuussb24+lum1N3rW5YkHKmgQlRCi2EmMgp/egNCp4OqjdTQiHxWJdW5E0ZQx8+mzvf/alHu7OrF+VAsq+3ug10sTsBCiAFzYB18/CTEXICUWHl2qdUSikJDkRuTYtqMRDPvsT5syV2c9G8e0lF24hRAFx2yGvR/C9hlgTocSlaBZ1hNRRPEkyY24qyOXYuj6oe32FgOalmdU26qUlb2ehBAFKeE6fPsM/POD5bhOL+j2PrjKMANxiyQ3IlsxSWnUn/6DTVmgtwufDL6fumWlb1sIUcCu/AVf9IO4y2Bwgc5vQ6MhMhtKZCLJjcgk3WSm47ydnL6WYFP+/mMh9Agpq1FUQohiz/vmz5+S1aDPCihdV9NwROElyY2w8flv//Lat0dsyka0rszkh2tpFJEQolhLjr3V5eRREgaut6w47OKpbVyiUJPkRljVn/4DMUlp1mOdDsKmdMDHzVnDqIQQxdbZnbBuGIROs6xfAxAgv2iJu5PkRgAwYe0hm8Rmw+gW1A/21S4gIUTxZTbBztnwy9ugzLBvCdz3GGSxf6AQWZHkppj77/RuFyc9x1/vhE4G6AkhtBAXDuuHW1ptAEKegIffkcRG5IokN8XYT8dtE5tSXi78Nqm9JDZCCG2c/gnWj4CEa+DsAV3nQv3HtI5KFEGS3BRTZ67F8+SKW4nN4oGN6FCntIYRCSGKtaizsLI3KBME1LHMhipVXeuoRBElyU0x9NPxCJvEZtWwprSo6q9hREKIYs+vErR83rJXVKdZ4CwLhIq8k+SmmNn01xVGf3HAerzyKUlshBAa+edHKFnVktgAtHtNFuQTdiEjtIqRq3HJNonNpuda0rKaJDZCiAJmSoMfXoNVvS0bX6anWsolsRF2Ii03xURymokmb263Hi8fej91ysgWCkKIAhZ9wZLQXNxnOS7bCFCahiQcjyQ3xcSQ5fuszyd1rknbGgEaRiOEKJaOb4ZvR0JyNLj4QI8PoXYPraMSDkiSGwenlCJkxo/WBfpe7FiDp9tU0TgqIUSxkp4K26bBbwssx2UaQu9lt8baCGFnktw4uLk/nrQmNk0q+jG6bVWNIxJCFD8K/t1jefrAKAidDk5GbUMSDk2SGwcWdiGaD386BUDN0l589UwzjSMSQhQrSlkGCTu5WNatuXoUanbROipRDEhy46AOXYim5wLLb0pVAzzZ9FwrjSMSQhQb6Snww6vg6gPtXrWU+VWSbihRYCS5cUCXo5PocTOxAcvqwwa9TLEUQhSA66fh66Fw5RDo9FD/cSgp4/xEwZLkxgE9tvg36/NdL7Ul2M9dw2iEEMXGkfWw8TlIjQM3P3hkkSQ2QhOS3DiYz/ae43xUImBZfVgSGyFEvktLgi2TYP9yy3H5ZvDoJ+BTVtu4RLElyY0DOREex5QNf1uPZfVhIUS+Uwo+6wEXfgd00Go8PDgZDPL1IrQj//ocRJrJTMd5O63H345uoWE0QohiQ6eDhoMtY216LYaq7bWOSAhJbhzF05/vtz5f0L8hIcG+2gUjhHBsqYkQcwFK1bAcNxgANR8GtxLaxiXETbJxpgN4ce0hfjp+FYBp3WrT5b4gjSMSQjisq8dhSTv4/BFIjLpVLomNKEQkuSniLkUnsXb/RQC63BfEkBayjoQQIp8cXAWLH4Rrx8CcDtH/ah2REFmSbqki7snlf1ifz+sXol0gQgjHlRIPmyfAoS8tx5UfhF5LwFM24BWFkyQ3Rdil6CRORMQBMKR5RZwN0hAnhLCziL9h7RCIPGlZlK/tZGj5Aujl540ovCS5KcLGrQ6zPp/StbZ2gQghHNfueZbExivIsnZNRZmJKQo/SW6KqB+PRrDvnGUw35JBjdHL9gpCiPzQZQ44u0L7qeAha2eJokHaFYuo4Z/9CUDbGqV4qHagxtEIIRzGlUOWTS+Vshy7+kD3DyWxEUXKPbXcJCcn4+rqaq9YRA5tCLtkff5c+2oaRiKEcBhKwR9LYetkMKVCqZrQ4AmtoxIiT3LdcmM2m3n99dcpW7Ysnp6enDlzBoDXXnuNTz75xO4BiszG3hxr4+XqRIPysraEEOIeJcfA2sGWGVGmVKjeGWo8rHVUQuRZrpObN954gxUrVvDOO+9gNBqt5XXr1mXp0qV2DU5k9uvpSOvzj59opGEkQgiHcGk/LGoFRzeA3hk6zoTHvwR3P60jEyLPcp3cfPbZZyxevJgBAwZgMBis5fXr1+f48eN2DU7YUkrRf8nvAOh10Lyq9IELIe7Bgc/hk46Wxfh8y8OTW6HZaMt+UUIUYbkec3Pp0iWqVq2aqdxsNpOWlmaXoETWfjgaYX2+YXRLDSMRQjgEv8qgTFCrG3SfD26+WkckhF3kOrmpXbs2u3btokKFCjblX3/9NQ0aNLBbYMKWUoq5P5wEoEu9IOqV89E4IiFEkZQUfSuJqdgChm2HMg2ktUY4lFwnN1OmTGHw4MFcunQJs9nM+vXrOXHiBJ999hnfffddfsQogFW/n7euRjylmyzYJ4TIJbMZ9s6HXXPgqW1QqrqlvGxDbeMSIh/kesxNjx49+N///se2bdvw8PBgypQpHDt2jP/973889NBD+RGjABbuOA1AWV83Ar1l+r0QIhcSrsOXj8GPr1lmRv21WuuIhMhXeVrnplWrVvz444/2jkVkIyYpjUvRSQDM6VNf42iEEEXKv3th3VMQewkMLtD5LWg0VOuohMhXuW65qVy5MtevX89UHh0dTeXKle0SlLC16vd/AahZ2osHKsv0TCFEDpjNsOtdWNHFktiUrArDt0PjJ2V8jXB4uU5uzp07h8lkylSekpLCpUuXsjhD5NWKFSvQ6XSMbluNf9/uytZxbdDr9eh0OiZOnAjADz/8wFNPPUXdunUxGAxUrFhR26ALiWPHjtGpUyc8PT3x8/Nj4MCBXLt2Lcfnx8XF8dJLL1GpUiVcXFwoW7YsvXv3JjEx0Vpn+/btPPnkk1SvXh13d3cqV67MsGHDuHLlSn58JCFyJ2wVbJ9hmQ11Xz8Y8QuUrqd1VEIUiBx3S23cuNH6fOvWrfj43JqtYzKZ2L59u3yx5hOflgNw8i3N24/Ww8XJsrZQ3bp1Afjiiy9Ys2YNDRs2pEyZMlqGWWhcvHiR1q1b4+Pjw8yZM4mPj2fOnDkcPnyYffv22Sw+mZWYmBjatGnDxYsXGTFiBFWrVuXatWvs2rWLlJQU3N3dAXj55ZeJioqiT58+VKtWjTNnzjB//ny+++47wsLCKF26dEF8XCGyVv9xOLIO6j5q2UZBWmtEcaJySKfTKZ1Op/R6vfV5xsNoNKrq1aur//3vfzm9nGZiYmIUoGJiYrQO5a6WL1+uAFV60Htq0Ce/Z1nn0qVLKjU1VSmlVJcuXVSFChUKMMLCaeTIkcrNzU39+++/1rIff/xRAerjjz/O0fm+vr7qzJkzd6z3yy+/KJPJlKkMUK+88kreghcir0zpSv2xTKm0lFtlZrN28QhhZ7n5/s5xt5TZbMZsNlO+fHmuXr1qPTabzaSkpHDixAm6du2aTylY8ZSabrY+73d/cJZ1ypQpg7Ozs13eT6fTMWbMGNauXUvt2rVxc3OjWbNmHD58GICPP/6YqlWr4urqyoMPPsi5c+dszt+1axd9+vShfPnyuLi4EBwczLhx40hKSrLWuXr1KqVKleLBBx9EZew6DJw6dQoPDw/69et3z59j3bp1dO3alfLly1vLQkNDqV69Ol999dUdz42Ojmb58uWMGDGCSpUqkZqaSkpKSpZ1W7dujV6vz1Tm5+fHsWPH7vlzCJFjcRHweU/47nnYNu1WubTWiGIq17Olzp49mx9xiCz8c3NdG5WawP2lnYiMvLWvlL9//my9sGvXLjZu3Mjo0aMBmDVrFl27duWll17io48+YtSoUdy4cYN33nmHJ598kp9++sl67tq1a0lMTGTkyJGULFmSffv28eGHH3Lx4kXWrl0LQEBAAAsXLqRPnz58+OGHPPfcc5jNZoYMGYKXlxcfffSR9XqJiYk2Y1yyYzAYKFHCsoHopUuXuHr1Ko0bN85Ur0mTJmzevPmO19q9ezfJyclUrVqV3r178+2332I2m2nWrBkLFiwgJCTkjufHx8cTHx+fb38/QmRy+mdYPwISroKzOwTdp3VEQmguT1PBExIS+OWXXzh//jypqak2rz333HN2CUzAmj8vABCx+lUCVr9q89rtrR72dOLECY4fP24dP1WiRAmefvpp3njjDU6ePImXlxdgGWc1a9Yszp07Z6379ttv4+bmZr1WxniVyZMnc/78eWtLSu/evXn88ceZNGkSnTt3ZsOGDezZs4dvv/2WkiVLWs9/5513mD59+l1jrlChgrUVKWMwb1BQUKZ6QUFBREVFkZKSgouLS5bX+ueffwCYNGkSVapU4bPPPiMmJobp06fTrl07/v777yyvnWHevHmkpqbapQVKiDsypcMvb8HOOYCCgDrQZ8WtxfmEKMZyndwcPHiQhx9+mMTERBISEvDz8yMyMhJ3d3cCAgIkubGTX09HkphqmZU2cvJMerW9v0Det3379jYDw5s2bQrAo48+ak1sbi8/c+aMtf7tiU1CQgJJSUk0b94cpRQHDx606SaaP38+O3bsoHfv3pw8eZKBAwfSo0cPm1gGDRpEy5Z330Pr9vfN6ALLKnlxdXW11skuuYmPjwcsXXTbt2/H09MTgAYNGlhbb954440sz925cyfTp0+nb9++tGvX7q5xC5FnsZdh3TD4d4/luOFg6Pw2OLvd+TwhiolcJzfjxo2jW7duLFq0CB8fH3777TecnZ154oknGDt2bH7EWCwt2XnG+vzJRx7KspslP9yegADWWXHBwcFZlt+4ccNadv78eaZMmcLGjRttysEyA+l2fn5+fPDBB/Tp04fAwEA++OCDTLFUrlw512snZSQ6WY2TSU5Otqlzp/O7detmTWwAHnjgASpVqsSvv/6a5XnHjx/nkUceoW7duixdujRXMQuRa2lJcOUvMHpCt/ehXm+tIxKiUMl1chMWFsbHH3+MXq/HYDCQkpJC5cqVeeeddxg8eDC9evXKjziLnZ9P5HxNFnsyGAy5Ks/oHjOZTDz00ENERUXx8ssvU7NmTTw8PLh06RJDhgzBbDZnOnfr1q2AJUG6ePEivr6+Nq9njF/JScylSpUCbnVHZbXWzJUrV/Dz88u21QawTqcPDAzM9FpAQECmpA3gwoULdOjQAR8fHzZv3mzTwiWE3Sh1a4BwySqWLii/SpbnQggbuU5unJ2drTNEAgICOH/+PLVq1cLHx4cLFy7YPcDixGRW7Dsbxb5zmVeALuwOHz7MyZMn+fTTTxk0aJC1PLttOrZs2cLSpUt56aWXWLVqFYMHD+b333/HyenWP8k5c+bkesxN2bJlKVWqFH/++Wemevv27bvrgOBGjRoBZLkg5eXLl6lZs6ZN2fXr1+nQoQMpKSls3779juNxhMizmIuwbji0eQmqtLWUVQvVNiYhCrFcJzcNGjTgjz/+oFq1arRp04YpU6YQGRnJ559/bl1YTuTeliNXmP6/o1yJSdY6lDzJaNm5faCzUor3338/U93o6GiGDRtGkyZNmDlzJm3btqVz587MnDmTKVOmWOvlZcwNWMYHffrpp1y4cMHanbZ9+3ZOnjzJuHHjrPXS0tI4ffo0Pj4+1qSkRo0a1K9fnw0bNhAZGWmd9fTDDz9w4cIFnn32Wev5CQkJPPzww1y6dImff/6ZatWq3TVWIXLtxPfw7UhIugGbJ8DofaDPuiVVCGGR6+Rm5syZxMVZpii/+eabDBo0iJEjR1KtWjU++eQTuwdYHGw5coWRKw+Q3fynX09Hkt2Qm7/++su6evSpU6eIiYmxDnitX78+3bp1y4eIM6tZsyZVqlRhwoQJXLp0CW9vb9atW5dlN87YsWO5fv0627Ztw2Aw0KlTJ4YNG8Ybb7xBjx49qF/fsjloXsbcAEyePJm1a9fStm1bxo4dS3x8PLNnz6ZevXoMHXprw8BLly5Rq1YtBg8ezIoVK6zl7733Hg899BAtW7bk6aefJiYmhrlz51K9enVGjhxprTdgwAD27dvHk08+ybFjx2zWtvH09KRnz565jl0Iq/RU2D4d9s63HJdpAL2XS2IjRE7k63KChVBhW6E43WRWD8zcpiq8/F2mR8mHn1eAqjtqgUo3Zb3SaMYqxlk9Bg8enKtYADV69GibsrNnzypAzZ4926b8559/VoBau3attezo0aMqNDRUeXp6Kn9/fzV8+HB16NAhBajly5crpZTasGGDAtS7775rc73Y2FhVoUIFVb9+feuKy/fiyJEjqkOHDsrd3V35+vqqAQMGqPDw8Cw/W1b36ccff1QPPPCAcnV1VX5+fmrgwIHqypUrNnUqVKiQ7b2XlaLFPYk6p9TitkpN9bY8Nr+sVFqy1lEJoancfH/rlLLPgikHDhxgypQpfPfdd7k6b8GCBcyePZvw8HDq16/Phx9+SJMmTbKtHx0dzSuvvML69euJioqiQoUKzJs3j4cffjhH7xcbG4uPjw8xMTF4e3vnKtb8sPf0dR5f8ttd6305/AGaVSl513pCiCIu5iIsbA7JMeDqAz0+glqy+rsQufn+ztWu4Fu3bmXChAlMnjyZM2csU5WPHz9Oz549uf/++7OcEXMna9asYfz48UydOpUDBw5Qv359OnbsyNWrV7Osn5qaykMPPcS5c+f4+uuvOXHiBEuWLKFs2bK5et/C5GpczsbY5LSeEKKI8y4L1TtDufvhmd2S2AiRBzkec/PJJ58wfPhw/Pz8uHHjBkuXLmXu3Lk8++yz9OvXjyNHjlCrVq1cvfncuXMZPny4dRzEokWL2LRpE8uWLWPixImZ6i9btoyoqCh+/fVX635KRX0n8gAvV7vWy0p4ePgdX3dzc7PZ5V0IUcCizoCrL7j7WaZ7d30PDM6WhxAi13LccvP+++/z9ttvExkZyVdffUVkZCQfffQRhw8fZtGiRblObFJTU9m/fz+hobemM+r1ekJDQ9m7d2+W52zcuJFmzZoxevRoAgMDqVu3LjNnzsRkMmX7PikpKcTGxto8CpMmlfwI8nElu+3tdECQjytNKvnl+T2CgoLu+JDFF4XQ0JH1sKg1fDvKspYNgNFdEhsh7kGOW25Onz5Nnz59AOjVqxdOTk7Mnj2bcuXK5emNIyMjMZlMmRZLCwwM5Pjx41mec+bMGX766ScGDBjA5s2bOXXqFKNGjSItLY2pU6dmec6sWbNytFaKVgx6HVO71WbkygOZXstIeKZ2q41Bn/fdfbNbayZDxsJ1QogClJYMWyfBn8ssx0k3ICXWMs5GCHFPcpzcJCUl4e7uDlj23XFxcSnwBcvMZjMBAQEsXrwYg8FAo0aNuHTpErNnz842uZk0aRLjx4+3HsfGxmbaSkBrneoGMb1HbaZsOGpTXtrHlandatOp7r3d59tbx4QQhUDkKVg7BCIOW45bjoe2r4AhT3sZCyH+I1f/k5YuXWrdbyc9PZ0VK1ZYFznLkNONM/39/TEYDERERNiUR0REULp06SzPCQoKwtnZ2WYrgFq1ahEeHk5qaipGozHTOS4uLndcbr+wSEq9NRj7/cdCCPCydEXdS4uNEKIQ+usr+N/zkJYA7v7Q62OoKr+ACGFPOU5uypcvz5IlS6zHpUuX5vPPP7epo9PpcpzcGI1GGjVqxPbt262LnZnNZrZv386YMWOyPKdFixZ88cUXmM1m6xYQJ0+eJCgoKMvEpij55qBluf/hrSrRI6Tozv4SQtxBaiL89LolsanYCnotAW/ZskMIe8txcpOxd489jR8/nsGDB9O4cWOaNGnCvHnzSEhIsM6eGjRoEGXLlmXWrFkAjBw5kvnz5zN27FieffZZ/vnnH2bOnJnjhKowOx5uWfU5yCf7HauFEEWc0R16r4B/frDsEyWrDQuRLzTt4O3Xrx/Xrl1jypQphIeHExISwpYtW6yDjM+fP29toQEIDg5m69atjBs3jvvuu4+yZcsyduxYXn75Za0+gl38fTnG+rxHiAzuFcKhhH0BZhM0HGg5LtfI8hBC5Bu7rVBcVBS2FYoBpmw4wmd7/6WUlwt/vCJ970I4hJR4y0aXh74EgwuM/BX8q2odlRBFVm6+v2VofiFw6KKl5ea+sjIFVAiHEPG3ZTZU5EnQ6aH1i+BXSeuohCg2JLnRmFKKQxeiAXiwRiltgxFC3Bul4MBn8P1LkJ4MXkHw6FKo2FLryIQoViS50diB8zeszx9pmLcFEYUQhYBS8M0z8Ndqy3HVUHjkY/Dwv/N5Qgi7y9XGmRlOnz7Nq6++yuOPP27d5PL777/n77//tmtwxcEPR2+t8+PpIrmmEEWWTgclq4DOAKHToP9aSWyE0Eiuk5tffvmFevXq8fvvv7N+/Xri4+MBOHToULarBIvs/fC3JbnpWCfwLjWFEIWOUpZtEzK0egGe/gVajgN9nn53FELYQa7/902cOJE33niDH3/80WbhvHbt2vHbb7/ZNbjiwNlgWYG4VlDhmLklhMih5BjLoOEVXSEtyVKmN0DpepqGJYTIQ3Jz+PBhHnnkkUzlAQEBREZG2iWo4iI2OY2TEZaWr56yKrEQRcelA/Bxazj6LVw7DuflFzshCpNcJze+vr5cuXIlU/nBgwcpW1a+oHPj+8OW+1jez50KJd01jkYIcVdKwW+L4JMOcOMc+JSHJ7dClbZaRyaEuE2uk5vHHnuMl19+mfDwcHQ6HWazmT179jBhwgQGDRqUHzE6rG8PXgagXc0AdDrZIFOIQi3pBqx5Ara8DOY0qNkVntkJ5RprHZkQ4j9yndzMnDmTmjVrEhwcTHx8PLVr16Z169Y0b96cV199NT9idFhxKWkABHgX/l3LhSj2Nr0Ax78DgxE6vwP9VoJbCa2jEkJkIddzj41GI0uWLOG1117jyJEjxMfH06BBA6pVq5Yf8Tkss1lx5FIsAB1qy0wpIQq90OkQdRa6zoUyDbSORghxB7lObnbv3k3Lli0pX7485cuXz4+YioWMxfvcnA1UKOmhcTRCiEwSo+DE99BggOXYNxiG/2RZz0YIUajluluqXbt2VKpUicmTJ3P06NH8iKlY2H7csvhh44olcDbIehhCFCrnf4NFLWHDKEuCk0ESGyGKhFx/q16+fJkXXniBX375hbp16xISEsLs2bO5ePFifsTnsJJSTQC4Gw0aRyKEsDKbYddcWP4wxF4CvyrgLbNAhShqcp3c+Pv7M2bMGPbs2cPp06fp06cPn376KRUrVqRdu3b5EaNDOhuZAEDjCn4aRyKEACD+GqzqDdungzJBvT6W1YaD7tM6MiFELt3TZkaVKlVi4sSJ1K9fn9dee41ffvnFXnE5vKNXLIOJG5T31TYQIQSc2w1fPwXx4eDkCg/PhgYDpRtKiCIqz4M99uzZw6hRowgKCqJ///7UrVuXTZs22TM2hxWVkMq1uBQAasq2C0JoLy7cktj414DhP0PDQZLYCFGE5brlZtKkSaxevZrLly/z0EMP8f7779OjRw/c3WWF3Zw6Hm5ptSnt7So7gQuhFaVuJTD1eoMpDWp3B6PMXhSiqMv1N+vOnTt58cUX6du3L/7+/vkRk8M7c80y3sbDRQYTC6GJMzvgh1dhwDrwurnOVMjjmoYkhLCfXCc3e/bsyY84ipUfjkYAUD/YV9tAhChuzCbY8RbsnA0o+OUt6Pqe1lEJIewsR8nNxo0b6dy5M87OzmzcuPGOdbt3726XwBxZUmo6ADUCvTSORIhiJPYKrBsG/+62HDccBB3e1DYmIUS+yFFy07NnT8LDwwkICKBnz57Z1tPpdJhMJnvF5rDOXU8EoE4ZH40jEaKYOLUN1o+AxOtg9ISu8+C+PlpHJYTIJzlKbsxmc5bPRe4lpZpumyklLTdC5Lu/v4G1QyzPA+tBnxXgX1XLiIQQ+SzXU8E/++wzUlJSMpWnpqby2Wef2SUoR3YmMt763N9TdgMXIt9VDYWSVeH+YTBsmyQ2QhQDuU5uhg4dSkxMTKbyuLg4hg4dapegHNnJiDgAqpSS6aZC5JsLf1imegO4eFnWrunyLji7ahuXEKJA5Dq5UUqhy2Jxq4sXL+LjI2NI7uaPc5bdwD1kfRsh7C89Fba+Ap+Ewm8f3Sp3lcUyhShOcvwN26BBA3Q6HTqdjvbt2+PkdOtUk8nE2bNn6dSpU74E6UiS0ywDrmuVlh+2QtjVjX/h6yfh0p+W49jL2sYjhNBMjpObjFlSYWFhdOzYEU9PT+trRqORihUr8uijj9o9QEdzOToJgDplJbkRwm6OfQcbRkFyDLj6QI+PoFZXraMSQmgkx8nN1KlTAahYsSL9+vXD1VX6rvPitzNRANSWPaWEuHfpKfDjFPh9keW4bGPovQxKVNA2LiGEpnI98GPw4MH5EUexEJucZn1e0V8GFAtxz64dhz+WWp43GwPtp4KTUduYhBCay1Fy4+fnx8mTJ/H396dEiRJZDijOEBUVZbfgHM0/N2dKgUwDF8IugupD53fAuyzUkDF/QgiLHCU37733Hl5eXtbnd0puRPauxaUCEOgtiY0QeZKWDNumQoOBULqupez+p7SNSQhR6OQoubm9K2rIkCH5FYvD23s6EoB6ZX21DUSIoijylGWl4YjDcPonGLkXDLKkghAis1yvc3PgwAEOHz5sPd6wYQM9e/Zk8uTJpKam2jU4R5OYapkGnmqSLSyEyJW/1sLiNpbExt0fOs2SxEYIka1cJzdPP/00J0+eBODMmTP069cPd3d31q5dy0svvWT3AB3JNwcvAdC4QgmNIxGiiEhNhI3PwvphkBoPFVrCM7stWyoIIUQ2cp3cnDx5kpCQEADWrl1LmzZt+OKLL1ixYgXr1q2zd3wOJd1sWQ6+aSU/jSMRogiIi4Cl7eHAZ4AO2rwMgzaAd5DWkQkhCrlct+sqpaw7g2/bto2uXS0LZQUHBxMZGWnf6BxIQkq69XmtMrLGjRB35eF/8xEAjy6Byg9qHZEQoojIdXLTuHFj3njjDUJDQ/nll19YuHAhAGfPniUwMNDuATqKs5EJ1ufers4aRiJEIZaaADqDZYNLvQF63VzDxkt+tgghci7X3VLz5s3jwIEDjBkzhldeeYWqVasC8PXXX9O8eXO7B+go/rpo2Und1TnXt1yI4iHiKCxuC1sn3SrzCpTERgiRa7luubnvvvtsZktlmD17NgaDwS5BOaLfz14HoHW1UhpHIkQhoxQc/Bw2vwjpyZASC+1eA3cZmyaEyJs8z6Xcv38/x44dA6B27do0bNjQbkE5ImUZS8zNMcVCCICUOPhuPBz+ynJcpT30WiyJjRDinuQ6ubl69Sr9+vXjl19+wdfXF4Do6Gjatm3L6tWrKVVKWiaycuxKLAANyvtqG4gQhUX4YcuifNdPWcbZtHsVWjwPeum6FULcm1z/FHn22WeJj4/n77//JioqiqioKI4cOUJsbCzPPfdcfsToEHzcLIOIvd1kMLEQpKfAqj6WxMa7LAzdDK3GS2IjhLCLXLfcbNmyhW3btlGrVi1rWe3atVmwYAEdOnSwa3CO5Fp8CgBVZDdwIcDJBbrMhQOfQs+F0g0lhLCrXCc3ZrMZZ+fMrQ/Ozs7W9W+ELaUU/15PBKCMr5vG0QihkcsHISkaqrS1HNd8GGp0BtmIVwhhZ7luA27Xrh1jx47l8uXL1rJLly4xbtw42rdvb9fgHEV0Ypr1eWkfVw0jEUIDSsHvH8MnHeDroRBz8dZrktgIIfJBrpOb+fPnExsbS8WKFalSpQpVqlShUqVKxMbG8uGHH+ZHjEXejcRbG4q6Ost0eVGMJN2ANU/A9y+BKRUqtACjdM0KIfJXrrulgoODOXDgANu3b7dOBa9VqxahobKRXXaiEizJTVnpkhLFycU/LS010efBYIQOb0CTEdJaI4TId7lKbtasWcPGjRtJTU2lffv2PPvss/kVl0O5EpMMSHIjigmlYO8C2DYVzOlQoiL0WQFlGmgdmRCimMhxcrNw4UJGjx5NtWrVcHNzY/369Zw+fZrZs2fnZ3wOITrJMubGz8OocSRCFACdDiJPWhKb2j2h+wfg6qN1VEKIYiTHY27mz5/P1KlTOXHiBGFhYXz66ad89NFH+Rmbw4i+2S3l5ZrnBaGFKPxuny3Z+W3otcTSYiOJjRCigOU4uTlz5gyDBw+2Hvfv35/09HSuXLmSL4E5khs3Z0v5yAJ+whGZzbD7Pfii760Ex9kN7usr42uEEJrIcVNCSkoKHh63Zjno9XqMRiNJSUn5EpgjORkRB8hMKeGAEiLhm6fh1DbL8YlNUKubtjEJIYq9XPWTvPbaa7i7u1uPU1NTefPNN/HxudXsPHfuXPtF5yBiky0tN6kmWeRQOJBze2DdUxB3BZxc4eHZULOr1lEJIUTOk5vWrVtz4sQJm7LmzZtz5swZ67FOmqCzlLEjuMyWEg7BbIJdc2HHTFBm8K9hGVsTWFvryIQQAshFcrNjx458DMOxHb4UA0C5EpLcCAewaTzsX2F5HjLA0mIjC/MJIQqRQrEF74IFC6hYsSKurq40bdqUffv25ei81atXo9Pp6NmzZ/4GeI+MBsttlh3BhUNo/BS4lYCei6DnR5LYCCEKHc2TmzVr1jB+/HimTp3KgQMHqF+/Ph07duTq1at3PO/cuXNMmDCBVq1aFVCkeaOUso61KeXponE0QuSB2QQXbvuFI+g+eP4IhDyuXUxCCHEHmic3c+fOZfjw4QwdOpTatWuzaNEi3N3dWbZsWbbnmEwmBgwYwPTp06lcuXIBRpt78Snp1uelvCS5EUVM7BX4tDssfxgu7b9V7uKpXUxCCHEXmiY3qamp7N+/32ZfKr1eT2hoKHv37s32vBkzZhAQEMBTTz1VEGHek+vxtzbNdDfKVHBRhJzaBotawr+7wckF4sK1jkgIIXJE0yVzIyMjMZlMBAYG2pQHBgZy/PjxLM/ZvXs3n3zyCWFhYTl6j5SUFFJSUqzHsbGxeY43LxJTTQD4ujvLbDJRNJjS4ec3LAvzAQTWs8yG8q+qaVhCCJFTeWq52bVrF0888QTNmjXj0qVLAHz++efs3r3brsH9V1xcHAMHDmTJkiX4+/vn6JxZs2bh4+NjfQQHB+drjP8VlyyrE4siJOYirOhyK7G5fxgM2yaJjRCiSMl1crNu3To6duyIm5sbBw8etLaKxMTEMHPmzFxdy9/fH4PBQEREhE15REQEpUuXzlT/9OnTnDt3jm7duuHk5ISTkxOfffYZGzduxMnJidOnT2c6Z9KkScTExFgfFy5cyFWM9ypjzI23qyQ3ogg49j+48Bu4eFtaa7q8C86uWkclhBC5kuvk5o033mDRokUsWbIEZ+dbX9gtWrTgwIEDubqW0WikUaNGbN++3VpmNpvZvn07zZo1y1S/Zs2aHD58mLCwMOuje/futG3blrCwsCxbZVxcXPD29rZ5FKQLUYkAuMnWC6IoaPI0tBgLT/8CdR7ROhohhMiTXI+5OXHiBK1bt85U7uPjQ3R0dK4DGD9+PIMHD6Zx48Y0adKEefPmkZCQwNChQwEYNGgQZcuWZdasWbi6ulK3bl2b8319fQEylRcWzk6W/DE8NlnjSITIQvR5+OlNSwuNiyfo9fDQDK2jEkKIe5Lr5KZ06dKcOnWKihUr2pTv3r07T9Oy+/Xrx7Vr15gyZQrh4eGEhISwZcsW6yDj8+fPo9drPmM9zzJmSzWuWELjSIT4j+Ob4NuRkBxjWYivq+wLJ4RwDLlOboYPH87YsWNZtmwZOp2Oy5cvs3fvXiZMmMBrr72WpyDGjBnDmDFjsnztbts+rFixIk/vWVD+/PcGAAFeMm5BFBLpqfDjFPh9oeW4bCNLV5QQQjiIXCc3EydOxGw20759exITE2ndujUuLi5MmDCBZ599Nj9iLNJcb3ZLpaSbNI5ECCDqLHw9FC4ftBw3GwPtp4KTUdu4hBDCjnKd3Oh0Ol555RVefPFFTp06RXx8PLVr18bTU1YszcrJiDgAagR6aRyJKPbO7oLV/SEl9tbeUDU6aR2VEELYXZ4X8TMajdSuXduesTikjPVtnA1Fd9yQcBD+1SwrDQc8AL0/AZ9yWkckhBD5ItfJTdu2be+40u5PP/10TwE5mnPXLVPBK5WSnZOFBhKug0dJy3Ov0jBkM/hVAoOsuySEcFy5Tm5CQkJsjtPS0ggLC+PIkSMMHjzYXnE5jJgkywrFsoifKHCHv4b/PQ895kOdnpayUtW1jEgIIQpErpOb9957L8vyadOmER8ff88BOZJ0k9n63M9DBmyKApKWBN+/DAc+tRwfWn0ruRFCiGLAbgNBnnjiCZYtW2avyzmEuOR063MPF1mhWBSAaydhSfubiY0OWr8E/VZqHZUQQhQou+0KvnfvXlxdZS2X292e3Lg4SXIj8lnYl7BpPKQlgkcA9FoMVdpqHZUQQhS4XCc3vXr1sjlWSnHlyhX+/PPPPC/i56jiUizjbfw9XTSORDi8y2Hw7TOW55VaQ6+l4BWoaUhCCKGVXCc3Pj4+Nsd6vZ4aNWowY8YMOnToYLfAHEFs0s0dwd3s1kAmRNbKhFgW5HP1gVYvgF5aCoUQxVeuvnVNJhNDhw6lXr16lCgheyXdTWKqJbnxdJHkRtiZUnDoS6jUBnzKWso6vqltTEIIUUjkakCxwWCgQ4cOedr9uzi6kWjplpLkRthVShysH2HZ9HLdU2BKv/s5QghRjOR6tlTdunU5c+ZMfsTicCLjUwAo7S0DrYWdhB+GxQ/C4a9AZ4BqHUAnq18LIcTtcv1T8Y033mDChAl89913XLlyhdjYWJuHuCU2YwE/N1nAT9wjpeDPZZZp3tdPgXdZGLoZWo0HvSQ3Qghxuxz3l8yYMYMXXniBhx9+GIDu3bvbbMOglEKn02Eyye7XGQ5figFkjRtxj1LiYOOz8Pc3luPqnaDnQnD30zYuIYQopHKc3EyfPp1nnnmGn3/+OT/jcSiBN7ujom+OvREiT3QGuHYC9E4QOs0yK+oO+7sJIURxl+PkRikFQJs2bfItGEdzMiIOgOqBXhpHIoocpSwPvR6M7tBnBSTHQvD9WkcmhBCFXq466++0G7jIXrpZaR2CKEqSouGrgbDntn3cStWQxEYIIXIoV3OUq1evftcEJyoq6p4CciQZO4IHeMkKxSKHLu6Hr4dA9Hn4Zxs0GAieAVpHJYQQRUqukpvp06dnWqFYZO9anGUquKxzI+5KKfjtI/hxKpjToERF6L1cEhshhMiDXH3rPvbYYwQEyA/bnEpMtcwcK+Fh1DgSUaglRsG3o+Dk95bj2j2g+4eWrRSEEELkWo6TGxlvk3e+ss6NyE56KiwNhajTYHCBTjOh8VMyG0oIIe5BjgcUZ8yWEjmTkn5rvR8/T2m5EdlwMsIDI8GvCgzbBvcPk8RGCCHuUY5bbsxmc37G4XAyxtsY9Do8jDLmRtwm4TokXIOAmpbj+4dByADLlG8hhBD3TNZtzydXbyY3JdydMejlN3Fx07+/wqIW8GU/SLasYI1OJ4mNEELYkSQ3+SQ8JhmAyPhUjSMRhYLZDDtnw4ouEHcFDEZIiNQ6KiGEcEjSX5JPUtMt3Xj+Mt5GxF+F9SPgzM2tS+r3hy5zwOihbVxCCOGgJLnJJ5eikwCoXUam8xZrZ36B9cMhPgKc3aHLuxDSX+uohBDCoUlyk09uJFi6owwy3KZ4++0jS2JTqpZlf6iMQcRCCCHyjSQ3+ST65tYLJdylW6pY6/GRZY+oByfLoGEhhCggMqA4n0TdbLkJ8HbVOBJRoE5th62v3Dr2KAkd3pDERgghCpC03OQTd6MBACeZBl48mNJhx0zYNRdQENwUanfXOiohhCiWJLnJJ4cvWdYwKVvCTeNIRL6LuQTrhsH5Xy3HjZ+Eag9pG5MQQhRjktzkk5IeRv69nkhymunulUXRdfIH+OZpSIoCoxd0/wDq9tI6KiGEKNYkuckn6WbLXlxlfaXlxmHtnAM/vW55HhQCfZaDX2VNQxJCCCHJTb7566KlW8rDRW6xwyoTAuigyQjo8Do4uWgdkRBCCCS5yTdlfd24FJ0k+0o5mvhr4FnK8rxqKIz+HUrV0DYmIYQQNmQqeD5JSbeMtfF1d9Y4EmEX6amwZRLMbwRRZ2+VS2IjhBCFjiQ3+SQlzbK3lIuTQeNIxD27cQ6WdbSsNpwcA6e2aR2REEKIO5BuqXyglCLx5iypjPVuRBF1dANseBZSYsCtBPRcCDU6ax2VEEKIO5DkJh+kpJsx3ZwtJclNEZWWDD+8Cn8ssRwHN4VHPwHfYG3jEkIIcVeS3OSD2Jv7SgG4OUtyUyT9vuhWYtPieWj3Khhk/JQQQhQFktzkg7iUdOtzJ4MMayqSHhgJ53ZB02dktWEhhChi5Js3H6SmWwYT+3vKjuBFRloS7PnAskcUWNaseWKdJDZCCFEESctNPki6OZhYZkoVEddOwtohcPVvy2yo9q9pHZEQQoh7IMlNPkhKtSQ3Hi6S3BR6h1bDd+MhLQE8AqBiS60jEkIIcY8kuckHGZtluspg4sIrNQE2vwRhKy3HlVpDr6XgFahtXEIIIe6ZJDf54HJMMgDOMpi4cLp2Ar4aBNeOg04PbSZC6wmgl2RUCCEcgSQ3+SBj+veFqESNIxFZUma48S94loZHl0KlVlpHJIQQwo4kuckHGftKhQT7ahuIuMVsutUyE1ALHlsJpevf2gRTCCGEw5B+k3xwLjIBABcZc1M4hB+Ghc3h3723yqqGSmIjhBAOSpKbfODpYlnJNjwmSeNIijml4M9lsKS9ZXzNj69ZyoQQQjg06ZbKB4mploXg7ivnq20gxVlyLPxvLPy93nJcrQP0XAQ6nbZxCSGEyHeS3OSDmJt7S/m6yV5EmrgcBl8PhagzoHeC9lOh2RjQS0OlEEIUB5Lc5IOzN8fcuLvI7S1wEUfhk4fAlAo+wdB7GQQ30ToqIYQQBUi+ffNBys29pZSM7yh4AbWgekfL7KgeC8DdT+uIhBBCFLBC0U6/YMECKlasiKurK02bNmXfvn3Z1l2yZAmtWrWiRIkSlChRgtDQ0DvW14K70TJLykNabgrGpQOWPaHAMqam1xJ47AtJbIQQopjSPLlZs2YN48ePZ+rUqRw4cID69evTsWNHrl69mmX9HTt28Pjjj/Pzzz+zd+9egoOD6dChA5cuXSrgyLOXeHNvqRLusit4vlIK9i6ATzpYBg9ntJQ5u8nAYSGEKMY0T27mzp3L8OHDGTp0KLVr12bRokW4u7uzbNmyLOuvWrWKUaNGERISQs2aNVm6dClms5nt27cXcOTZC7sQDYCLs+a313ElRsHq/rB1MpjTLKsOm1K1jkoIIUQhoOm3b2pqKvv37yc0NNRaptfrCQ0NZe/evXc485bExETS0tLw8ys8XRAVS7oDoJfWg/xxYR8sagUnNoPBCA/PgT6fgpOL1pEJIYQoBDQdFBIZGYnJZCIw0HYn5sDAQI4fP56ja7z88suUKVPGJkG6XUpKCikpKdbj2NjYvAecQ+euW/aUKuUpX7Z2ZTbDrx/A9hmgTOBXGfqsgKD6WkcmhBCiECnS/SZvvfUWq1ev5ptvvsHV1TXLOrNmzcLHx8f6CA4Ozve4MjbONDoV6dtb+CRHw++LLIlN3d7w9E5JbIQQQmSi6bevv78/BoOBiIgIm/KIiAhKly59x3PnzJnDW2+9xQ8//MB9992Xbb1JkyYRExNjfVy4cMEusd9JqskyFdzLVWZL2ZW7Hzz6CXR737Kbt4uX1hEJIYQohDRNboxGI40aNbIZDJwxOLhZs2bZnvfOO+/w+uuvs2XLFho3bnzH93BxccHb29vmkZ/STGZMZsusHVcn2TjznpjNsHM2HFpzq6xiC2g0RGZDCSGEyJbmTQvjx49n8ODBNG7cmCZNmjBv3jwSEhIYOnQoAIMGDaJs2bLMmjULgLfffpspU6bwxRdfULFiRcLDwwHw9PTE09NTs8+RISnNZH0us6XuQfxVWD8CzvwMzu5QqRV4l9E6KiGEEEWA5slNv379uHbtGlOmTCE8PJyQkBC2bNliHWR8/vx59LftCbRw4UJSU1Pp3bu3zXWmTp3KtGnTCjL0LCXfntzImJu8ObsT1g2D+AhwcoOHZ4NXkNZRCSGEKCJ0qpjtERAbG4uPjw8xMTH50kV1ISqRVu/8jJuzgWOvd7L79R2a2WTphvrlbcu6NaVqWWZDBdTUOjIhhBAay833t+YtN44mNtmyI7gMCcklUzqs7AVnf7EcNxgInd8Bo7u2cQkhhChyJLmxszSTpSEsYwsGkUMGJyjbEC7+Cd3mwX19tY5ICCFEESXJjZ3FJFlabqoGaD+4udAzpVvWrvHwtxy3fQUaDrIszieEEELkkYx4tbPElHQAohNln6M7irkEn3aFVX0g/ea9MjhLYiOEEOKeScuNnWWMzvZ2ddY0jkLt5A/wzdOQFAVGL7h6FMqEaB2VEEIIByHJjZ2lpltWJy5bwk3jSAohU5plX6hfP7AcB9WH3suhZBVt4xJCCOFQJLmxs5R0y0Bio0F6/GxEn4evn4SLf1iOmzwNHV6XnbyFEELYnSQ3dpYxS8rNKFsv2Nj4rCWxcfGBHvOhdnetIxJCCOGgpHnBztJubpopO4L/R5e5UPlBeGanJDZCCCHylXwD21nGmJti3y114xzs//TWcckqMGgDlKioVURCCCGKCemWsrMzkQlAMW+5OboBNjwLKbHgWx6qtNU6IiGEEMWIJDd25uNmmQIeEZuscSQaSEuGH16FP5ZYjss1kZlQQgghCpwkN/mkvF8x2xPp+mlYOwTC/7IctxgL7V6zLMwnhBBCFCBJbuwsY0Cxh0sxurV/f2PphkqNAzc/eORjqN5B66iEEEIUU8XoG7hgpKVb1ih2Lk4DilMTLIlN+ebw6FLwKat1REIIIYoxSW7sLOxCNADOBp22geQ3U7plJ2+AkAFg9ICa3W6VCSGEEBopRs0LBSP45lib+OR0jSPJR4dWw8LmkBhlOdbpoM4jktgIIYQoFCS5sbN9Z68DUCXAU+NI8kFqAnw72rLpZeQJ+H2R1hEJIYQQmUhyY2cV/T0ASDepu9QsYq4egyXtIGwloIMHJ0Gbl7WOSgghhMhE+hHsLDnNsrdUaR9XjSOxE6UgbBVsmgDpSeAZaBk0XKm11pEJIYQQWZLkxs5ORsQD4OrsII1ifyyFzRMszyu3hV6LwTNA25iEEEKIO3CQb+DCw8/DCIBe5yCzper1Ab/KlgX5nlgviY0QQohCT1pu7Mxktoy18XItoivzKgVnfra00uh04OYLI/eCs4N0swkhhHB40nJjZynpljE3LkVx48zkWFj3FHz+COxfcatcEhshhBBFiLTc2JFSiuQ0y/YLRS65uXLIsjdU1BnQO0F6Mdz4UwghhEOQ5MaOElNN1udFZm8ppSyDhrdOBlMq+ARD72UQ3ETryIQQQog8KSLfwEVDxqaZUERabpKiYeOzcGyj5bjGw9BjAbj7aRqWEEIIcS8kubGj1JvJjV4HTkVh48yrR+H4d6B3hodmwAMjLYOIhRBCiCJMkhs7Sk23JDdFZkfwCs3h4dlQpgGUbaR1NEIIIYRdFJFv4aIhY8xNSrr5LjU1khgFXz8Fkf/cKrt/mCQ2QgghHIq03NhRod5P6sI++PpJiLlgmRE1/CfpghJCCOGQJLmxo4w1boL93DSO5DZmM+z9ELbPAHM6lKgEXd+TxEYIIYTDkuTGjqISUgEwFpYxNwnX4dtn4J8fLMd1ekG398HVW9u4hBBCiHwkyY0dZTSGnL6WoG0gANdPw4quEHcZnFyh01vQaIi02AghhHB4ktzYUcbqxPdXLKFxJIBvefANBqMH9FkBpetqHZEQQghRICS5saMLUYkAuDobtAkgIRJcvMHJCAZn6PsZGD3BxVObeIQQQggNFJLBIY7B09WSK57Rolvq7E5Y2By2T79V5lVaEhshhBDFjiQ3dpSxiF+D8r4F96ZmE+x4Cz7rAfERcGo7pCYW3PsLIYQQhYx0S9lRRnJTYLOl4sJh/XBLqw1Agyeg82wwuhfM+wshhBCFkCQ3dpSxcaaxIDbNPP0TrB8BCdfA2QO6zoX6j+X/+wohhBCFnCQ3dpRwc/sFN2M+DyhOioavhkBKDATUscyGKlU9f99TCCGEKCIkubGjlJtTwfN9tpSbr6Wl5twuy/o1zoVoRWQhhBBCY5Lc2NGpa/EAuORHt9Q/P4KTC1RqbTmu19vyEEIIIYQNmS1lRx43u6Pik9Ptd1FTGvw4BVb1tuzoHX/VftcWQgghHJC03OSDQG9X+1wo+oJlJ++L+yzHtXtYFukTQgghRLYkubGjvy/HAuDj7nzvFzu+Gb4dCcnR4OIDPT60JDdCCCGEuCNJbuzIz8PI+ahEUtJMeb+I2QQ/vAa/LbAcl2kIvZeBXyX7BCmEEEI4OElu7Ejd/POeuqV0esvaNQAPjILQ6Za9ooQQQgiRI5Lc2FFGi427MQ+31ZQOBifQ6SzTvO/rC9UesnOEQgghhOOT2VJ2lJBqmSXl6pyL25qeAptfhK8GgrrZ9uPiJYmNEEIIkUfScmNHGYv45XiF4uun4euhcOWQ5fj8XqjQPJ+iE0IIIYoHSW7syLq3VE42zjyyDjaOhdQ4cPODRxZJYiOEEELYgSQ3dpRusnQrOd8puUlLgi2TYP9yy3H5ZvDoJ+BTtgAiFEIIIRyfJDd2FJdiGXPjfKftF75+Ek5sBnTQajw8ONkykFgIIYQQdiHfqnaiMgYDA056XfYVW70Al8Ogx3yo2j7/AxNCCCGKGUlu7CTNdCu5sdkVPDURLh+Aii0tx+Uaw9gwyyaYQgghhLA7mQpuJxmDieG2AcVXj8OSdrDyUQg/cquyJDZCCCFEvikUyc2CBQuoWLEirq6uNG3alH379t2x/tq1a6lZsyaurq7Uq1ePzZs3F1Ck2UtNvz250cHBlbD4Qbh2DFx9ICVOu+CEEEKIYkTz5GbNmjWMHz+eqVOncuDAAerXr0/Hjh25evVqlvV//fVXHn/8cZ566ikOHjxIz5496dmzJ0eOHMmyfkFJylidmGQMG0bChtGQngSV28Izu6FCM03jE0IIIYoLnbp9JKwGmjZtyv3338/8+fMBMJvNBAcH8+yzzzJx4sRM9fv160dCQgLfffedteyBBx4gJCSERYsW3fX9YmNj8fHxISYmBm9vb7t9jtPX4hk993PmO39AVf1lyx5RbSdDyxdAr3kOKYQQQhRpufn+1vRbNzU1lf379xMaGmot0+v1hIaGsnfv3izP2bt3r019gI4dO2ZbPyUlhdjYWJtHfkhISech/Z+WxMYrCAZ/B61flMRGCCGEKGCafvNGRkZiMpkIDAy0KQ8MDCQ8PDzLc8LDw3NVf9asWfj4+FgfwcHB9gn+P1LTzawwPMpKY19LN1TFFvnyPkIIIYS4M4efCj5p0iTGjx9vPY6Njc2XBKdxRT8Oz3gYpTpbdvYWQgghhCY0TW78/f0xGAxERETYlEdERFC6dOkszyldunSu6ru4uODiUnBTr3WS2AghhBCa0rRbymg00qhRI7Zv324tM5vNbN++nWbNsp5d1KxZM5v6AD/++GO29YUQQghRvGjeLTV+/HgGDx5M48aNadKkCfPmzSMhIYGhQ4cCMGjQIMqWLcusWbMAGDt2LG3atOHdd9+lS5curF69mj///JPFixdr+TGEEEIIUUhontz069ePa9euMWXKFMLDwwkJCWHLli3WQcPnz59Hf9uMo+bNm/PFF1/w6quvMnnyZKpVq8a3335L3bp1tfoIQgghhChENF/npqDl1zo3QgghhMg/RWadGyGEEEIIe5PkRgghhBAORZIbIYQQQjgUSW6EEEII4VAkuRFCCCGEQ5HkRgghhBAORZIbIYQQQjgUSW6EEEII4VAkuRFCCCGEQ9F8+4WClrEgc2xsrMaRCCGEECKnMr63c7KxQrFLbuLi4gAIDg7WOBIhhBBC5FZcXBw+Pj53rFPs9pYym81cvnwZLy8vdDqdXa8dGxtLcHAwFy5ckH2r8pHc54Ih97lgyH0uOHKvC0Z+3WelFHFxcZQpU8ZmQ+2sFLuWG71eT7ly5fL1Pby9veU/TgGQ+1ww5D4XDLnPBUfudcHIj/t8txabDDKgWAghhBAORZIbIYQQQjgUSW7syMXFhalTp+Li4qJ1KA5N7nPBkPtcMOQ+Fxy51wWjMNznYjegWAghhBCOTVpuhBBCCOFQJLkRQgghhEOR5EYIIYQQDkWSGyGEEEI4FElucmnBggVUrFgRV1dXmjZtyr59++5Yf+3atdSsWRNXV1fq1avH5s2bCyjSoi0393nJkiW0atWKEiVKUKJECUJDQ+/69yIscvvvOcPq1avR6XT07NkzfwN0ELm9z9HR0YwePZqgoCBcXFyoXr26/OzIgdze53nz5lGjRg3c3NwIDg5m3LhxJCcnF1C0RdPOnTvp1q0bZcqUQafT8e233971nB07dtCwYUNcXFyoWrUqK1asyPc4USLHVq9erYxGo1q2bJn6+++/1fDhw5Wvr6+KiIjIsv6ePXuUwWBQ77zzjjp69Kh69dVXlbOzszp8+HABR1605PY+9+/fXy1YsEAdPHhQHTt2TA0ZMkT5+PioixcvFnDkRUtu73OGs2fPqrJly6pWrVqpHj16FEywRVhu73NKSopq3Lixevjhh9Xu3bvV2bNn1Y4dO1RYWFgBR1605PY+r1q1Srm4uKhVq1aps2fPqq1bt6qgoCA1bty4Ao68aNm8ebN65ZVX1Pr16xWgvvnmmzvWP3PmjHJ3d1fjx49XR48eVR9++KEyGAxqy5Yt+RqnJDe50KRJEzV69GjrsclkUmXKlFGzZs3Ksn7fvn1Vly5dbMqaNm2qnn766XyNs6jL7X3+r/T0dOXl5aU+/fTT/ArRIeTlPqenp6vmzZurpUuXqsGDB0tykwO5vc8LFy5UlStXVqmpqQUVokPI7X0ePXq0ateunU3Z+PHjVYsWLfI1TkeSk+TmpZdeUnXq1LEp69evn+rYsWM+RqaUdEvlUGpqKvv37yc0NNRaptfrCQ0NZe/evVmes3fvXpv6AB07dsy2vsjbff6vxMRE0tLS8PPzy68wi7y83ucZM2YQEBDAU089VRBhFnl5uc8bN26kWbNmjB49msDAQOrWrcvMmTMxmUwFFXaRk5f73Lx5c/bv32/tujpz5gybN2/m4YcfLpCYiwutvgeL3caZeRUZGYnJZCIwMNCmPDAwkOPHj2d5Tnh4eJb1w8PD8y3Ooi4v9/m/Xn75ZcqUKZPpP5S4JS/3effu3XzyySeEhYUVQISOIS/3+cyZM/z0008MGDCAzZs3c+rUKUaNGkVaWhpTp04tiLCLnLzc5/79+xMZGUnLli1RSpGens4zzzzD5MmTCyLkYiO778HY2FiSkpJwc3PLl/eVlhvhUN566y1Wr17NN998g6urq9bhOIy4uDgGDhzIkiVL8Pf31zoch2Y2mwkICGDx4sU0atSIfv368corr7Bo0SKtQ3MoO3bsYObMmXz00UccOHCA9evXs2nTJl5//XWtQxN2IC03OeTv74/BYCAiIsKmPCIigtKlS2d5TunSpXNVX+TtPmeYM2cOb731Ftu2beO+++7LzzCLvNze59OnT3Pu3Dm6detmLTObzQA4OTlx4sQJqlSpkr9BF0F5+fccFBSEs7MzBoPBWlarVi3Cw8NJTU3FaDTma8xFUV7u82uvvcbAgQMZNmwYAPXq1SMhIYERI0bwyiuvoNfL7/72kN33oLe3d7612oC03OSY0WikUaNGbN++3VpmNpvZvn07zZo1y/KcZs2a2dQH+PHHH7OtL/J2nwHeeecdXn/9dbZs2ULjxo0LItQiLbf3uWbNmhw+fJiwsDDro3v37rRt25awsDCCg4MLMvwiIy//nlu0aMGpU6esySPAyZMnCQoKksQmG3m5z4mJiZkSmIyEUsmWi3aj2fdgvg5XdjCrV69WLi4uasWKFero0aNqxIgRytfXV4WHhyullBo4cKCaOHGitf6ePXuUk5OTmjNnjjp27JiaOnWqTAXPgdze57feeksZjUb19ddfqytXrlgfcXFxWn2EIiG39/m/ZLZUzuT2Pp8/f155eXmpMWPGqBMnTqjvvvtOBQQEqDfeeEOrj1Ak5PY+T506VXl5eakvv/xSnTlzRv3www+qSpUqqm/fvlp9hCIhLi5OHTx4UB08eFABau7cuergwYPq33//VUopNXHiRDVw4EBr/Yyp4C+++KI6duyYWrBggUwFL4w+/PBDVb58eWU0GlWTJk3Ub7/9Zn2tTZs2avDgwTb1v/rqK1W9enVlNBpVnTp11KZNmwo44qIpN/e5QoUKCsj0mDp1asEHXsTk9t/z7SS5ybnc3udff/1VNW3aVLm4uKjKlSurN998U6Wnpxdw1EVPbu5zWlqamjZtmqpSpYpydXVVwcHBatSoUerGjRsFH3gR8vPPP2f58zbj3g4ePFi1adMm0zkhISHKaDSqypUrq+XLl+d7nDqlpP1NCCGEEI5DxtwIIYQQwqFIciOEEEIIhyLJjRBCCCEciiQ3QgghhHAoktwIIYQQwqFIciOEEEIIhyLJjRBCCCEciiQ3QggbK1aswNfXV+sw8kyn0/Htt9/esc6QIUPo2bNngcQjhCh4ktwI4YCGDBmCTqfL9Dh16pTWobFixQprPHq9nnLlyjF06FCuXr1ql+tfuXKFzp07A3Du3Dl0Oh1hYWE2dd5//31WrFhhl/fLzrRp06yf02AwEBwczIgRI4iKisrVdSQREyL3ZFdwIRxUp06dWL58uU1ZqVKlNIrGlre3NydOnMBsNnPo0CGGDh3K5cuX2bp16z1f+267xwP4+Pjc8/vkRJ06ddi2bRsmk4ljx47x5JNPEhMTw5o1awrk/YUorqTlRggH5eLiQunSpW0eBoOBuXPnUq9ePTw8PAgODmbUqFHEx8dne51Dhw7Rtm1bvLy88Pb2plGjRvz555/W13fv3k2rVq1wc3MjODiY5557joSEhDvGptPpKF26NGXKlKFz584899xzbNu2jaSkJMxmMzNmzKBcuXK4uLgQEhLCli1brOempqYyZswYgoKCcHV1pUKFCsyaNcvm2hndUpUqVQKgQYMG6HQ6HnzwQcC2NWTx4sWUKVPGZhdugB49evDkk09ajzds2EDDhg1xdXWlcuXKTJ8+nfT09Dt+TicnJ0qXLk3ZsmUJDQ2lT58+/Pjjj9bXTSYTTz31FJUqVcLNzY0aNWrw/vvvW1+fNm0an376KRs2bLC2Au3YsQOACxcu0LdvX3x9ffHz86NHjx6cO3fujvEIUVxIciNEMaPX6/nggw/4+++/+fTTT/npp5946aWXsq0/YMAAypUrxx9//MH+/fuZOHEizs7OAJw+fZpOnTrx6KOP8tdff7FmzRp2797NmDFjchWTm5sbZrOZ9PR03n//fd59913mzJnDX3/9RceOHenevTv//PMPAB988AEbN27kq6++4sSJE6xatYqKFStmed19+/YBsG3bNq5cucL69esz1enTpw/Xr1/n559/tpZFRUWxZcsWBgwYAMCuXbsYNGgQY8eO5ejRo3z88cesWLGCN998M8ef8dy5c2zduhWj0WgtM5vNlCtXjrVr13L06FGmTJnC5MmT+eqrrwCYMGECffv2pVOnTly5coUrV67QvHlz0tLS6NixI15eXuzatYs9e/bg6elJp06dSE1NzXFMQjisfN+aUwhR4AYPHqwMBoPy8PCwPnr37p1l3bVr16qSJUtaj5cvX658fHysx15eXmrFihVZnvvUU0+pESNG2JTt2rVL6fV6lZSUlOU5/73+yZMnVfXq1VXjxo2VUkqVKVNGvfnmmzbn3H///WrUqFFKKaWeffZZ1a5dO2U2m7O8PqC++eYbpZRSZ8+eVYA6ePCgTZ3/7mjeo0cP9eSTT1qPP/74Y1WmTBllMpmUUkq1b99ezZw50+Yan3/+uQoKCsoyBqWUmjp1qtLr9crDw0O5urpad0+eO3dutucopdTo0aPVo48+mm2sGe9do0YNm3uQkpKi3Nzc1NatW+94fSGKAxlzI4SDatu2LQsXLrQee3h4AJZWjFmzZnH8+HFiY2NJT08nOTmZxMRE3N3dM11n/PjxDBs2jM8//9zatVKlShXA0mX1119/sWrVKmt9pRRms5mzZ89Sq1atLGOLiYnB09MTs9lMcnIyLVu2ZOnSpcTGxnL58mVatGhhU79FixYcOnQIsHQpPfTQQ9SoUYNOnTrRtWtXOnTocE/3asCAAQwfPpyPPvoIFxcXVq1axWOPPYZer7d+zj179ti01JhMpjveN4AaNWqwceNGkpOTWblyJWFhYTz77LM2dRYsWMCyZcs4f/48SUlJpKamEhIScsd4Dx06xKlTp/Dy8rIpT05O5vTp03m4A0I4FkluhHBQHh4eVK1a1abs3LlzdO3alZEjR/Lmm2/i5+fH7t27eeqpp0hNTc3yS3ratGn079+fTZs28f333zN16lRWr17NI488Qnx8PE8//TTPPfdcpvPKly+fbWxeXl4cOHAAvV5PUFAQbm5uAMTGxt71czVs2JCzZ8/y/fffs23bNvr27UtoaChff/31Xc/NTrdu3VBKsWnTJu6//3527drFe++9Z309Pj6e6dOn06tXr0znurq6Zntdo9Fo/Tt466236NKlC9OnT+f1118HYPXq1UyYMIF3332XZs2a4eXlxezZs/n999/vGG98fDyNGjWySSozFJZB40JoSZIbIYqR/fv3Yzabeffdd62tEhnjO+6kevXqVK9enXHjxvH444+zfPlyHnnkERo2bMjRo0czJVF3o9frszzH29ubMmXKsGfPHtq0aWMt37NnD02aNLGp169fP/r160fv3r3p1KkTUVFR+Pn52VwvY3yLyWS6Yzyurq706tWLVatWcerUKWrUqEHDhg2trzds2JATJ07k+nP+16uvvkq7du0YOXKk9XM2b96cUaNGWev8t+XFaDRmir9hw4asWbOGgIAAvL297ykmIRyRDCgWohipWrUqaWlpfPjhh5w5c4bPP/+cRYsWZVs/KSmJMWPGsGPHDv7991/27NnDH3/8Ye1uevnll/n1118ZM2YMYWFh/PPPP2zYsCHXA4pv9+KLL/L222+zZs0aTpw4wcSJEwkLC2Ps2LEAzJ07ly+//JLjx49z8uRJ1q5dS+nSpbNceDAgIAA3Nze2bNlCREQEMTEx2b7vgAED2LRpE8uWLbMOJM4wZcoUPvvsM6ZPn87ff//NsWPHWL16Na+++mquPluzZs247777mDlzJgDVqlXjzz//ZOvWrZw8eZLXXnuNP/74w+acihUr8tdff3HixAkiIyNJS0tjwIAB+Pv706NHD3bt2sXZs2fZsWMHzz33HBcvXsxVTEI4JK0H/Qgh7C+rQagZ5s6dq4KCgpSbm5vq2LGj+uyzzxSgbty4oZSyHfCbkpKiHnvsMRUcHKyMRqMqU6aMGjNmjM1g4X379qmHHnpIeXp6Kg8PD3XfffdlGhB8u/8OKP4vk8mkpk2bpsqWLaucnZ1V/fr11ffff299ffHixSokJER5eHgob29v1b59e3XgwAHr69w2oFgppZYsWaKCg4OVXq9Xbdq0yfb+mEwmFRQUpAB1+vTpTHFt2bJFNW/eXLm5uSlvb2/VpEkTtXjx4mw/x9SpU1X9+vUzlX/55ZfKxcVFnT9/XiUnJ6shQ4YoHx8f5evrq0aOHKkmTpxoc97Vq1et9xdQP//8s1JKqStXrqhBgwYpf39/5eLioipXrqyGDx+uYmJiso1JiOJCp5RS2qZXQgghhBD2I91SQgghhHAoktwIIYQQwqFIciOEEEIIhyLJjRBCCCEciiQ3QgghhHAoktwIIYQQwqFIciOEEEIIhyLJjRBCCCEciiQ3QgghhHAoktwIIYQQwqFIciOEEEIIhyLJjRBCCCEcyv8BoScX6zjWlX8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_ROC(posterior_probs_df[\"given label (name)\"] != posterior_probs_df[\"true labels\"], posterior_probs_df.apply(lambda row: row.iloc[:10].argmax() / row.iloc[int(row[\"given label (name)\"])], axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_27788\\2751278478.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  posterior_probs_df[(posterior_probs_df[\"given label (name)\"] == posterior_probs_df[\"true labels\"]) & (posterior_probs_df[posterior_probs_df.columns[:-4]] > 0.95).any(1) & (posterior_probs_df[\"out-label\"] != posterior_probs_df[\"true labels\"])]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p(k = 0.0 | x)</th>\n",
       "      <th>p(k = 1.0 | x)</th>\n",
       "      <th>p(k = 2.0 | x)</th>\n",
       "      <th>p(k = 3.0 | x)</th>\n",
       "      <th>p(k = 4.0 | x)</th>\n",
       "      <th>p(k = 5.0 | x)</th>\n",
       "      <th>p(k = 6.0 | x)</th>\n",
       "      <th>p(k = 7.0 | x)</th>\n",
       "      <th>p(k = 8.0 | x)</th>\n",
       "      <th>p(k = 9.0 | x)</th>\n",
       "      <th>given label (name)</th>\n",
       "      <th>out-label</th>\n",
       "      <th>model pred labels</th>\n",
       "      <th>true labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1.955426e-08</td>\n",
       "      <td>1.933588e-33</td>\n",
       "      <td>5.575818e-03</td>\n",
       "      <td>9.540141e-01</td>\n",
       "      <td>8.956306e-04</td>\n",
       "      <td>1.217764e-02</td>\n",
       "      <td>2.786154e-07</td>\n",
       "      <td>2.615120e-02</td>\n",
       "      <td>3.179590e-05</td>\n",
       "      <td>1.153464e-03</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>1.534290e-07</td>\n",
       "      <td>6.691055e-51</td>\n",
       "      <td>1.189811e-02</td>\n",
       "      <td>9.683299e-01</td>\n",
       "      <td>1.097713e-04</td>\n",
       "      <td>1.592452e-02</td>\n",
       "      <td>4.240165e-10</td>\n",
       "      <td>3.710179e-03</td>\n",
       "      <td>2.943747e-06</td>\n",
       "      <td>2.440332e-05</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>1.453660e-05</td>\n",
       "      <td>4.448264e-69</td>\n",
       "      <td>1.695074e-02</td>\n",
       "      <td>6.212534e-03</td>\n",
       "      <td>1.982746e-06</td>\n",
       "      <td>9.765995e-01</td>\n",
       "      <td>4.207030e-13</td>\n",
       "      <td>1.973741e-04</td>\n",
       "      <td>2.244042e-05</td>\n",
       "      <td>9.238985e-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>2.248206e-03</td>\n",
       "      <td>2.983601e-67</td>\n",
       "      <td>1.658622e-02</td>\n",
       "      <td>1.855184e-10</td>\n",
       "      <td>1.384626e-04</td>\n",
       "      <td>9.800644e-01</td>\n",
       "      <td>1.716995e-09</td>\n",
       "      <td>3.978766e-04</td>\n",
       "      <td>5.645939e-04</td>\n",
       "      <td>2.209910e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>1.554939e-02</td>\n",
       "      <td>7.185461e-108</td>\n",
       "      <td>9.834119e-01</td>\n",
       "      <td>8.754339e-06</td>\n",
       "      <td>2.712940e-04</td>\n",
       "      <td>6.644191e-04</td>\n",
       "      <td>9.478339e-13</td>\n",
       "      <td>7.404420e-05</td>\n",
       "      <td>2.015312e-05</td>\n",
       "      <td>2.234518e-09</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58259</th>\n",
       "      <td>9.506230e-01</td>\n",
       "      <td>3.919347e-19</td>\n",
       "      <td>1.088429e-08</td>\n",
       "      <td>4.776678e-53</td>\n",
       "      <td>3.097477e-02</td>\n",
       "      <td>2.055323e-10</td>\n",
       "      <td>1.809941e-02</td>\n",
       "      <td>1.982444e-07</td>\n",
       "      <td>3.025693e-04</td>\n",
       "      <td>3.685223e-10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58495</th>\n",
       "      <td>4.423375e-06</td>\n",
       "      <td>5.245683e-135</td>\n",
       "      <td>3.093217e-02</td>\n",
       "      <td>6.584733e-04</td>\n",
       "      <td>1.874732e-09</td>\n",
       "      <td>9.684046e-01</td>\n",
       "      <td>2.150363e-21</td>\n",
       "      <td>1.501662e-07</td>\n",
       "      <td>1.613687e-07</td>\n",
       "      <td>1.208344e-15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58817</th>\n",
       "      <td>1.357521e-02</td>\n",
       "      <td>1.354575e-85</td>\n",
       "      <td>9.825699e-01</td>\n",
       "      <td>1.621915e-05</td>\n",
       "      <td>3.035202e-03</td>\n",
       "      <td>7.263820e-06</td>\n",
       "      <td>3.056801e-09</td>\n",
       "      <td>2.781761e-06</td>\n",
       "      <td>7.933780e-04</td>\n",
       "      <td>5.793771e-09</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59239</th>\n",
       "      <td>1.928676e-05</td>\n",
       "      <td>1.475646e-72</td>\n",
       "      <td>3.403805e-02</td>\n",
       "      <td>4.186966e-03</td>\n",
       "      <td>8.013416e-06</td>\n",
       "      <td>9.607569e-01</td>\n",
       "      <td>2.397849e-13</td>\n",
       "      <td>9.600860e-04</td>\n",
       "      <td>2.715815e-05</td>\n",
       "      <td>3.586618e-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59287</th>\n",
       "      <td>2.105141e-03</td>\n",
       "      <td>2.670259e-78</td>\n",
       "      <td>9.761934e-01</td>\n",
       "      <td>5.353399e-04</td>\n",
       "      <td>7.759609e-04</td>\n",
       "      <td>3.385634e-04</td>\n",
       "      <td>4.743377e-08</td>\n",
       "      <td>1.813506e-02</td>\n",
       "      <td>4.965533e-05</td>\n",
       "      <td>1.866842e-03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>439 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p(k = 0.0 | x)  p(k = 1.0 | x)  p(k = 2.0 | x)  p(k = 3.0 | x)  \\\n",
       "1023     1.955426e-08    1.933588e-33    5.575818e-03    9.540141e-01   \n",
       "1075     1.534290e-07    6.691055e-51    1.189811e-02    9.683299e-01   \n",
       "1119     1.453660e-05    4.448264e-69    1.695074e-02    6.212534e-03   \n",
       "1143     2.248206e-03    2.983601e-67    1.658622e-02    1.855184e-10   \n",
       "1324     1.554939e-02   7.185461e-108    9.834119e-01    8.754339e-06   \n",
       "...               ...             ...             ...             ...   \n",
       "58259    9.506230e-01    3.919347e-19    1.088429e-08    4.776678e-53   \n",
       "58495    4.423375e-06   5.245683e-135    3.093217e-02    6.584733e-04   \n",
       "58817    1.357521e-02    1.354575e-85    9.825699e-01    1.621915e-05   \n",
       "59239    1.928676e-05    1.475646e-72    3.403805e-02    4.186966e-03   \n",
       "59287    2.105141e-03    2.670259e-78    9.761934e-01    5.353399e-04   \n",
       "\n",
       "       p(k = 4.0 | x)  p(k = 5.0 | x)  p(k = 6.0 | x)  p(k = 7.0 | x)  \\\n",
       "1023     8.956306e-04    1.217764e-02    2.786154e-07    2.615120e-02   \n",
       "1075     1.097713e-04    1.592452e-02    4.240165e-10    3.710179e-03   \n",
       "1119     1.982746e-06    9.765995e-01    4.207030e-13    1.973741e-04   \n",
       "1143     1.384626e-04    9.800644e-01    1.716995e-09    3.978766e-04   \n",
       "1324     2.712940e-04    6.644191e-04    9.478339e-13    7.404420e-05   \n",
       "...               ...             ...             ...             ...   \n",
       "58259    3.097477e-02    2.055323e-10    1.809941e-02    1.982444e-07   \n",
       "58495    1.874732e-09    9.684046e-01    2.150363e-21    1.501662e-07   \n",
       "58817    3.035202e-03    7.263820e-06    3.056801e-09    2.781761e-06   \n",
       "59239    8.013416e-06    9.607569e-01    2.397849e-13    9.600860e-04   \n",
       "59287    7.759609e-04    3.385634e-04    4.743377e-08    1.813506e-02   \n",
       "\n",
       "       p(k = 8.0 | x)  p(k = 9.0 | x)  given label (name)  out-label  \\\n",
       "1023     3.179590e-05    1.153464e-03                 7.0        3.0   \n",
       "1075     2.943747e-06    2.440332e-05                 7.0        3.0   \n",
       "1119     2.244042e-05    9.238985e-07                 3.0        5.0   \n",
       "1143     5.645939e-04    2.209910e-07                 2.0        5.0   \n",
       "1324     2.015312e-05    2.234518e-09                 5.0        2.0   \n",
       "...               ...             ...                 ...        ...   \n",
       "58259    3.025693e-04    3.685223e-10                 6.0        0.0   \n",
       "58495    1.613687e-07    1.208344e-15                 3.0        5.0   \n",
       "58817    7.933780e-04    5.793771e-09                 8.0        2.0   \n",
       "59239    2.715815e-05    3.586618e-06                 3.0        5.0   \n",
       "59287    4.965533e-05    1.866842e-03                 9.0        2.0   \n",
       "\n",
       "       model pred labels  true labels  \n",
       "1023                   7            7  \n",
       "1075                   7            7  \n",
       "1119                   3            3  \n",
       "1143                   2            2  \n",
       "1324                   5            5  \n",
       "...                  ...          ...  \n",
       "58259                  6            6  \n",
       "58495                  3            3  \n",
       "58817                  8            8  \n",
       "59239                  3            3  \n",
       "59287                  9            9  \n",
       "\n",
       "[439 rows x 14 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_probs_df[(posterior_probs_df[\"given label (name)\"] == posterior_probs_df[\"true labels\"]) & (posterior_probs_df[posterior_probs_df.columns[:-4]] > 0.95).any(1) & (posterior_probs_df[\"out-label\"] != posterior_probs_df[\"true labels\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
