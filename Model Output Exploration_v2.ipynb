{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e600d897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a900432bceff44a9809e0d769e3fd8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d21341ef5b6474aa9fff6ce5312b5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34ba2e17c1144e99e662e2bfc6a9d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843954a909f74c92af10cd6c96b6d31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    "    download = True,\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "98301007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "\n",
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_num):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # fully connected layer, output out_num values\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, out_num),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "77e4c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model helper functions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def generate(model, loaders):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Generate outputs from random model\n",
    "    total_step = len(loaders['train'])\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            images = images.to(device)\n",
    "            try:\n",
    "                output = model(images)\n",
    "            except:\n",
    "                output = model(images.unsqueeze(1).float())\n",
    "            yield output\n",
    "\n",
    "def create_dataset_labels(outputs_generator):\n",
    "    outputs_list = []\n",
    "    for output in outputs_generator:\n",
    "        output = output.cpu()\n",
    "        outputs_list.append(output)\n",
    "    outputs_tensor = torch.cat(outputs_list).squeeze()\n",
    "    return outputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba1ec20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mislabeling dataset class\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "\n",
    "class Mislabeling_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    a Dataset class that contains a Dataset, providing the data of the internal Dataset\n",
    "    but with labeling errors\n",
    "    \"\"\"\n",
    "    def __init__(self, internal_dataset, internal_dataset_labels = None, fraction_mislabeled = 0.1, random_state = None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.internal_dataset = copy.deepcopy(internal_dataset)\n",
    "        self.true_labels = copy.deepcopy(internal_dataset_labels)\n",
    "        if self.true_labels is None:\n",
    "            self.set_true_labels()\n",
    "        elif len(self.true_labels) != len(internal_dataset):\n",
    "          raise Exception(\"Must have same number of labels as the length of the dataset [i.e. len(internal_dataset_labels) == len(internal_dataset)]\")\n",
    "        self.classes = unique_labels(self.true_labels)\n",
    "        self.fraction_mislabeled = fraction_mislabeled\n",
    "        self.rng = np.random.default_rng(random_state)\n",
    "        # could potentially add a parameter to choose what method to mislabel (e.g., completely random, half mislabeled from each class)\n",
    "\n",
    "\n",
    "        self.mislabel_sample_inds = self.rng.choice(np.arange(len(self.internal_dataset)), \\\n",
    "                                                    size=int(self.fraction_mislabeled*len(internal_dataset)), \\\n",
    "                                                    replace=False)\n",
    "        mislabel_maps = [[class_j for class_j in self.classes if class_j != class_i] for class_i in self.classes]\n",
    "\n",
    "        self.labels = copy.deepcopy(self.true_labels)\n",
    "        for ind in self.mislabel_sample_inds:\n",
    "            self.labels[ind] = mislabel_maps[self.true_labels[ind]][self.rng.integers(len(self.classes)-1)]\n",
    "\n",
    "\n",
    "    def set_true_labels(self):\n",
    "        # helper function used by __init__()\n",
    "        self.true_labels = np.zeros(len(self.internal_dataset), dtype=object)\n",
    "        for i in range(len(self.internal_dataset)):\n",
    "            self.true_labels[i] = self.internal_dataset[i][1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.internal_dataset[idx][0], self.labels[idx].item()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.internal_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "279fdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mislabled dataset\n",
    "\n",
    "mislabeled_train_data = Mislabeling_Dataset(train_data, internal_dataset_labels=train_data.targets, \\\n",
    "                                            fraction_mislabeled=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0094495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "832b4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training functioning\n",
    "\n",
    "from torch.autograd import Variable\n",
    "num_epochs = 1\n",
    "\n",
    "def train_CNN(num_epochs, cnn, loaders, optimizer, max_count, count=0):\n",
    "    cnn.train()\n",
    "    if count >= max_count:\n",
    "        print(\"Model failed to converge\")\n",
    "        return True\n",
    "    else:\n",
    "        # Train the model\n",
    "        total_step = len(loaders['train'])\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "                # gives batch data, normalize x when iterate train_loader\n",
    "                b_x = Variable(images).to(device)  # batch x\n",
    "                b_y = Variable(labels).to(device)   # batch y\n",
    "                output = cnn(b_x)\n",
    "                loss = loss_func(output, b_y)\n",
    "\n",
    "                # clear gradients for this training step\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # backpropagation, compute gradients\n",
    "                loss.backward()\n",
    "                # apply gradients\n",
    "                optimizer.step()\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                        .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "        if loss.item() > 2.0:\n",
    "            print(\"Loss too high; doing additional training\", \"\\n\")\n",
    "            return train_CNN(1, cnn, loaders, optimizer, max_count, count=count+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6a621c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def calc_std_ratios(clean_df, mislabeled_df, mislabeled_dict, clean_dict):\n",
    "    ratios_list = []\n",
    "    ratios_dict = {}\n",
    "    for n in range(len(clean_dict.keys())):\n",
    "        ratios_dict[n] = np.std(np.sort(mislabeled_df[n].values) \\\n",
    "                                [:(len(mislabeled_df[n].values) - mislabeled_dict[n])]) / \\\n",
    "                         np.std(np.sort(clean_df[n].values) \\\n",
    "                                [:(len(clean_df[n].values) - clean_dict[n])])\n",
    "        ratios_list.append(ratios_dict[n])\n",
    "    return np.mean(ratios_list), ratios_dict\n",
    "\n",
    "def calc_means(mislabeled_df, mislabeled_dict):\n",
    "    means_list = []\n",
    "    means_dict = {}\n",
    "    for n in range(len(mislabeled_df.columns)):\n",
    "        means_dict[n] = np.mean(np.sort(mislabeled_df[n].values) \\\n",
    "                                [:(len(mislabeled_df[n].values) - mislabeled_dict[n])])\n",
    "        means_list.append(means_dict[n])\n",
    "    return np.mean(means_list), means_dict\n",
    "\n",
    "def calc_overall_mean(mislabeled_df):\n",
    "    mislabeled_array = mislabeled_df.to_numpy()\n",
    "    new_shape = np.prod(mislabeled_array.shape)\n",
    "    reshaped_array = np.reshape(mislabeled_array, new_shape)\n",
    "    mean_ = np.mean(np.sort(reshaped_array)[:(len(reshaped_array) - mislabeled_array.shape[0])])\n",
    "    return mean_\n",
    "\n",
    "def softmaxed_outputs_array(model, loaders):\n",
    "    model_outputs = create_dataset_labels(generate(model, loaders))\n",
    "    m = nn.Softmax(dim=1)\n",
    "    softmaxed_array = m(model_outputs).numpy()\n",
    "    return softmaxed_array\n",
    "\n",
    "def outputs_hist(data_array, model_title, single=False):\n",
    "    if not single:\n",
    "        for col in range(data_array.shape[1]):\n",
    "            plt.figure()\n",
    "            plt.hist(data_array[:,col], bins=100)\n",
    "            plt.title(\"outputs for class {}, {}\".format(col, model_title))\n",
    "            plt.xlabel(\"value\")\n",
    "            plt.ylabel(\"counts\")\n",
    "            plt.show()\n",
    "    else:\n",
    "        new_shape = np.prod(data_array.shape)\n",
    "        reshaped_data = np.reshape(data_array, new_shape)\n",
    "        plt.figure()\n",
    "        plt.hist(reshaped_data, bins=100)\n",
    "        plt.title(\"outputs for all classes, {}\".format(model_title))\n",
    "        plt.xlabel(\"value\")\n",
    "        plt.ylabel(\"counts\")\n",
    "        plt.show()\n",
    "\n",
    "def num_mislabeled_dict(dataset):\n",
    "    num_samples_dict = {}\n",
    "    for class_ in range(len(dataset.classes)):\n",
    "        try:\n",
    "            num_samples_dict[class_] = sum(dataset.labels.numpy() == class_)\n",
    "        except:\n",
    "            num_samples_dict[class_] = sum(dataset.targets.numpy() == class_)\n",
    "    return num_samples_dict\n",
    "\n",
    "def calc_ideal_dist(dataset, bins):\n",
    "    num_ones = len(dataset)\n",
    "    num_zeros = num_ones * (len(dataset.classes) - 1)\n",
    "    counts = np.zeros(bins)\n",
    "    counts[0] = num_zeros\n",
    "    counts[-1] = num_ones\n",
    "    return counts\n",
    "\n",
    "def angular_similarity(vec1, vec2):\n",
    "    cosine_similarity = np.dot(vec1, vec2) / ( np.linalg.norm(vec1) * np.linalg.norm(vec2) )\n",
    "    angular_distance = np.arccos(cosine_similarity) / np.pi\n",
    "    similarity = 1 - angular_distance\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "83082969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go again with a different percentage and define a function to help out\n",
    "\n",
    "def mislabeling_statistics(error_percentage, training_dataset, clean_df, clean_dict, epochs, plot=False):\n",
    "    mislabeled_dataset = Mislabeling_Dataset(training_dataset, internal_dataset_labels=training_dataset.targets, \\\n",
    "                                             fraction_mislabeled=error_percentage, random_state=0)\n",
    "    model_mislabeled_stats = CNN(len(training_dataset.classes)).to(device)\n",
    "    optimizer_mislabeled_stats = optim.Adam(model_mislabeled_stats.parameters(), lr = 0.01)\n",
    "    loaders_mislabeled_stats = {\n",
    "    'train' : torch.utils.data.DataLoader(mislabeled_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0),\n",
    "\n",
    "    'test' : torch.utils.data.DataLoader(training_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0),\n",
    "    }\n",
    "    print(\"training {}% mislabeled model\".format(error_percentage*100))\n",
    "    converge_fail = train_CNN(epochs, model_mislabeled_stats, loaders_mislabeled_stats, optimizer_mislabeled_stats, max_count=5, count=0)\n",
    "    if converge_fail:\n",
    "        print(\"Skipping:\", error_percentage, \"\\n\")\n",
    "        return None\n",
    "    else:\n",
    "        outputs_mislabeled_stats = softmaxed_outputs_array(model_mislabeled_stats, loaders_mislabeled_stats)\n",
    "        if plot:\n",
    "            outputs_hist(outputs_mislabeled_stats, \"{}% mislabeled model\".format(error_percentage*100), single=True)\n",
    "        mislabeled_stats_df = pd.DataFrame(outputs_mislabeled_stats)\n",
    "        mislabeled_stats_dict = num_mislabeled_dict(mislabeled_dataset)\n",
    "        mean_std_out, std_dict_out = calc_std_ratios(clean_df, mislabeled_stats_df, mislabeled_stats_dict, clean_dict)\n",
    "        mean_out, mean_dict_out = calc_means(mislabeled_stats_df, mislabeled_stats_dict)\n",
    "        overall_mean = calc_overall_mean(mislabeled_stats_df)\n",
    "        print(overall_mean, \"\\n\")\n",
    "        del model_mislabeled_stats\n",
    "        return mean_out, mean_dict_out, mean_std_out, std_dict_out, overall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "914ddb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do something with cosine similarity of the distributions now\n",
    "\n",
    "def mislabeling_dist_similarity(error_percentage, training_dataset, epochs, num_bins, plot=False):\n",
    "    mislabeled_dataset = Mislabeling_Dataset(training_dataset, internal_dataset_labels=training_dataset.targets, \\\n",
    "                                             fraction_mislabeled=error_percentage, random_state=0)\n",
    "    model_mislabeled_stats = CNN(len(training_dataset.classes)).to(device)\n",
    "    optimizer_mislabeled_stats = optim.Adam(model_mislabeled_stats.parameters(), lr = 0.01)\n",
    "    loaders_mislabeled_stats = {\n",
    "    'train' : torch.utils.data.DataLoader(mislabeled_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0),\n",
    "\n",
    "    'test' : torch.utils.data.DataLoader(training_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0),\n",
    "    }\n",
    "    print(\"training {}% mislabeled model\".format(error_percentage*100))\n",
    "    converge_fail = train_CNN(epochs, model_mislabeled_stats, loaders_mislabeled_stats, optimizer_mislabeled_stats, max_count=5, count=0)\n",
    "    if converge_fail:\n",
    "        print(\"Skipping:\", error_percentage, \"\\n\")\n",
    "        return None\n",
    "    else:\n",
    "        outputs_mislabeled_stats = softmaxed_outputs_array(model_mislabeled_stats, loaders_mislabeled_stats)\n",
    "        if plot:\n",
    "            outputs_hist(outputs_mislabeled_stats, \"{}% mislabeled model\".format(error_percentage*100), single=True)\n",
    "        outputs_mislabeled_vector = np.reshape(outputs_mislabeled_stats, np.prod(outputs_mislabeled_stats.shape))\n",
    "        counts, bins = np.histogram(outputs_mislabeled_vector, bins=num_bins)\n",
    "        ideal_counts = calc_ideal_dist(training_dataset, bins=num_bins)\n",
    "        \n",
    "        # Calculate similarity between sample distribution and ideal distribution\n",
    "        similarity = angular_similarity(counts, ideal_counts)\n",
    "        \n",
    "        del model_mislabeled_stats\n",
    "        print(\"Similarity to Ideal:\", similarity, \"\\n\")\n",
    "        \n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "79c5faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a bunch of different error percentages\n",
    "\n",
    "def error_percentage_looper(bound1, bound2, plot=True):\n",
    "    error_percent_list = []\n",
    "    similarity_list = []\n",
    "    \n",
    "    for n in range(bound1, bound2+1):\n",
    "        if plot:\n",
    "            similarity = mislabeling_dist_similarity(n/100, train_data, epochs=1, plot=True, num_bins=100)\n",
    "        else:\n",
    "            similarity = mislabeling_dist_similarity(n/100, train_data, epochs=1, plot=False, num_bins=100)\n",
    "            \n",
    "        if similarity != None:\n",
    "            error_percent_list.append(n/100)\n",
    "            similarity_list.append(similarity)\n",
    "    return error_percent_list, similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "52346972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_looper(bound1, bound2, num_trials, plot=True):\n",
    "    trials_dict = {}\n",
    "    for n in range(num_trials):\n",
    "        if plot:\n",
    "            list_1, list_2 = error_percentage_looper(bound1, bound2)\n",
    "        else:\n",
    "            list_1, list_2 = error_percentage_looper(bound1, bound2, plot=False)\n",
    "        data_array = np.array([list_1, list_2]).transpose()\n",
    "        trials_dict[\"trial {}\".format((n+1))] = data_array\n",
    "    return trials_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b710d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 1\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1493\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1500\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1402\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0605\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2420\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2873\n",
      "Similarity to Ideal: 0.9900659104182767 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0774\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0732\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4261\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4642\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3449\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2762\n",
      "Similarity to Ideal: 0.977024908824618 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3186\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1469\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3387\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1877\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2987\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3211\n",
      "Similarity to Ideal: 0.9781275093105011 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2754\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1875\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6456\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2778\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5034\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3023\n",
      "Similarity to Ideal: 0.9753937846093217 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3863\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4068\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8929\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3156\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4885\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4884\n",
      "Similarity to Ideal: 0.9511260620093369 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3968\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6473\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8966\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4503\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6771\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5761\n",
      "Similarity to Ideal: 0.9485943626740915 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5736\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5963\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0822\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3922\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6195\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6579\n",
      "Similarity to Ideal: 0.9162411476394658 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6259\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7431\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9945\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4747\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7513\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6582\n",
      "Similarity to Ideal: 0.9144846713968677 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7448\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9322\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0592\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6989\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6821\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7030\n",
      "Similarity to Ideal: 0.9091860527308834 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9199\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0226\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9812\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5574\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8085\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8076\n",
      "Similarity to Ideal: 0.8856329753448855 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0938\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0761\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2428\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7478\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0506\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9262\n",
      "Similarity to Ideal: 0.8924302076241091 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2988\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3083\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2935\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3086\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3087\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3087\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3087\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.11 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7956\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9559\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0616\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7653\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9099\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6798\n",
      "Similarity to Ideal: 0.8953748840198533 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9917\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3258\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2758\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8560\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1302\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9136\n",
      "Similarity to Ideal: 0.8259989269949962 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1226\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2727\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0773\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7566\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2083\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7444\n",
      "Similarity to Ideal: 0.9114289335478607 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1159\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2166\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1553\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8982\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2111\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8813\n",
      "Similarity to Ideal: 0.8405865229530145 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0237\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3117\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1177\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9389\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1292\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8722\n",
      "Similarity to Ideal: 0.8568501157548162 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3215\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4089\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2337\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0548\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2076\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0318\n",
      "Similarity to Ideal: 0.7892375071025349 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1541\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3908\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1013\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8808\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2722\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8718\n",
      "Similarity to Ideal: 0.7703899960825576 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2802\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4974\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2013\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0821\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5103\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0602\n",
      "Similarity to Ideal: 0.6786087033641226 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3396\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5363\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2841\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0389\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5228\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9648\n",
      "Similarity to Ideal: 0.677068476052631 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3236\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5903\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3135\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2594\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3087\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8988\n",
      "Similarity to Ideal: 0.6928938056341982 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4151\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6762\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4461\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2455\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4214\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1562\n",
      "Similarity to Ideal: 0.6421528415303264 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4840\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4735\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3808\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1603\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5492\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1318\n",
      "Similarity to Ideal: 0.6303128586680524 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3613\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4831\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4018\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1910\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5987\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1300\n",
      "Similarity to Ideal: 0.6483550588410371 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4215\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3974\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4835\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1480\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5686\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1747\n",
      "Similarity to Ideal: 0.6047365633580104 \n",
      "\n",
      "Trial: 2\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0865\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1320\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0834\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0403\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1616\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3518\n",
      "Similarity to Ideal: 0.9961705399404934 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2045\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0672\n",
      "Epoch [1/1], Step [300/600], Loss: 0.5102\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4957\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4255\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2862\n",
      "Similarity to Ideal: 0.9768345040059517 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4235\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1278\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2554\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1631\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2085\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4072\n",
      "Similarity to Ideal: 0.9812155068482332 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2899\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2009\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7373\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3009\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5330\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2612\n",
      "Similarity to Ideal: 0.9672661243575305 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3881\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4933\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9648\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2814\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5044\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3629\n",
      "Similarity to Ideal: 0.9481277149106951 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3176\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7755\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8583\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3145\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6147\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5679\n",
      "Similarity to Ideal: 0.9319845631300636 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5593\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6941\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9991\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4643\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6085\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5893\n",
      "Similarity to Ideal: 0.9227579153294614 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5945\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6581\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9465\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3944\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6562\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6343\n",
      "Similarity to Ideal: 0.927845903766254 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6527\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9359\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9133\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6489\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6790\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6101\n",
      "Similarity to Ideal: 0.903532501876819 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9521\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9056\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9309\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5737\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7769\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8186\n",
      "Similarity to Ideal: 0.9038400221613498 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9356\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0627\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2602\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7372\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0075\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8613\n",
      "Similarity to Ideal: 0.8951664636314753 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8936\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9509\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9769\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5933\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9253\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7507\n",
      "Similarity to Ideal: 0.8980821658498147 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8076\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0278\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1254\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7431\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9247\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8077\n",
      "Similarity to Ideal: 0.8811981499085488 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0241\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1440\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0599\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8055\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0966\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8119\n",
      "Similarity to Ideal: 0.821179034921455 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1750\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2385\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1222\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7634\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1115\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7839\n",
      "Similarity to Ideal: 0.868720267589209 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0631\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1923\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0874\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8691\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1016\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7786\n",
      "Similarity to Ideal: 0.8288315230183008 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0082\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3115\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1232\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9957\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0846\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8675\n",
      "Similarity to Ideal: 0.8736548070380039 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2673\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4738\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2007\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0132\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1970\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0280\n",
      "Similarity to Ideal: 0.7936411908026474 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2380\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3495\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1305\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9246\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2668\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9521\n",
      "Similarity to Ideal: 0.7664270022191881 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4250\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5043\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2516\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0342\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2938\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0525\n",
      "Similarity to Ideal: 0.6858849662445532 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3332\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5308\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1926\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0580\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2990\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9401\n",
      "Similarity to Ideal: 0.7478471559858431 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4881\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5896\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2637\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1342\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4117\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9256\n",
      "Similarity to Ideal: 0.6400394876713447 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4744\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6761\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4929\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2015\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4293\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0417\n",
      "Similarity to Ideal: 0.6178569893083572 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3795\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4863\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4466\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1058\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5032\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1274\n",
      "Similarity to Ideal: 0.6539492964063242 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2978\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3007\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2930\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.8416\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6531\n",
      "Epoch [1/1], Step [300/600], Loss: 1.5156\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2767\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5756\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1878\n",
      "Similarity to Ideal: 0.6113396007696785 \n",
      "\n",
      "Trial: 3\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0646\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0997\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1750\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0822\n",
      "Epoch [1/1], Step [500/600], Loss: 0.0954\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3852\n",
      "Similarity to Ideal: 0.995883832898705 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0907\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1211\n",
      "Epoch [1/1], Step [300/600], Loss: 0.5353\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3836\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3370\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2853\n",
      "Similarity to Ideal: 0.9697050395213962 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4118\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1567\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3223\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1284\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2781\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3009\n",
      "Similarity to Ideal: 0.979222425419996 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1403\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6895\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2970\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5396\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3112\n",
      "Similarity to Ideal: 0.961202917999989 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4005\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3487\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9403\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3318\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4650\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3595\n",
      "Similarity to Ideal: 0.9628771444865121 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3845\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6426\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9045\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3798\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7397\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5329\n",
      "Similarity to Ideal: 0.9387393832204252 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5004\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7452\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0373\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4149\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5656\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6328\n",
      "Similarity to Ideal: 0.9310117801847192 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5994\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6429\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9401\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4785\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7119\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6191\n",
      "Similarity to Ideal: 0.9030282538779126 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7241\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9761\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9715\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7127\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6925\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7303\n",
      "Similarity to Ideal: 0.9185232683361855 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8832\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9674\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9133\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5397\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7771\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7712\n",
      "Similarity to Ideal: 0.8803266443885497 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9735\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8961\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0355\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6047\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8765\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8127\n",
      "Similarity to Ideal: 0.9054102666471858 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0248\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0955\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0682\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6793\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9811\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8253\n",
      "Similarity to Ideal: 0.8757196528853469 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8770\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0015\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0613\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7589\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9288\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7335\n",
      "Similarity to Ideal: 0.8787404372562388 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1691\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2787\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1800\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8008\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1121\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8844\n",
      "Similarity to Ideal: 0.8492182126857397 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0065\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1595\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1911\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7774\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1913\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8063\n",
      "Similarity to Ideal: 0.8691387498914109 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1215\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1822\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1619\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8628\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1184\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8055\n",
      "Similarity to Ideal: 0.7801293751321647 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1107\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3175\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1543\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0569\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1440\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8946\n",
      "Similarity to Ideal: 0.7984432508427703 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3603\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5274\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2760\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1314\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2580\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0128\n",
      "Similarity to Ideal: 0.7485575331890084 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1849\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5451\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1828\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8762\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3431\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0346\n",
      "Similarity to Ideal: 0.8292882559369245 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3259\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3817\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1951\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9977\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4164\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9497\n",
      "Similarity to Ideal: 0.7424652552017884 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2968\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3038\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.2 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2968\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3023\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3005\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.21 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4772\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5515\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3742\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1298\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4488\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1801\n",
      "Similarity to Ideal: 0.6242208901279236 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4169\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4367\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3961\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1110\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3905\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0020\n",
      "Similarity to Ideal: 0.655753803773014 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3673\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5107\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3433\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2006\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5881\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0553\n",
      "Similarity to Ideal: 0.6369627862090812 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3523\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4949\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4357\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0788\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4865\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0603\n",
      "Similarity to Ideal: 0.643241259861165 \n",
      "\n",
      "Trial: 4\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0712\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0974\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0815\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0889\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1229\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3857\n",
      "Similarity to Ideal: 0.9919361730182509 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1387\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1528\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4517\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3642\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4190\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2517\n",
      "Similarity to Ideal: 0.9770712685305163 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3928\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1122\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2815\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1485\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1809\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2928\n",
      "Similarity to Ideal: 0.9776505620913453 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3054\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1585\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7503\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2680\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5872\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2665\n",
      "Similarity to Ideal: 0.9654213414390896 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3647\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2605\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9524\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3138\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4729\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3997\n",
      "Similarity to Ideal: 0.9509888765915154 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3389\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6964\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9120\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4133\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6216\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5177\n",
      "Similarity to Ideal: 0.9250307370588476 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5699\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6302\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0153\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4993\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6487\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6856\n",
      "Similarity to Ideal: 0.9212933835393389 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5594\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6960\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9952\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4936\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7938\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6409\n",
      "Similarity to Ideal: 0.9035715574637353 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7023\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9056\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9631\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5878\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7255\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6270\n",
      "Similarity to Ideal: 0.9011689477854097 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9128\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9940\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0008\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6011\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8626\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9152\n",
      "Similarity to Ideal: 0.9015836717913268 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0501\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0902\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0402\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7240\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0224\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8911\n",
      "Similarity to Ideal: 0.8783165089546505 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8964\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9690\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9695\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5959\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9056\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7110\n",
      "Similarity to Ideal: 0.9137422421754522 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7634\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0707\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1067\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7252\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9151\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7451\n",
      "Similarity to Ideal: 0.8882527086936457 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1453\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2119\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2159\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8888\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1189\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8259\n",
      "Similarity to Ideal: 0.8681114391996528 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4078\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4341\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3327\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8533\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2073\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8331\n",
      "Similarity to Ideal: 0.8763543515444648 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2067\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3192\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2970\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8562\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2352\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8856\n",
      "Similarity to Ideal: 0.8394473490048983 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9636\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3052\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1872\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9308\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0390\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8400\n",
      "Similarity to Ideal: 0.8388939433619602 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2814\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3935\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1349\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9767\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2222\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9091\n",
      "Similarity to Ideal: 0.7355733939185078 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2948\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.18 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2966\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5369\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1874\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9355\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3683\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9331\n",
      "Similarity to Ideal: 0.7501230949626025 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5188\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6325\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2059\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0614\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5953\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9161\n",
      "Similarity to Ideal: 0.7473232192078555 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3087\n",
      "Epoch [1/1], Step [200/600], Loss: 1.7092\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1783\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1026\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2763\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9361\n",
      "Similarity to Ideal: 0.6269888286496585 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4126\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4221\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4202\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1596\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4374\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0831\n",
      "Similarity to Ideal: 0.6125327546614501 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4389\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6027\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4554\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2512\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5402\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1152\n",
      "Similarity to Ideal: 0.5926100655989075 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2930\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4461\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4593\n",
      "Epoch [1/1], Step [300/600], Loss: 1.5288\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2217\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5790\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1697\n",
      "Similarity to Ideal: 0.5963898299708912 \n",
      "\n",
      "Trial: 5\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0333\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0399\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1327\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0530\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2675\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2768\n",
      "Similarity to Ideal: 0.9948801585131833 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0947\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0767\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4582\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3192\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4095\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2653\n",
      "Similarity to Ideal: 0.9770737116327379 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4009\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1498\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2613\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1841\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2637\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2681\n",
      "Similarity to Ideal: 0.9811207746215168 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3249\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1727\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7236\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3459\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5673\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3206\n",
      "Similarity to Ideal: 0.9674046716882928 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4085\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4484\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9576\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3966\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5743\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3786\n",
      "Similarity to Ideal: 0.9556660644404672 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2952\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3095\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2973\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2973\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2973\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2973\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.05 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5612\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6671\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0704\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4180\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6479\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6066\n",
      "Similarity to Ideal: 0.9258148461354335 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6170\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7457\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0934\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5105\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7735\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7622\n",
      "Similarity to Ideal: 0.9154524681681611 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7098\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9239\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0230\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6854\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6198\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7377\n",
      "Similarity to Ideal: 0.8536887802908073 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9392\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9753\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9892\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6213\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7639\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7277\n",
      "Similarity to Ideal: 0.9032874601555992 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9130\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9736\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0833\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6345\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9077\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8465\n",
      "Similarity to Ideal: 0.8724639326990372 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9141\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9449\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0617\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6230\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9872\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8156\n",
      "Similarity to Ideal: 0.8739361679400001 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8982\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0764\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0829\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7025\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8626\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7674\n",
      "Similarity to Ideal: 0.9224112633416512 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1378\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3926\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2030\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8250\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0912\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8564\n",
      "Similarity to Ideal: 0.8523603419318163 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1473\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2614\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0781\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7340\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1451\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8584\n",
      "Similarity to Ideal: 0.8481225097259352 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1399\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0514\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1844\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8398\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1371\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8585\n",
      "Similarity to Ideal: 0.820949862303133 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1302\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3992\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1582\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9306\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1934\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8609\n",
      "Similarity to Ideal: 0.843837499344672 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2946\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4788\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1172\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1702\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2265\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9425\n",
      "Similarity to Ideal: 0.7897890462082546 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2361\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3841\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0994\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9119\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2488\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9286\n",
      "Similarity to Ideal: 0.750481605329595 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3001\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2942\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3061\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3017\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3062\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3028\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.19 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4199\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5097\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2493\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0895\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4553\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0098\n",
      "Similarity to Ideal: 0.7067823242652047 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3148\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6620\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1996\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1142\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3313\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9699\n",
      "Similarity to Ideal: 0.7103596849382297 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3032\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4543\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3517\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1106\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4038\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9732\n",
      "Similarity to Ideal: 0.6384879212486442 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4977\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5577\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3919\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1135\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5453\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1243\n",
      "Similarity to Ideal: 0.5976159601780688 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3906\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5514\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4070\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1994\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5385\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0399\n",
      "Similarity to Ideal: 0.6172081097415856 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3837\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4759\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3371\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0937\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4534\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1629\n",
      "Similarity to Ideal: 0.6925682291269262 \n",
      "\n",
      "Trial: 6\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0410\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0863\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0705\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0911\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1291\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2621\n",
      "Similarity to Ideal: 0.9944161184372556 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1414\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0982\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4710\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4400\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2796\n",
      "Similarity to Ideal: 0.9802904083576003 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3845\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0622\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3543\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1649\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2001\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3140\n",
      "Similarity to Ideal: 0.9787456287701715 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3052\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1227\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7585\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2708\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5809\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2862\n",
      "Similarity to Ideal: 0.9711380398493108 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4067\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3620\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8850\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3329\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5838\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3690\n",
      "Similarity to Ideal: 0.9495759860076625 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3639\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6922\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8272\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3499\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6915\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5726\n",
      "Similarity to Ideal: 0.927359233994245 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5260\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7054\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0115\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4532\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6726\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5916\n",
      "Similarity to Ideal: 0.9346644992325043 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6080\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6623\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9450\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4803\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6917\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6250\n",
      "Similarity to Ideal: 0.9202443686262062 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2976\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2972\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.08 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9739\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9382\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9108\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5817\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7885\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8359\n",
      "Similarity to Ideal: 0.9208501589026286 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9464\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0321\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1564\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6344\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9607\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8266\n",
      "Similarity to Ideal: 0.8864358745250374 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7994\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9812\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9285\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6182\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9757\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7488\n",
      "Similarity to Ideal: 0.8515706018443829 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8885\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0768\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1240\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7853\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0359\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7939\n",
      "Similarity to Ideal: 0.8800343487815994 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9685\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1697\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0641\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8388\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0988\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7747\n",
      "Similarity to Ideal: 0.8790428114948923 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1621\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2997\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0274\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8407\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2070\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8308\n",
      "Similarity to Ideal: 0.8588276962839894 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0891\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1995\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1150\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8505\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1416\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8265\n",
      "Similarity to Ideal: 0.8121001883247694 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0385\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3654\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2826\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9446\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0948\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8539\n",
      "Similarity to Ideal: 0.8555810148819281 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1665\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4144\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2037\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0127\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1302\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9073\n",
      "Similarity to Ideal: 0.7625953119527891 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1822\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4785\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0961\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8686\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2448\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8465\n",
      "Similarity to Ideal: 0.7838510171577731 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3001\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2941\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3061\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3017\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3062\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3028\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3083\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.19 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3333\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4772\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2915\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9584\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3724\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8618\n",
      "Similarity to Ideal: 0.7351159456298926 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4276\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5433\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2851\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1983\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3205\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9558\n",
      "Similarity to Ideal: 0.7522480350617545 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5130\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4709\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3536\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1460\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3779\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0755\n",
      "Similarity to Ideal: 0.6689840020413814 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5293\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6190\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3879\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1857\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6108\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1787\n",
      "Similarity to Ideal: 0.6726966685334328 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2977\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2930\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2986\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3065\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 7\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0645\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1125\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0968\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1686\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1199\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5978\n",
      "Similarity to Ideal: 0.9895212024830844 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1184\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1186\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4937\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4806\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4321\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3314\n",
      "Similarity to Ideal: 0.9796331442581228 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3852\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0604\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2657\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1260\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2397\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3244\n",
      "Similarity to Ideal: 0.979042200136184 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2966\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3078\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3115\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3005\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2961\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2979\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3115\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2960\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2978\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3115\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2960\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2978\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3115\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2960\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2978\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3115\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.03 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4006\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4715\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9276\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3789\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6121\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4877\n",
      "Similarity to Ideal: 0.9363539588632148 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3504\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7599\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8926\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3309\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6558\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4674\n",
      "Similarity to Ideal: 0.9461208450038908 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5208\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6407\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8847\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3277\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6112\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6376\n",
      "Similarity to Ideal: 0.925651985906332 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5430\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6888\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0005\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4473\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7718\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6505\n",
      "Similarity to Ideal: 0.9115106147723907 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.08 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8156\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9010\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9745\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5844\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8549\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8166\n",
      "Similarity to Ideal: 0.8775377958056847 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3011\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3070\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3044\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.1 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0074\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9287\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0545\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7465\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0699\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8558\n",
      "Similarity to Ideal: 0.8437028806393797 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8705\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1038\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0905\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8282\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0091\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7836\n",
      "Similarity to Ideal: 0.8960389826865767 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0181\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2279\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1178\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7945\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1298\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7379\n",
      "Similarity to Ideal: 0.8615028568980819 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1996\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1180\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1160\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7176\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1908\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7429\n",
      "Similarity to Ideal: 0.8719131095416884 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0530\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1377\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1750\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8456\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1609\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8138\n",
      "Similarity to Ideal: 0.8510822092536017 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9430\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4713\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1618\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0052\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0549\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9373\n",
      "Similarity to Ideal: 0.8056849926195637 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1937\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3350\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1676\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0186\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2678\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9308\n",
      "Similarity to Ideal: 0.8566446872633517 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2727\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4828\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1837\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9850\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2909\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0194\n",
      "Similarity to Ideal: 0.7399714028431874 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3391\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4369\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1866\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0242\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4590\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9133\n",
      "Similarity to Ideal: 0.7527232140539521 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3412\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4342\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2239\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0479\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4467\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8264\n",
      "Similarity to Ideal: 0.80164478974672 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3842\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5071\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2395\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1741\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3130\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9842\n",
      "Similarity to Ideal: 0.6735303639771606 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4783\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5792\n",
      "Epoch [1/1], Step [300/600], Loss: 1.5252\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1888\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4023\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1196\n",
      "Similarity to Ideal: 0.6387322864422484 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3474\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5705\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4138\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0908\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5452\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1443\n",
      "Similarity to Ideal: 0.5952021479221059 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2553\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5659\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4087\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2237\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4147\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0853\n",
      "Similarity to Ideal: 0.6349466075271537 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3483\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3392\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3949\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1451\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5060\n",
      "Epoch [1/1], Step [600/600], Loss: 1.2699\n",
      "Similarity to Ideal: 0.6616311046186671 \n",
      "\n",
      "Trial: 8\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1199\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1016\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1930\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0880\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1988\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2485\n",
      "Similarity to Ideal: 0.9931522055803553 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0984\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0622\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4395\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4125\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3790\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2822\n",
      "Similarity to Ideal: 0.9787975603786964 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3817\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0966\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2567\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1497\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2157\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2540\n",
      "Similarity to Ideal: 0.977096253787604 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3096\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1541\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6901\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2953\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5261\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3184\n",
      "Similarity to Ideal: 0.9719174586631216 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3972\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3871\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8847\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2981\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4933\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3860\n",
      "Similarity to Ideal: 0.9548930175112932 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3836\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6543\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8660\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2848\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6672\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5537\n",
      "Similarity to Ideal: 0.9446858340945565 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2959\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3071\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3110\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3043\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3043\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.06 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5820\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7577\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0031\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5021\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6303\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6538\n",
      "Similarity to Ideal: 0.9181585853352278 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7270\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9380\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1070\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7434\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6858\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7188\n",
      "Similarity to Ideal: 0.898059918000422 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0656\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9282\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9724\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6183\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9442\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8683\n",
      "Similarity to Ideal: 0.9012955129579775 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9600\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0556\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0893\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7935\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9385\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8270\n",
      "Similarity to Ideal: 0.8718509408891613 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9409\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0068\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0036\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6787\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0704\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7221\n",
      "Similarity to Ideal: 0.8955158303022519 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9528\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9792\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0559\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7117\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0109\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7227\n",
      "Similarity to Ideal: 0.8762504470879672 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0507\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1126\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1856\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8477\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1241\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7701\n",
      "Similarity to Ideal: 0.8638442460067328 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0914\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2793\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1306\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7561\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1511\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7732\n",
      "Similarity to Ideal: 0.868546211124299 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1663\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1911\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2622\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9578\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3215\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9330\n",
      "Similarity to Ideal: 0.7136299328101288 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0486\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4231\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1780\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9248\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1309\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9042\n",
      "Similarity to Ideal: 0.8172262310900765 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2137\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2611\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1878\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9805\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1049\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8644\n",
      "Similarity to Ideal: 0.8240148708470618 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2666\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3063\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1167\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8985\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3133\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9258\n",
      "Similarity to Ideal: 0.7430047585688526 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3087\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5715\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1475\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0475\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4014\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0548\n",
      "Similarity to Ideal: 0.7120134940998563 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3353\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6289\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1751\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0579\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3846\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8976\n",
      "Similarity to Ideal: 0.6973855034660981 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2723\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5004\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2590\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1115\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3177\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9164\n",
      "Similarity to Ideal: 0.6727776056559527 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2923\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3001\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2759\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5959\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3879\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2158\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5177\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1752\n",
      "Similarity to Ideal: 0.5999078695198594 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4480\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6522\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4327\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1213\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5048\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0827\n",
      "Similarity to Ideal: 0.62267607393356 \n",
      "\n",
      "Trial: 9\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0498\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1138\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1207\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0854\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1481\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2302\n",
      "Similarity to Ideal: 0.9938663535350248 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0912\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0732\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4357\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3370\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3714\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3161\n",
      "Similarity to Ideal: 0.9846488483771977 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3819\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1331\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2805\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1361\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1848\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2486\n",
      "Similarity to Ideal: 0.9772049478981014 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3395\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1255\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7228\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2754\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5893\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2669\n",
      "Similarity to Ideal: 0.9634697178097571 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4253\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4174\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8724\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3597\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4755\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4300\n",
      "Similarity to Ideal: 0.9571855386084753 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3775\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7347\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8973\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2886\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7530\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5584\n",
      "Similarity to Ideal: 0.9408709117004326 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5919\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6502\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9561\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3437\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6320\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6471\n",
      "Similarity to Ideal: 0.9195534245633077 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6540\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6221\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1425\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4591\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7139\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6911\n",
      "Similarity to Ideal: 0.9015676056571741 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7012\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8916\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1238\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6354\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7742\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7837\n",
      "Similarity to Ideal: 0.9103477223871345 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9171\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9183\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8770\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5709\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7493\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7155\n",
      "Similarity to Ideal: 0.9319744810754496 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9159\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9199\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0475\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7450\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9194\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8291\n",
      "Similarity to Ideal: 0.870855980482167 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8388\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0050\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9926\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6367\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9501\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7812\n",
      "Similarity to Ideal: 0.9045138516490653 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9468\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1074\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1524\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8583\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0122\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7319\n",
      "Similarity to Ideal: 0.8846297856271004 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2955\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2911\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3080\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.13 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9989\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1630\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1209\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7138\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1223\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7845\n",
      "Similarity to Ideal: 0.8926117158011744 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1683\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2041\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0746\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7865\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2272\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9000\n",
      "Similarity to Ideal: 0.8254157297543948 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0711\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2829\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1845\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9107\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1471\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8179\n",
      "Similarity to Ideal: 0.8236798601692683 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2987\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3180\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0369\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9492\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1601\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9248\n",
      "Similarity to Ideal: 0.7682433214494524 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2952\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4279\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0821\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9195\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2466\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9159\n",
      "Similarity to Ideal: 0.7905876429254985 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3564\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6173\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2093\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0475\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3841\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0745\n",
      "Similarity to Ideal: 0.7112356193428225 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3188\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4819\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2123\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0859\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3659\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8643\n",
      "Similarity to Ideal: 0.7578894036477356 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2964\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.21 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4855\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5956\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3811\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1290\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4785\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1741\n",
      "Similarity to Ideal: 0.6123958318617697 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2976\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3023\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2987\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4966\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4716\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1720\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5773\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0481\n",
      "Similarity to Ideal: 0.6490846927669717 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3154\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4110\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3493\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1305\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5366\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1179\n",
      "Similarity to Ideal: 0.6478778393747043 \n",
      "\n",
      "Trial: 10\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1174\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0727\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1356\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1320\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1823\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2392\n",
      "Similarity to Ideal: 0.9915571451709426 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0778\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0569\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3852\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3972\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4255\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2770\n",
      "Similarity to Ideal: 0.9805704694595822 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3799\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1195\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2792\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1748\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1905\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2419\n",
      "Similarity to Ideal: 0.9747759749270146 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2868\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1535\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7515\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3203\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4839\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2957\n",
      "Similarity to Ideal: 0.9664874818192364 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4935\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4090\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9624\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3953\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5620\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3917\n",
      "Similarity to Ideal: 0.9478164397530069 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3487\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7466\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7946\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3523\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6496\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5518\n",
      "Similarity to Ideal: 0.9480192730666789 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5400\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6117\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0157\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5071\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6928\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6370\n",
      "Similarity to Ideal: 0.9259951399269792 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6142\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7250\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9715\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4856\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7558\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6410\n",
      "Similarity to Ideal: 0.9201134803542715 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6134\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8995\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0350\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5959\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6651\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6723\n",
      "Similarity to Ideal: 0.8910054852755636 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9688\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9184\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9523\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5324\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8388\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8003\n",
      "Similarity to Ideal: 0.938391588467582 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8994\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9124\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9731\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6383\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8717\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7815\n",
      "Similarity to Ideal: 0.9030129744498271 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8253\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8656\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0478\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6190\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9629\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7791\n",
      "Similarity to Ideal: 0.8705603925817679 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9031\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0269\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0502\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7874\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9751\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7538\n",
      "Similarity to Ideal: 0.9044268637310048 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0640\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2176\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1328\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7777\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0990\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8298\n",
      "Similarity to Ideal: 0.912922466244781 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0910\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1837\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1241\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7647\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1366\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7080\n",
      "Similarity to Ideal: 0.8929121345932415 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0687\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0983\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1462\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8862\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2164\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7505\n",
      "Similarity to Ideal: 0.8409491071609005 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0107\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4351\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1571\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0325\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1236\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9280\n",
      "Similarity to Ideal: 0.8188577471960612 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1530\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3782\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1425\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9604\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1299\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8616\n",
      "Similarity to Ideal: 0.7831479112764014 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3544\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3533\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0862\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9052\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2311\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8801\n",
      "Similarity to Ideal: 0.8321575926154201 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3860\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5247\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2062\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0220\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3276\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9884\n",
      "Similarity to Ideal: 0.7287366562590545 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3306\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4462\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3028\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0611\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3654\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9443\n",
      "Similarity to Ideal: 0.6890529786829085 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3497\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6706\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2144\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1443\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3614\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9256\n",
      "Similarity to Ideal: 0.6827337279692921 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2923\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3020\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3001\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4301\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5407\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3823\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1271\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4631\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0270\n",
      "Similarity to Ideal: 0.6508780411162753 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4066\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5953\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4060\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2298\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6466\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0512\n",
      "Similarity to Ideal: 0.635661143666949 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3641\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4188\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4111\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1222\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5070\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1462\n",
      "Similarity to Ideal: 0.6165321820016862 \n",
      "\n",
      "Trial: 11\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1009\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2000\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2898\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0762\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1625\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3923\n",
      "Similarity to Ideal: 0.9920921406666784 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1179\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0691\n",
      "Epoch [1/1], Step [300/600], Loss: 0.5242\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4039\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3199\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2920\n",
      "Similarity to Ideal: 0.9774375694036948 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3882\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1216\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2282\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1256\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2141\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2519\n",
      "Similarity to Ideal: 0.9762526674306747 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3721\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1921\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8228\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3227\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5376\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2970\n",
      "Similarity to Ideal: 0.9593879895315823 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4293\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3975\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9467\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3360\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5455\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3642\n",
      "Similarity to Ideal: 0.9533266069593167 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3683\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7006\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9061\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3135\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7415\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5242\n",
      "Similarity to Ideal: 0.946289064204637 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5614\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6908\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0284\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4661\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6873\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6137\n",
      "Similarity to Ideal: 0.9161384683008551 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6435\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6817\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0089\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5200\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7344\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6441\n",
      "Similarity to Ideal: 0.9141151037984077 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6586\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0620\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1641\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7892\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6670\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7497\n",
      "Similarity to Ideal: 0.894624874909457 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9972\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0275\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9683\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5852\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7742\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8337\n",
      "Similarity to Ideal: 0.8916880714791411 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9909\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0195\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0346\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6983\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9230\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8115\n",
      "Similarity to Ideal: 0.9097999989927767 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9617\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0202\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0292\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6786\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0554\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7847\n",
      "Similarity to Ideal: 0.9149596740566278 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8919\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1073\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0387\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8143\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9875\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8090\n",
      "Similarity to Ideal: 0.9109684018409986 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0030\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1098\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2116\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7556\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1038\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8698\n",
      "Similarity to Ideal: 0.8769632279929592 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1534\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1998\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1417\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7426\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1670\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8083\n",
      "Similarity to Ideal: 0.8165668907755028 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1126\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1452\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1140\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8875\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2216\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8197\n",
      "Similarity to Ideal: 0.8359628362484267 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0572\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4407\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1962\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0009\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1943\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9277\n",
      "Similarity to Ideal: 0.8331305647705122 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1998\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3392\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1689\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0031\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2129\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8710\n",
      "Similarity to Ideal: 0.8127811480125227 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2330\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4416\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1334\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9581\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2347\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0184\n",
      "Similarity to Ideal: 0.7526278435714189 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3097\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4509\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0905\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9894\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3656\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9760\n",
      "Similarity to Ideal: 0.6826223908444654 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5196\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5513\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1836\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0639\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4648\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9656\n",
      "Similarity to Ideal: 0.7546889501539276 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3385\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6711\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1974\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1807\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3033\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9104\n",
      "Similarity to Ideal: 0.7470783419270894 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4053\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5039\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4726\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1689\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4770\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1047\n",
      "Similarity to Ideal: 0.7051930515715419 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3045\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2729\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4231\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3710\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1640\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5505\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0773\n",
      "Similarity to Ideal: 0.6239806498680922 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3688\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5739\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3143\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0879\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4760\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0401\n",
      "Similarity to Ideal: 0.633697532947062 \n",
      "\n",
      "Trial: 12\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0695\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0864\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2628\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0963\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1309\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2393\n",
      "Similarity to Ideal: 0.9935036310874131 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0984\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0945\n",
      "Epoch [1/1], Step [300/600], Loss: 0.5034\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3338\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3463\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2618\n",
      "Similarity to Ideal: 0.9738609660563409 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3542\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1083\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2794\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1228\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1951\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3625\n",
      "Similarity to Ideal: 0.980228226306652 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3583\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1731\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7383\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2786\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4967\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3268\n",
      "Similarity to Ideal: 0.9641651401546746 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5251\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5246\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9894\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4253\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5773\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4426\n",
      "Similarity to Ideal: 0.9587548793794199 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3234\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6660\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9268\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3342\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6186\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5150\n",
      "Similarity to Ideal: 0.9363228445489301 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2963\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3070\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3071\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.06 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5994\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6750\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9398\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4723\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6894\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5916\n",
      "Similarity to Ideal: 0.9098207042230498 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6896\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9350\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9704\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6740\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6909\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6683\n",
      "Similarity to Ideal: 0.9021998955696813 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0423\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0299\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9363\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6116\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8685\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8318\n",
      "Similarity to Ideal: 0.9107978211118879 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9225\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9529\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0374\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6053\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8947\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8018\n",
      "Similarity to Ideal: 0.8827467811944674 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8973\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9941\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0231\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6690\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0374\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8129\n",
      "Similarity to Ideal: 0.875997433527169 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7977\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1073\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9733\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7631\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9276\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7448\n",
      "Similarity to Ideal: 0.8894445589531925 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9536\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1187\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1305\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8007\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0370\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8337\n",
      "Similarity to Ideal: 0.8785699725313137 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1465\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3215\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1891\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7600\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0830\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8585\n",
      "Similarity to Ideal: 0.8459867804670442 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1663\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2045\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2141\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8981\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1750\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8613\n",
      "Similarity to Ideal: 0.8296110765926076 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0232\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3641\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1100\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8716\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1721\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8919\n",
      "Similarity to Ideal: 0.8008506893360732 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1683\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0993\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9646\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1478\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8973\n",
      "Similarity to Ideal: 0.8355168512029602 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2039\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4838\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1286\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9539\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3112\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9473\n",
      "Similarity to Ideal: 0.8015907676266145 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3865\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4070\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1277\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9802\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3104\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8686\n",
      "Similarity to Ideal: 0.7374373503460117 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2478\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4614\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2491\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0485\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4594\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8772\n",
      "Similarity to Ideal: 0.7155317071118514 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2917\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5788\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2505\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1433\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4277\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0070\n",
      "Similarity to Ideal: 0.6778436480186778 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3328\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5307\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4174\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2359\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4215\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0592\n",
      "Similarity to Ideal: 0.6641988147833058 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4237\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5811\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4643\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2066\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6298\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0968\n",
      "Similarity to Ideal: 0.6082155895031097 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3390\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6387\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4279\n",
      "Epoch [1/1], Step [400/600], Loss: 1.3276\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5430\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1678\n",
      "Similarity to Ideal: 0.6536798941694784 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4865\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5643\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4768\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1717\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5121\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1902\n",
      "Similarity to Ideal: 0.6744340905105637 \n",
      "\n",
      "Trial: 13\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0487\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0285\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1077\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0403\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1204\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4595\n",
      "Similarity to Ideal: 0.9948023503836393 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0928\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0770\n",
      "Epoch [1/1], Step [300/600], Loss: 0.5288\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3433\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3224\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2653\n",
      "Similarity to Ideal: 0.981936349122172 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3779\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0797\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2070\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1195\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2266\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2205\n",
      "Similarity to Ideal: 0.9733128451680929 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3243\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1770\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8179\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3032\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5631\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2953\n",
      "Similarity to Ideal: 0.9729773844472746 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4179\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3937\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9103\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2933\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4626\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3952\n",
      "Similarity to Ideal: 0.9523609202974448 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4330\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6881\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8508\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3330\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6987\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6139\n",
      "Similarity to Ideal: 0.9282675815259266 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5364\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5989\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0100\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3995\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6228\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5583\n",
      "Similarity to Ideal: 0.9300466714595675 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6027\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5727\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0618\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5478\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6835\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6630\n",
      "Similarity to Ideal: 0.8838746958869239 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8339\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0103\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1545\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7732\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7986\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9125\n",
      "Similarity to Ideal: 0.8686527083935344 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9463\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1176\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9256\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6197\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7945\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8553\n",
      "Similarity to Ideal: 0.9204395266208649 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9965\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0051\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1375\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7016\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9689\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9198\n",
      "Similarity to Ideal: 0.8655620779730413 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8953\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0707\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0195\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7069\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9819\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7646\n",
      "Similarity to Ideal: 0.8766274983015413 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8346\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0141\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0977\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7302\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9599\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7662\n",
      "Similarity to Ideal: 0.9041249908379816 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0279\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2055\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1302\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8344\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1660\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9067\n",
      "Similarity to Ideal: 0.8758306771178013 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1622\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2796\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1855\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7935\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1355\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7649\n",
      "Similarity to Ideal: 0.826582019758048 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1562\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1037\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1943\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8449\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1526\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8237\n",
      "Similarity to Ideal: 0.8643944234900187 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0531\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3172\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2314\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9438\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1638\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8596\n",
      "Similarity to Ideal: 0.7825672893961408 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2388\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4789\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2032\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1160\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2952\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0606\n",
      "Similarity to Ideal: 0.7170927304741257 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2931\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5204\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1725\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9762\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2708\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0916\n",
      "Similarity to Ideal: 0.81910000849903 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3420\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5012\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1541\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0351\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3753\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9458\n",
      "Similarity to Ideal: 0.7151661275365373 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4595\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6494\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3152\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1033\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3252\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0339\n",
      "Similarity to Ideal: 0.6737079308451137 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4245\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5762\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2841\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2048\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3991\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0258\n",
      "Similarity to Ideal: 0.6711356730975775 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5431\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5910\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3975\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1789\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6171\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1155\n",
      "Similarity to Ideal: 0.704602787513076 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4048\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4906\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4263\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1319\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4866\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0735\n",
      "Similarity to Ideal: 0.636268514289363 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3215\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5165\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4162\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2529\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5163\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0587\n",
      "Similarity to Ideal: 0.6033108143263066 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2985\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3061\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3065\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 14\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0683\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0424\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1812\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0492\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1717\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2968\n",
      "Similarity to Ideal: 0.9952446369527124 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0924\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0671\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4759\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4239\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3935\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3082\n",
      "Similarity to Ideal: 0.9738042155350485 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3573\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0727\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2495\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1489\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1826\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2213\n",
      "Similarity to Ideal: 0.9795717450708378 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3132\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1357\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7054\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2552\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5150\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2565\n",
      "Similarity to Ideal: 0.9710346142949562 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3995\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3270\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8676\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3054\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4561\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3400\n",
      "Similarity to Ideal: 0.9549122399058178 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3548\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7064\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8706\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2902\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6256\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5548\n",
      "Similarity to Ideal: 0.9555470171333503 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5609\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7262\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0975\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4438\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7318\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7340\n",
      "Similarity to Ideal: 0.9163905008241013 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6064\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7431\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0029\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4539\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6824\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7059\n",
      "Similarity to Ideal: 0.8908466457762874 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7230\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0023\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1184\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7487\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7390\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6744\n",
      "Similarity to Ideal: 0.9139623322971691 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9655\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9280\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0605\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6848\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7715\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8685\n",
      "Similarity to Ideal: 0.8780278080954861 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8836\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8946\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0232\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6254\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9094\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8405\n",
      "Similarity to Ideal: 0.9020742269205435 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9146\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9476\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9680\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6694\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0011\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7974\n",
      "Similarity to Ideal: 0.8749635604837017 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8600\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9992\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0147\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7339\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9712\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6967\n",
      "Similarity to Ideal: 0.8875007179169316 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0791\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1929\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2865\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9228\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1838\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8679\n",
      "Similarity to Ideal: 0.8113447295502515 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2010\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2578\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0993\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7869\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1127\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7992\n",
      "Similarity to Ideal: 0.7960376263414538 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1944\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0913\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1772\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8085\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1645\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8166\n",
      "Similarity to Ideal: 0.8230450081213914 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0011\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3154\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1216\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9019\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1731\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8142\n",
      "Similarity to Ideal: 0.8333665686318422 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1596\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3829\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2114\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9839\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2369\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9000\n",
      "Similarity to Ideal: 0.8091474491758378 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2286\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4613\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1837\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8546\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2944\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0693\n",
      "Similarity to Ideal: 0.80803830063597 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3017\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2941\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3062\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3026\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3017\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3062\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3028\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3028\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3083\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.19 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2626\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4157\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2404\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0597\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3913\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9665\n",
      "Similarity to Ideal: 0.6688982587597353 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2968\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2949\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3007\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2966\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.21 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4816\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5650\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4259\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1344\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4193\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1795\n",
      "Similarity to Ideal: 0.6987258556626296 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3400\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4881\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4632\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2363\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6047\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1393\n",
      "Similarity to Ideal: 0.6435704303169526 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3197\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5958\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4346\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1866\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4719\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0951\n",
      "Similarity to Ideal: 0.6019095579601926 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3639\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4308\n",
      "Epoch [1/1], Step [300/600], Loss: 1.5159\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1545\n",
      "Epoch [1/1], Step [500/600], Loss: 1.7243\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0462\n",
      "Similarity to Ideal: 0.643948284025432 \n",
      "\n",
      "Trial: 15\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0360\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1765\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0992\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0152\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2511\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3058\n",
      "Similarity to Ideal: 0.9939267830010237 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1097\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0612\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3709\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3657\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3901\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3013\n",
      "Similarity to Ideal: 0.9767038241186753 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4050\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0883\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2247\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1497\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2376\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2998\n",
      "Similarity to Ideal: 0.9815359480057781 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1387\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7453\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3171\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5190\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3201\n",
      "Similarity to Ideal: 0.9661019503319838 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3829\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4285\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9069\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2934\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4675\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3365\n",
      "Similarity to Ideal: 0.9583119473908525 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3722\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5370\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8267\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3501\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6524\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5345\n",
      "Similarity to Ideal: 0.9433577994235309 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5712\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5690\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9293\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3575\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6178\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5638\n",
      "Similarity to Ideal: 0.9223883093549113 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6741\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7259\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0060\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4937\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7033\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6327\n",
      "Similarity to Ideal: 0.8982772874244365 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6340\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9049\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0427\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7569\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6669\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6739\n",
      "Similarity to Ideal: 0.9013372065914786 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0025\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9627\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0383\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6109\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7504\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8542\n",
      "Similarity to Ideal: 0.8585276529559209 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9419\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9254\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0029\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6338\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8542\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7844\n",
      "Similarity to Ideal: 0.9068744450221389 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7776\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0015\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0400\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6519\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9449\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8486\n",
      "Similarity to Ideal: 0.8808842815171667 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8611\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1078\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0966\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7329\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9885\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7049\n",
      "Similarity to Ideal: 0.90491628058321 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9613\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2168\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1058\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7864\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0804\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8006\n",
      "Similarity to Ideal: 0.8542642088160284 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1638\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1680\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0759\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7346\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0658\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7788\n",
      "Similarity to Ideal: 0.8499869561301852 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1089\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1315\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1788\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8275\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1627\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8603\n",
      "Similarity to Ideal: 0.7767686839758838 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0458\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3203\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0689\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9162\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0635\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8689\n",
      "Similarity to Ideal: 0.7221812676341945 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2550\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4654\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1554\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0000\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1915\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9465\n",
      "Similarity to Ideal: 0.7825108482954133 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2803\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4240\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1609\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9371\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3317\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8348\n",
      "Similarity to Ideal: 0.8240434030636354 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3807\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4149\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1829\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0595\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3492\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9672\n",
      "Similarity to Ideal: 0.6972813529087007 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2966\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.2 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3611\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5147\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1888\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1336\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3170\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9162\n",
      "Similarity to Ideal: 0.6649925812605879 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4445\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5832\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2604\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1343\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3509\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0341\n",
      "Similarity to Ideal: 0.6196027792546912 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4095\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6446\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4353\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2256\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5074\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0750\n",
      "Similarity to Ideal: 0.631312432966828 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2931\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6169\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4602\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1304\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5577\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0439\n",
      "Similarity to Ideal: 0.582784108062157 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3064\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 16\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0635\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1372\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1308\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0282\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1281\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2860\n",
      "Similarity to Ideal: 0.9907024103890728 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1107\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1004\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4146\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4693\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4048\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2527\n",
      "Similarity to Ideal: 0.9818614518925899 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4777\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1021\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3257\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1666\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2439\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2471\n",
      "Similarity to Ideal: 0.9773454292820478 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3355\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1344\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7385\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2865\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5705\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2982\n",
      "Similarity to Ideal: 0.9673476249457953 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4323\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3348\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8616\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3349\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5285\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4826\n",
      "Similarity to Ideal: 0.9632335679601662 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3907\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6363\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8196\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3392\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6798\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5364\n",
      "Similarity to Ideal: 0.948972855597145 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5694\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6554\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9813\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3897\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6402\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6587\n",
      "Similarity to Ideal: 0.9188448651031789 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5597\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7305\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0574\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4986\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7439\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7360\n",
      "Similarity to Ideal: 0.9284000815844617 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6596\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8870\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8950\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6505\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7243\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6922\n",
      "Similarity to Ideal: 0.9004524405755292 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8137\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9407\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8912\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6232\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7944\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7767\n",
      "Similarity to Ideal: 0.9024383087661624 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3044\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3071\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.1 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2065\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0688\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1316\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6857\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1036\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8889\n",
      "Similarity to Ideal: 0.871509381305296 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7949\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9977\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0575\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8228\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9863\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7460\n",
      "Similarity to Ideal: 0.8769719202945294 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9788\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1110\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1160\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8539\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1660\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8458\n",
      "Similarity to Ideal: 0.8884539609043254 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1815\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2460\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3027\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8337\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1361\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8427\n",
      "Similarity to Ideal: 0.8756692835515476 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2968\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3056\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2935\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3106\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2958\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3057\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2958\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3108\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2958\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3108\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2957\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3108\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.15 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9463\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4204\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1693\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9353\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0954\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8420\n",
      "Similarity to Ideal: 0.775256660640439 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2769\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4167\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1643\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9818\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1369\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9802\n",
      "Similarity to Ideal: 0.7549844501628589 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3345\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4967\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1635\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0587\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2664\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9582\n",
      "Similarity to Ideal: 0.7136737570017466 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2988\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4238\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2436\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0216\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3318\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9840\n",
      "Similarity to Ideal: 0.6827458136967115 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2197\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4869\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2149\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9715\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3599\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9370\n",
      "Similarity to Ideal: 0.704698328594217 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2970\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2948\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3005\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.21 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5988\n",
      "Epoch [1/1], Step [200/600], Loss: 1.7541\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4909\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2586\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4397\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1092\n",
      "Similarity to Ideal: 0.7088770962858362 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3857\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5047\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4068\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1886\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5745\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0906\n",
      "Similarity to Ideal: 0.6775693049962814 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2935\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2948\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2931\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3236\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4966\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3010\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1946\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4738\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1298\n",
      "Similarity to Ideal: 0.682484735288925 \n",
      "\n",
      "Trial: 17\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0906\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0197\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1104\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0631\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1126\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3610\n",
      "Similarity to Ideal: 0.9957406766680679 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1585\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1167\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4212\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3867\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4357\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3334\n",
      "Similarity to Ideal: 0.9828130942546093 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4290\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0922\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3050\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1248\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1991\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3459\n",
      "Similarity to Ideal: 0.9767864222046372 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2883\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2088\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8333\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3763\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6038\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3209\n",
      "Similarity to Ideal: 0.9633541774690648 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4084\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3755\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9545\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3187\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5010\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4264\n",
      "Similarity to Ideal: 0.9512952932845233 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3778\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6356\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8608\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3593\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6166\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5108\n",
      "Similarity to Ideal: 0.9378314929097921 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5468\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6436\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0670\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3898\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6436\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7475\n",
      "Similarity to Ideal: 0.9271710607403189 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5587\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6658\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9506\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4744\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7148\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5854\n",
      "Similarity to Ideal: 0.9217712196252886 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5909\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9074\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9512\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6521\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6904\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6192\n",
      "Similarity to Ideal: 0.9048799051851478 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0141\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0277\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0555\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6643\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8951\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8945\n",
      "Similarity to Ideal: 0.9109692819828481 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9911\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0346\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0550\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6569\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9274\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7812\n",
      "Similarity to Ideal: 0.8900005831839247 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9248\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9905\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9447\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5964\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0874\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7584\n",
      "Similarity to Ideal: 0.8523209078609808 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8065\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9863\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0770\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7129\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9337\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7132\n",
      "Similarity to Ideal: 0.9003344930538275 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9677\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1468\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0347\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7460\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0689\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7910\n",
      "Similarity to Ideal: 0.8219951172686706 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0407\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1925\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1780\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7600\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1461\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7627\n",
      "Similarity to Ideal: 0.8586303902169313 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0948\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1408\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1119\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8649\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2226\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8649\n",
      "Similarity to Ideal: 0.8018375613061602 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9612\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4682\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1541\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9266\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0653\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8418\n",
      "Similarity to Ideal: 0.8641561639984418 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3007\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2957\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3049\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3028\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3085\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3026\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.17 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2896\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4208\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0908\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8860\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2928\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9853\n",
      "Similarity to Ideal: 0.8164741947276524 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3002\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4143\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2121\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0061\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3789\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9890\n",
      "Similarity to Ideal: 0.695132024478607 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3537\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5094\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1417\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0643\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3942\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9319\n",
      "Similarity to Ideal: 0.764797122187488 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4026\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4662\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2679\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0914\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3125\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9076\n",
      "Similarity to Ideal: 0.6864190147040099 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4506\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6005\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3127\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1322\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4148\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0366\n",
      "Similarity to Ideal: 0.7179168825986375 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3040\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3023\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3007\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2932\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3075\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4441\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3181\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1292\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5468\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1283\n",
      "Similarity to Ideal: 0.6845521489641851 \n",
      "\n",
      "Trial: 18\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0496\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0300\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0828\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0399\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3460\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3403\n",
      "Similarity to Ideal: 0.9941695808582963 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0802\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0600\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4364\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4329\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3849\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2296\n",
      "Similarity to Ideal: 0.9807550721681318 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3562\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0771\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2575\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1228\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2003\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3034\n",
      "Similarity to Ideal: 0.9792119329478114 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3113\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1965\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7222\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3970\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5269\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3129\n",
      "Similarity to Ideal: 0.9605688330677629 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3653\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4504\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8986\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3165\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5171\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3949\n",
      "Similarity to Ideal: 0.9509427731761072 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3476\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6680\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8914\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3188\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6977\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5784\n",
      "Similarity to Ideal: 0.9366109743826729 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4752\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6559\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0813\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4213\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5867\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7166\n",
      "Similarity to Ideal: 0.9246796585594843 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7216\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6844\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0652\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5050\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8049\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6882\n",
      "Similarity to Ideal: 0.9304890164837261 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7816\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9246\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1297\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6726\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6732\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7713\n",
      "Similarity to Ideal: 0.9158781951374013 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9043\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9998\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8739\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5695\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7271\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7819\n",
      "Similarity to Ideal: 0.8922536052179929 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9962\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0298\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0756\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7481\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0160\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8727\n",
      "Similarity to Ideal: 0.9018351787984958 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9016\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9767\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9125\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6920\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9359\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6780\n",
      "Similarity to Ideal: 0.8569571204751423 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9570\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1295\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2854\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8034\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0068\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8113\n",
      "Similarity to Ideal: 0.88151579714109 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0572\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3079\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2609\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8759\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0470\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8728\n",
      "Similarity to Ideal: 0.849024613852319 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0840\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2865\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1092\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7792\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2180\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7212\n",
      "Similarity to Ideal: 0.8918670174908132 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1077\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2355\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1449\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9724\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2360\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8342\n",
      "Similarity to Ideal: 0.8669424217754379 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9878\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3538\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1410\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9262\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0404\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9109\n",
      "Similarity to Ideal: 0.7932978129025761 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2074\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4359\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1293\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0565\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1939\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9329\n",
      "Similarity to Ideal: 0.8131455633568969 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2896\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4510\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2183\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9889\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2890\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0156\n",
      "Similarity to Ideal: 0.7735714041080548 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3421\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4117\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2507\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1243\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3711\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0298\n",
      "Similarity to Ideal: 0.7323665709672845 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4028\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4181\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2434\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0248\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3454\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9097\n",
      "Similarity to Ideal: 0.7047662867190274 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.21 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5005\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5172\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4360\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1885\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4194\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1001\n",
      "Similarity to Ideal: 0.6102317874638692 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3012\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5361\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3406\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0755\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5486\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9782\n",
      "Similarity to Ideal: 0.6561958202644607 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3972\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5493\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3742\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2315\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6197\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1135\n",
      "Similarity to Ideal: 0.5973303994979757 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2992\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3063\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 19\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0747\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0882\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0707\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0422\n",
      "Epoch [1/1], Step [500/600], Loss: 0.0880\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3264\n",
      "Similarity to Ideal: 0.9930664767124195 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1147\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1285\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4517\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3704\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3932\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2641\n",
      "Similarity to Ideal: 0.9784966927824723 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3834\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0909\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2617\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1111\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2289\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2609\n",
      "Similarity to Ideal: 0.9796805213522971 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3102\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2053\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7186\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3110\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5830\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2635\n",
      "Similarity to Ideal: 0.9648852385202809 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4091\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4163\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9038\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3365\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5297\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3001\n",
      "Similarity to Ideal: 0.9565840996939435 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3593\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6822\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8069\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3350\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5963\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5022\n",
      "Similarity to Ideal: 0.9517740837337827 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5371\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6417\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1799\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4375\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6284\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6227\n",
      "Similarity to Ideal: 0.920206342969767 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5922\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6338\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9772\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5282\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7070\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5968\n",
      "Similarity to Ideal: 0.914000535201349 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6699\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9631\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9673\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6569\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6865\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6675\n",
      "Similarity to Ideal: 0.9126759031133133 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0344\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1623\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0473\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6187\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9750\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9733\n",
      "Similarity to Ideal: 0.9141857110837386 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3011\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3070\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3044\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3044\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2919\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3079\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3045\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.1 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1476\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9554\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0523\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7239\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9626\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7679\n",
      "Similarity to Ideal: 0.8844301246863117 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8405\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9864\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0378\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7923\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9604\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7433\n",
      "Similarity to Ideal: 0.8892414849481988 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8758\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1672\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1079\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7585\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0273\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7606\n",
      "Similarity to Ideal: 0.858583356841099 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0974\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2382\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1191\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7999\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1110\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7549\n",
      "Similarity to Ideal: 0.8793401186070042 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2049\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2190\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1609\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8429\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1818\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8898\n",
      "Similarity to Ideal: 0.8624157819088232 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9908\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4171\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1776\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9308\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0860\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8250\n",
      "Similarity to Ideal: 0.8331069907015374 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6065\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4416\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0716\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1805\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9744\n",
      "Similarity to Ideal: 0.7949554388749249 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2708\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4685\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1127\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8818\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1913\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9714\n",
      "Similarity to Ideal: 0.732511769577022 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3048\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4299\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1733\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0031\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3606\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9655\n",
      "Similarity to Ideal: 0.711755008174709 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5008\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5107\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2801\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0893\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4283\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9869\n",
      "Similarity to Ideal: 0.7094756248387031 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2933\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6646\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3182\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1834\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3953\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9597\n",
      "Similarity to Ideal: 0.6416229604491004 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3310\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5224\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4131\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2014\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4448\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0865\n",
      "Similarity to Ideal: 0.6635690026733896 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3020\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3048\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3057\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3057\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3066\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4449\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3648\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1540\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4767\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0890\n",
      "Similarity to Ideal: 0.5580992564911058 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3990\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6458\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4787\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2212\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5867\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1904\n",
      "Similarity to Ideal: 0.6713906925657368 \n",
      "\n",
      "Trial: 20\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0863\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0664\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1287\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1411\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1760\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2657\n",
      "Similarity to Ideal: 0.9931400873154631 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1426\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0913\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4566\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3919\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4163\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2515\n",
      "Similarity to Ideal: 0.9786194525583265 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3932\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0874\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1922\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1246\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2094\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3025\n",
      "Similarity to Ideal: 0.9768987785982727 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3122\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1407\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7633\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3027\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5572\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3154\n",
      "Similarity to Ideal: 0.9651729888071657 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3908\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4744\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9523\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3227\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4934\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3737\n",
      "Similarity to Ideal: 0.95715928845383 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3607\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7088\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8851\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3546\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6453\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5881\n",
      "Similarity to Ideal: 0.9557795757830461 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5466\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6114\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9802\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3633\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6271\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6466\n",
      "Similarity to Ideal: 0.9127054553592954 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5497\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6589\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9900\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4732\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7116\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6308\n",
      "Similarity to Ideal: 0.9206755044175947 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7253\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9504\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0211\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5960\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7037\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6186\n",
      "Similarity to Ideal: 0.8935345990099213 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9245\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0357\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9740\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5710\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8560\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8400\n",
      "Similarity to Ideal: 0.9022890110106168 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8826\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9966\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9999\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6013\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9523\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8251\n",
      "Similarity to Ideal: 0.8861845597153285 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8675\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9615\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9710\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6235\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9905\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7239\n",
      "Similarity to Ideal: 0.8991129604183321 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8529\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0573\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0698\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7377\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9390\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7754\n",
      "Similarity to Ideal: 0.9028264981966047 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9800\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2391\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1451\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7951\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0544\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7623\n",
      "Similarity to Ideal: 0.8727965476951302 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1124\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1918\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0495\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7613\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0239\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7349\n",
      "Similarity to Ideal: 0.8528269674922297 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0351\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1661\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1411\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8936\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2882\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8724\n",
      "Similarity to Ideal: 0.8433338964532461 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9615\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4064\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2240\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0316\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0935\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8547\n",
      "Similarity to Ideal: 0.7757875295904993 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2465\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4282\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2028\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9608\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0880\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8850\n",
      "Similarity to Ideal: 0.7625243378137438 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2948\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2932\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3054\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2932\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.18 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4352\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4239\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2324\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0437\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4192\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0116\n",
      "Similarity to Ideal: 0.6752343830961645 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2969\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2935\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.2 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3585\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5802\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2948\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1912\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4992\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0372\n",
      "Similarity to Ideal: 0.6504179526038272 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2922\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4218\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5962\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3827\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0544\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5275\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0964\n",
      "Similarity to Ideal: 0.6059444367735844 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3784\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5117\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4159\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2153\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5161\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0659\n",
      "Similarity to Ideal: 0.6348356938654769 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3536\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5500\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3761\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1218\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5407\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0563\n",
      "Similarity to Ideal: 0.5975189812358546 \n",
      "\n",
      "Trial: 21\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0790\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1324\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1052\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0698\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1913\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3109\n",
      "Similarity to Ideal: 0.9950972054083258 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0988\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0906\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4642\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4090\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4054\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3005\n",
      "Similarity to Ideal: 0.9776432414251598 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4029\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0940\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2540\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1460\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2091\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2840\n",
      "Similarity to Ideal: 0.9772218477011269 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2774\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1401\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7511\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3791\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5788\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3174\n",
      "Similarity to Ideal: 0.9719556201747259 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3922\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3677\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9940\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3382\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5716\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3870\n",
      "Similarity to Ideal: 0.9576536145479042 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3517\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7045\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8016\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3005\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6649\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5381\n",
      "Similarity to Ideal: 0.943749588113846 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5954\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6280\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9753\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4497\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5926\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6365\n",
      "Similarity to Ideal: 0.9326568698384766 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5344\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6198\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9453\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4601\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7695\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7198\n",
      "Similarity to Ideal: 0.9229008848334426 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6735\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8514\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9541\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6406\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6641\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6572\n",
      "Similarity to Ideal: 0.9086540702425645 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8843\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9141\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9520\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6438\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8080\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8294\n",
      "Similarity to Ideal: 0.889699978322936 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9948\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9926\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0680\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7242\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8986\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8238\n",
      "Similarity to Ideal: 0.8814901468718856 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8182\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9034\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9647\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6056\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9892\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7658\n",
      "Similarity to Ideal: 0.9070537359698904 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8529\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0510\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0628\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7371\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9195\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7390\n",
      "Similarity to Ideal: 0.8841362039530706 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0029\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2176\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1194\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6875\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0445\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6983\n",
      "Similarity to Ideal: 0.9006714654971459 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0522\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2578\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1442\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7595\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1172\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7187\n",
      "Similarity to Ideal: 0.8665627699104825 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1051\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1266\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1575\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8781\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2544\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8004\n",
      "Similarity to Ideal: 0.8022219019085659 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0309\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3826\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1814\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9959\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2031\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8483\n",
      "Similarity to Ideal: 0.7997810145279461 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2087\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3415\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1050\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9845\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2047\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8924\n",
      "Similarity to Ideal: 0.823601413098385 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2407\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4305\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0835\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9617\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2372\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9068\n",
      "Similarity to Ideal: 0.8563297503861005 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3476\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4553\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1340\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9734\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3999\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9333\n",
      "Similarity to Ideal: 0.7729386151618479 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4763\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4322\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3504\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1592\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4378\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9802\n",
      "Similarity to Ideal: 0.7337024765238522 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2438\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6984\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2143\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1040\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3724\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9050\n",
      "Similarity to Ideal: 0.6594075992859852 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3699\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4737\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3265\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0993\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3932\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0524\n",
      "Similarity to Ideal: 0.6668318374224225 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3401\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4611\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3387\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1316\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4281\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0586\n",
      "Similarity to Ideal: 0.6694174514716791 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3557\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5452\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3827\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1331\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4263\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0344\n",
      "Similarity to Ideal: 0.6442623256418396 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2983\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3064\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 22\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0426\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0272\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0721\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0527\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1216\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3382\n",
      "Similarity to Ideal: 0.9964561797645849 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1151\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0672\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3871\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4311\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4056\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2172\n",
      "Similarity to Ideal: 0.9783196014963015 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3551\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0880\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3258\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1385\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2196\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2643\n",
      "Similarity to Ideal: 0.9619988371961807 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3294\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1148\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6457\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2845\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5287\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3440\n",
      "Similarity to Ideal: 0.962663746733744 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4145\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3377\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9495\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3704\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5112\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3372\n",
      "Similarity to Ideal: 0.9465587245036987 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3577\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6088\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8123\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3817\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6734\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5310\n",
      "Similarity to Ideal: 0.937018464728305 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5201\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5967\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0537\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3920\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5763\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6521\n",
      "Similarity to Ideal: 0.9187245456682219 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5947\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5694\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9530\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4356\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6902\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6565\n",
      "Similarity to Ideal: 0.9002343700644478 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7145\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9130\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0131\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6214\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6996\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7970\n",
      "Similarity to Ideal: 0.9036677413974004 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9062\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1304\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9972\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6180\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8882\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8674\n",
      "Similarity to Ideal: 0.9173200861479682 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9225\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9200\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0070\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6191\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9499\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7856\n",
      "Similarity to Ideal: 0.8719432433291291 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8636\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9314\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9709\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6298\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9193\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7608\n",
      "Similarity to Ideal: 0.8648056554435262 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8391\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1965\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0773\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7319\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9323\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7508\n",
      "Similarity to Ideal: 0.8303353243482128 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9999\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1740\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0477\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7805\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0472\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7759\n",
      "Similarity to Ideal: 0.8558190946017928 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0888\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1675\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0343\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7024\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2181\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7372\n",
      "Similarity to Ideal: 0.8758579495119648 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2595\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1781\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3513\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9211\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2040\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8776\n",
      "Similarity to Ideal: 0.818961985542364 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0499\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4114\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1359\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8863\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1187\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8205\n",
      "Similarity to Ideal: 0.8393438524681446 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3010\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 1.6595\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2580\n",
      "Epoch [1/1], Step [600/600], Loss: 1.2204\n",
      "Similarity to Ideal: 0.7994200898713694 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2206\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4862\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2144\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9513\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2934\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0934\n",
      "Similarity to Ideal: 0.8060967741497761 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2950\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5563\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1969\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9662\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4029\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9931\n",
      "Similarity to Ideal: 0.7312928678304909 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3403\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5102\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1951\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0287\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4581\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9885\n",
      "Similarity to Ideal: 0.6949883114678468 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3126\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6954\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2323\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1448\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2843\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9604\n",
      "Similarity to Ideal: 0.6779636102782944 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5047\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5821\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4470\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1794\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5084\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1552\n",
      "Similarity to Ideal: 0.6076950315661223 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4490\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5738\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4913\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2247\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4674\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1539\n",
      "Similarity to Ideal: 0.6819071124618767 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3195\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6702\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4455\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1235\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5634\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0788\n",
      "Similarity to Ideal: 0.6270423375878982 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5267\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5810\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4058\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1827\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6276\n",
      "Epoch [1/1], Step [600/600], Loss: 1.2333\n",
      "Similarity to Ideal: 0.7170643305001156 \n",
      "\n",
      "Trial: 23\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1192\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0637\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1903\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1181\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1550\n",
      "Epoch [1/1], Step [600/600], Loss: 0.1983\n",
      "Similarity to Ideal: 0.9905668028026539 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0985\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1182\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4109\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3956\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3737\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2643\n",
      "Similarity to Ideal: 0.9778224331191071 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4187\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1851\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3597\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1432\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2457\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3082\n",
      "Similarity to Ideal: 0.971533247464565 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3916\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1923\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7421\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3424\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5911\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2884\n",
      "Similarity to Ideal: 0.9669960836076554 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4026\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3976\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8091\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2823\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4754\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3757\n",
      "Similarity to Ideal: 0.9587580441955463 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3754\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7093\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9987\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3672\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6693\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6196\n",
      "Similarity to Ideal: 0.9290780211508273 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5330\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6602\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9756\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3461\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5693\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7236\n",
      "Similarity to Ideal: 0.9367486560257925 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5588\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6872\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0173\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4194\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6544\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6713\n",
      "Similarity to Ideal: 0.9244573855486082 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7299\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9641\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0316\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6177\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7537\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7190\n",
      "Similarity to Ideal: 0.8989792315406064 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9473\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0307\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9120\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6108\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7406\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8507\n",
      "Similarity to Ideal: 0.9102978485135127 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8944\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9873\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0764\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6897\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9679\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9537\n",
      "Similarity to Ideal: 0.8603104556729456 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8945\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9885\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0012\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6282\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0061\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7487\n",
      "Similarity to Ideal: 0.8996924809412786 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8193\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1060\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0643\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7546\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9631\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7772\n",
      "Similarity to Ideal: 0.8660892395769014 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0589\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1434\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2066\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8697\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1553\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8536\n",
      "Similarity to Ideal: 0.8733498883432997 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1726\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3189\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1309\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8344\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1645\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7904\n",
      "Similarity to Ideal: 0.8725428928856294 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2088\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2800\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2327\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8543\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2297\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8997\n",
      "Similarity to Ideal: 0.7684540864149418 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2963\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3040\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3075\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3062\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2962\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3042\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3075\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3062\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2962\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3042\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3075\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3062\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2962\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3043\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3075\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3062\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2962\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3043\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3075\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.16 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2331\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4308\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1073\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9635\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1675\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8932\n",
      "Similarity to Ideal: 0.7788061175577956 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3181\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2988\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0845\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8665\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3138\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9745\n",
      "Similarity to Ideal: 0.7871766967365941 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3032\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3875\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1271\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9473\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3420\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9139\n",
      "Similarity to Ideal: 0.7608644348592281 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3362\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5969\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2970\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1386\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3720\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9348\n",
      "Similarity to Ideal: 0.6454837481815725 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3618\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5185\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2829\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1797\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3461\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9760\n",
      "Similarity to Ideal: 0.6565811780754093 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3659\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5178\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3871\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0744\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3847\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1053\n",
      "Similarity to Ideal: 0.6343919481150481 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3403\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6014\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4308\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1091\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5604\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0501\n",
      "Similarity to Ideal: 0.6303506254850899 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3309\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6060\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3961\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1481\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4641\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0290\n",
      "Similarity to Ideal: 0.6546564982038725 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4635\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4399\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4137\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2055\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6937\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1088\n",
      "Similarity to Ideal: 0.6352486094602183 \n",
      "\n",
      "Trial: 24\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0568\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0360\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1082\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0522\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1487\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2585\n",
      "Similarity to Ideal: 0.9923851192555844 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0640\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0768\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4752\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3967\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3182\n",
      "Similarity to Ideal: 0.987565320305155 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4302\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0906\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2699\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1425\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1888\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2621\n",
      "Similarity to Ideal: 0.9797872038453459 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3597\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2424\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8911\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3058\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5506\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3690\n",
      "Similarity to Ideal: 0.9599293945665232 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2983\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3034\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.04 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4031\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7433\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8123\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4012\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7475\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5632\n",
      "Similarity to Ideal: 0.9343077986349861 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5379\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6519\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1075\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3443\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6074\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7027\n",
      "Similarity to Ideal: 0.927753204245465 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6580\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7220\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1382\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5332\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7359\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7412\n",
      "Similarity to Ideal: 0.915287413603075 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6609\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9628\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9677\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6833\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7143\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7214\n",
      "Similarity to Ideal: 0.909795997677745 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8473\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1431\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9201\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6310\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7611\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7880\n",
      "Similarity to Ideal: 0.9060624051010614 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8910\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0284\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1067\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7660\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0015\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9085\n",
      "Similarity to Ideal: 0.8594991567941987 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9327\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9460\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9900\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5797\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9680\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7434\n",
      "Similarity to Ideal: 0.9094494217499095 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8552\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9370\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0233\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7592\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9149\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7280\n",
      "Similarity to Ideal: 0.9029767529781876 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0197\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1899\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1767\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8289\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1562\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9108\n",
      "Similarity to Ideal: 0.8869030862179339 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1667\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2669\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1702\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7467\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0674\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7052\n",
      "Similarity to Ideal: 0.883953022289842 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1546\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1273\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1327\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9120\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1676\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8360\n",
      "Similarity to Ideal: 0.8176364960847747 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0524\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3035\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1767\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9716\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0776\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8590\n",
      "Similarity to Ideal: 0.8231389415821883 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2712\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3705\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2524\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2027\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3361\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0095\n",
      "Similarity to Ideal: 0.7917600167254999 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1664\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3257\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0530\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8894\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1994\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8943\n",
      "Similarity to Ideal: 0.8119496791154364 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4053\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5002\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1456\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0306\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2712\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9273\n",
      "Similarity to Ideal: 0.7943230216665642 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4174\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3862\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2347\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0671\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5205\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9426\n",
      "Similarity to Ideal: 0.7427534235316584 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4115\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4690\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3043\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1105\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2766\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9605\n",
      "Similarity to Ideal: 0.6623035321217177 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3759\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5173\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4428\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1479\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4927\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1618\n",
      "Similarity to Ideal: 0.6567381864915756 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3664\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3901\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3797\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0815\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4457\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0391\n",
      "Similarity to Ideal: 0.6462164574845634 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3552\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6879\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4069\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2723\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5598\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1393\n",
      "Similarity to Ideal: 0.5783436261803054 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3113\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4903\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4090\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1332\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4891\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0773\n",
      "Similarity to Ideal: 0.6323175406673995 \n",
      "\n",
      "Trial: 25\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0910\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0431\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1426\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1350\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1508\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3284\n",
      "Similarity to Ideal: 0.9908184089806062 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1311\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0557\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4188\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4681\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4183\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2532\n",
      "Similarity to Ideal: 0.9749936721606203 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3407\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1749\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2799\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1679\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1538\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2642\n",
      "Similarity to Ideal: 0.9678604627417708 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3403\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1314\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7108\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2883\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5602\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3002\n",
      "Similarity to Ideal: 0.9635209245507153 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3689\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5092\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8718\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3043\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4875\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3824\n",
      "Similarity to Ideal: 0.9614643093804052 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4197\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7188\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8944\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3441\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6534\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5470\n",
      "Similarity to Ideal: 0.9305353216495966 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5270\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7658\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0393\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3932\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5692\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6578\n",
      "Similarity to Ideal: 0.931471797710747 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5993\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6319\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9274\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4555\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6369\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6781\n",
      "Similarity to Ideal: 0.9107996761548405 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6228\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9634\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9149\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6019\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6423\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6388\n",
      "Similarity to Ideal: 0.8832113109663374 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2986\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2970\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3112\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3028\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2986\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3028\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3112\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3028\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2986\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3029\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3112\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3028\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2986\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3029\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3112\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3028\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2986\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3029\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3112\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3028\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.09 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8946\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9110\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0138\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6308\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9236\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8619\n",
      "Similarity to Ideal: 0.9075315627039029 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2988\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2935\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3100\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3086\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3086\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3087\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3087\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2998\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3093\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.11 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8210\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9886\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0553\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7787\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9737\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7376\n",
      "Similarity to Ideal: 0.8877478582040345 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9734\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1423\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1161\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7650\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1265\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8024\n",
      "Similarity to Ideal: 0.8607183512617776 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0513\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2374\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1496\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7283\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1682\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7285\n",
      "Similarity to Ideal: 0.8827967848922211 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2959\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3056\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2935\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2958\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3057\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3108\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2958\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3108\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2957\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3108\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2957\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3108\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3071\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.15 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0553\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3717\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1569\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0156\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0359\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8262\n",
      "Similarity to Ideal: 0.8304136144641776 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2376\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3318\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1897\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9919\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1628\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9014\n",
      "Similarity to Ideal: 0.8011590462494274 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3654\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4089\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0654\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9567\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3327\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9707\n",
      "Similarity to Ideal: 0.7512731610702761 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3970\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3750\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2371\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0572\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3917\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9036\n",
      "Similarity to Ideal: 0.7052406141366525 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4193\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4191\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2082\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0348\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3992\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8713\n",
      "Similarity to Ideal: 0.7131698357275593 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4225\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5188\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2688\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2138\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3182\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1080\n",
      "Similarity to Ideal: 0.7125385494911853 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2922\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3020\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3040\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3057\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3057\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3902\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5228\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3431\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1259\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4680\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0587\n",
      "Similarity to Ideal: 0.5848743209665561 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3064\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 26\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0719\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0354\n",
      "Epoch [1/1], Step [300/600], Loss: 0.0603\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1353\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1082\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3067\n",
      "Similarity to Ideal: 0.9944373336545745 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0863\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1232\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4672\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3636\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3955\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2830\n",
      "Similarity to Ideal: 0.9828263695415705 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3908\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0765\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2764\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1658\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2108\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3023\n",
      "Similarity to Ideal: 0.9764813906554065 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2992\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1235\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7127\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2727\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5071\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3280\n",
      "Similarity to Ideal: 0.9546504174412964 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4322\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4113\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9448\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3090\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5149\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3866\n",
      "Similarity to Ideal: 0.9557532505914774 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3696\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6677\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9920\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3847\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7183\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6078\n",
      "Similarity to Ideal: 0.9374721607183347 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5222\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6531\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0169\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3960\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6469\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6488\n",
      "Similarity to Ideal: 0.9307669695375401 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6040\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6544\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9909\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5167\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7549\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6709\n",
      "Similarity to Ideal: 0.8961089377916902 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6688\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8915\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9782\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5828\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6816\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6555\n",
      "Similarity to Ideal: 0.9108144459413647 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9495\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0038\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9526\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5906\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8015\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8141\n",
      "Similarity to Ideal: 0.8999218495783712 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9533\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9126\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0454\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6019\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8962\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7333\n",
      "Similarity to Ideal: 0.9047847762020154 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8555\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0036\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9722\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6295\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9308\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7920\n",
      "Similarity to Ideal: 0.8956779870526844 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8775\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0235\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9982\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7597\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9428\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7135\n",
      "Similarity to Ideal: 0.9035626801463356 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0991\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3193\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1938\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7713\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1547\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8325\n",
      "Similarity to Ideal: 0.8887456248331539 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2114\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2737\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2194\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7793\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2107\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7080\n",
      "Similarity to Ideal: 0.8821583062990538 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1873\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1171\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2461\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9121\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2177\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9886\n",
      "Similarity to Ideal: 0.766800944320206 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9816\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3454\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2413\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9985\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1008\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9121\n",
      "Similarity to Ideal: 0.815310233693861 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2641\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4021\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1652\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9918\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1729\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9009\n",
      "Similarity to Ideal: 0.7237263292236165 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2048\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4138\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0796\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8911\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2725\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8773\n",
      "Similarity to Ideal: 0.8483907158642434 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2399\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4363\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1563\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9875\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3413\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9072\n",
      "Similarity to Ideal: 0.6815208661025676 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2959\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4538\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2918\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0376\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3285\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8656\n",
      "Similarity to Ideal: 0.7485247515243416 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3680\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6532\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2654\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2365\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3295\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0530\n",
      "Similarity to Ideal: 0.6606438825409822 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3483\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5642\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3922\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2144\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4697\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0832\n",
      "Similarity to Ideal: 0.6041234379931927 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3045\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2976\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2932\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3078\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2930\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3652\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6039\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4395\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1317\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4863\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1185\n",
      "Similarity to Ideal: 0.6442947857535237 \n",
      "\n",
      "Trial: 27\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0495\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0716\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1954\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0495\n",
      "Epoch [1/1], Step [500/600], Loss: 0.0883\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4195\n",
      "Similarity to Ideal: 0.9945997882143764 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1289\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0707\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4810\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3910\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2543\n",
      "Similarity to Ideal: 0.9794429114167386 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3561\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1230\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2778\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1735\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2111\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3218\n",
      "Similarity to Ideal: 0.9758339797867431 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3008\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1342\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7000\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2703\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6160\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3224\n",
      "Similarity to Ideal: 0.9572218449538753 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3788\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4301\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9308\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3394\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4996\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4095\n",
      "Similarity to Ideal: 0.9589302289021604 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3667\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6107\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7895\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3205\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6391\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6075\n",
      "Similarity to Ideal: 0.9494021472684904 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2961\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3071\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3072\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3111\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3018\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3042\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.06 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5257\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6970\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9531\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4926\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6629\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6255\n",
      "Similarity to Ideal: 0.896639467132547 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6377\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8982\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9740\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6997\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6477\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6681\n",
      "Similarity to Ideal: 0.8968937032368496 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8976\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9054\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8397\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5355\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7430\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8361\n",
      "Similarity to Ideal: 0.9192200183164653 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9778\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9509\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0973\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6453\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8944\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8155\n",
      "Similarity to Ideal: 0.8435584378811598 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8412\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9634\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9726\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6886\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0035\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7233\n",
      "Similarity to Ideal: 0.8695604995579063 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9143\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0437\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1324\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7403\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9516\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7603\n",
      "Similarity to Ideal: 0.8740646435232351 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9176\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2626\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0930\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8146\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1172\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7928\n",
      "Similarity to Ideal: 0.8938960125798819 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2281\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3413\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2744\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8129\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2920\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9496\n",
      "Similarity to Ideal: 0.8138100509606625 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1291\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2057\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1790\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8863\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2373\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8859\n",
      "Similarity to Ideal: 0.7973069724435049 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0080\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3323\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1739\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9271\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0347\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8527\n",
      "Similarity to Ideal: 0.8136985520149347 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2244\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4519\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1395\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9549\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1632\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8668\n",
      "Similarity to Ideal: 0.754483832173636 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1445\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3518\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0558\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8821\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2213\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9065\n",
      "Similarity to Ideal: 0.7698635342210395 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3673\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6934\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1349\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0265\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4274\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9576\n",
      "Similarity to Ideal: 0.711350200854328 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3640\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6535\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3140\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1118\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4636\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0471\n",
      "Similarity to Ideal: 0.6363928566103376 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2486\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5436\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1874\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1300\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2559\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9507\n",
      "Similarity to Ideal: 0.654903675257652 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3571\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5596\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4320\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2471\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3976\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1113\n",
      "Similarity to Ideal: 0.6705107088862372 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3762\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5514\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4483\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1832\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5223\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0954\n",
      "Similarity to Ideal: 0.6557806243444588 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2930\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2730\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3922\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4253\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1769\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5354\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1108\n",
      "Similarity to Ideal: 0.5810434616133893 \n",
      "\n",
      "Trial: 28\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0953\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0485\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2203\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0456\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1921\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2811\n",
      "Similarity to Ideal: 0.9899838433868489 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1083\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0579\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3943\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4116\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2969\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2808\n",
      "Similarity to Ideal: 0.9768896519344432 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3788\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0702\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2431\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1697\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1865\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2588\n",
      "Similarity to Ideal: 0.9777072303695236 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3341\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1375\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7798\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2482\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5658\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3045\n",
      "Similarity to Ideal: 0.9647651645996768 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4020\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3678\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9699\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3196\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4834\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4022\n",
      "Similarity to Ideal: 0.9500662388519909 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3163\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5871\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8544\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3411\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6790\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5283\n",
      "Similarity to Ideal: 0.9435823623959984 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4804\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5908\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9969\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3634\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5639\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6490\n",
      "Similarity to Ideal: 0.9385107194825021 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5898\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6746\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0335\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4436\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7021\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6826\n",
      "Similarity to Ideal: 0.9173057229206447 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6268\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9197\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9652\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6602\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6976\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6606\n",
      "Similarity to Ideal: 0.9097908948023731 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9544\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0021\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9684\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5660\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8588\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8057\n",
      "Similarity to Ideal: 0.9039518576050778 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8832\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9463\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0618\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6152\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8639\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8042\n",
      "Similarity to Ideal: 0.8751346983838707 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8500\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9746\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9737\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6530\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0114\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7019\n",
      "Similarity to Ideal: 0.9115030866728128 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8068\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1319\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1301\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7897\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0427\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7219\n",
      "Similarity to Ideal: 0.8986579127125078 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9513\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1302\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1144\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8538\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0807\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7981\n",
      "Similarity to Ideal: 0.8668427830972948 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0168\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1995\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0998\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7590\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1105\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7947\n",
      "Similarity to Ideal: 0.8634057630506989 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1799\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1201\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1007\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9400\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0775\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8394\n",
      "Similarity to Ideal: 0.8086027384577237 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9483\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3185\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0999\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9550\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0459\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8576\n",
      "Similarity to Ideal: 0.8509356424525372 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2084\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2478\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1662\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9592\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1868\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9052\n",
      "Similarity to Ideal: 0.802560490631122 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1808\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4083\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1043\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8725\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2353\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9267\n",
      "Similarity to Ideal: 0.7496473466950869 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3692\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4969\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2388\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0953\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4130\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0440\n",
      "Similarity to Ideal: 0.7464038523868299 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4556\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5260\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2793\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1248\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5347\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0143\n",
      "Similarity to Ideal: 0.6399045662704183 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4334\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5991\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3681\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2167\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4143\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9925\n",
      "Similarity to Ideal: 0.7087957925193764 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3048\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2922\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2516\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6191\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4047\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1629\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5278\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0576\n",
      "Similarity to Ideal: 0.642024950244756 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3065\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 29\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0701\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0616\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2106\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0831\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2275\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3158\n",
      "Similarity to Ideal: 0.9946209561602114 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0715\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0531\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4430\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3879\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4307\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2806\n",
      "Similarity to Ideal: 0.9822884751914015 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3373\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0746\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2707\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1670\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2198\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2832\n",
      "Similarity to Ideal: 0.9775884769408624 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2553\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1270\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8179\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2871\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5213\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2997\n",
      "Similarity to Ideal: 0.9761646963157251 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3682\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3857\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8410\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3758\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4995\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4327\n",
      "Similarity to Ideal: 0.9607268820584429 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3156\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6765\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8214\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3330\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6746\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5386\n",
      "Similarity to Ideal: 0.9363621138712056 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6506\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7208\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0658\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5150\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7596\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7463\n",
      "Similarity to Ideal: 0.9187171677717657 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6530\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7086\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0572\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4295\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7702\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7156\n",
      "Similarity to Ideal: 0.9160630196503269 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2980\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2972\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2982\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3107\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3018\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.08 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9628\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0210\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9330\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5203\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7611\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7677\n",
      "Similarity to Ideal: 0.8834750640801271 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8793\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8772\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9597\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6722\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9623\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8506\n",
      "Similarity to Ideal: 0.8831082875584232 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8744\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9276\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9963\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6957\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0036\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8290\n",
      "Similarity to Ideal: 0.87041942677615 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8559\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0163\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0131\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7181\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9426\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7022\n",
      "Similarity to Ideal: 0.914458204455365 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0011\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2685\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1593\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7554\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1616\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7728\n",
      "Similarity to Ideal: 0.8903330025342409 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1446\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3535\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1348\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7646\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1398\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7882\n",
      "Similarity to Ideal: 0.8441871704629238 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1274\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2298\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3118\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9068\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2156\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8403\n",
      "Similarity to Ideal: 0.8144821709347683 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9678\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4633\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1574\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8812\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1319\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8472\n",
      "Similarity to Ideal: 0.7890295869618356 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3256\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3494\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1026\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9114\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1920\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9229\n",
      "Similarity to Ideal: 0.7594266046313629 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2948\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2932\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2933\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2954\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3053\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.18 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3744\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4816\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1010\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9911\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4226\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0017\n",
      "Similarity to Ideal: 0.7506971934866552 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3377\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4390\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2081\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0813\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4511\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9045\n",
      "Similarity to Ideal: 0.7379840538071775 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4112\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5163\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2587\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2787\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4196\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9902\n",
      "Similarity to Ideal: 0.6485077793489519 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5625\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5406\n",
      "Epoch [1/1], Step [300/600], Loss: 1.5394\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2495\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4512\n",
      "Epoch [1/1], Step [600/600], Loss: 1.2209\n",
      "Similarity to Ideal: 0.5943818718371413 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3342\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6479\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3459\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0613\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4325\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0581\n",
      "Similarity to Ideal: 0.5982234858630566 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3535\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5932\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4291\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2544\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5315\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1281\n",
      "Similarity to Ideal: 0.630974501565772 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3237\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4822\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3932\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1238\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4949\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1194\n",
      "Similarity to Ideal: 0.636084347024954 \n",
      "\n",
      "Trial: 30\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0586\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0297\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1396\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0700\n",
      "Epoch [1/1], Step [500/600], Loss: 0.0434\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3858\n",
      "Similarity to Ideal: 0.9942130906278519 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1132\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0737\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4324\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3632\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3134\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3210\n",
      "Similarity to Ideal: 0.9751420206329465 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3549\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0539\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2862\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1744\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1941\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2527\n",
      "Similarity to Ideal: 0.9811109799077735 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2728\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1286\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7526\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2946\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5418\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2464\n",
      "Similarity to Ideal: 0.96245089002866 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3712\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4435\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9446\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2731\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4864\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3637\n",
      "Similarity to Ideal: 0.9686241531097216 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3184\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6143\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8366\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3354\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6845\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5400\n",
      "Similarity to Ideal: 0.9514522347251946 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5410\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7463\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0740\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4873\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6516\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6550\n",
      "Similarity to Ideal: 0.9371645248137771 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5706\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6295\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9822\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4920\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7121\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7243\n",
      "Similarity to Ideal: 0.8969995957781125 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6690\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8997\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9811\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6159\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6554\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6430\n",
      "Similarity to Ideal: 0.8905963605622209 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9440\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0507\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0965\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5995\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8853\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7565\n",
      "Similarity to Ideal: 0.8991911942062075 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9119\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0525\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2066\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7385\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0878\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9976\n",
      "Similarity to Ideal: 0.8682477500979168 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9877\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9298\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1073\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7608\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0377\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8828\n",
      "Similarity to Ideal: 0.8409324670546633 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9192\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0628\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0770\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8063\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9193\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7410\n",
      "Similarity to Ideal: 0.9090393346476192 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9921\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1773\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1370\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7962\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1078\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7130\n",
      "Similarity to Ideal: 0.88119234216115 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1260\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2567\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1243\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6663\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0478\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7542\n",
      "Similarity to Ideal: 0.8410871218810152 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1315\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1418\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0908\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8869\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1463\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8626\n",
      "Similarity to Ideal: 0.8712838618111411 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9526\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3141\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1499\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9222\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0984\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8166\n",
      "Similarity to Ideal: 0.8960345324393673 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2508\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4915\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3277\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1508\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1281\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0156\n",
      "Similarity to Ideal: 0.8545928012198327 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2285\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4955\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1476\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9663\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2774\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9485\n",
      "Similarity to Ideal: 0.7988285884180732 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2992\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3646\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1329\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9625\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2685\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9065\n",
      "Similarity to Ideal: 0.7346009963527667 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2261\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5409\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2214\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0527\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4574\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8529\n",
      "Similarity to Ideal: 0.6996255390124793 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4628\n",
      "Epoch [1/1], Step [200/600], Loss: 1.7020\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2320\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1149\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3316\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9902\n",
      "Similarity to Ideal: 0.7363690586203129 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5180\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4616\n",
      "Epoch [1/1], Step [300/600], Loss: 1.5055\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2241\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5366\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1200\n",
      "Similarity to Ideal: 0.6831413307704781 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.5363\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5186\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4611\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1725\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4936\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1067\n",
      "Similarity to Ideal: 0.5687470209217629 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2968\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3007\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2932\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2986\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3064\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 31\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0692\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0556\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1051\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0449\n",
      "Epoch [1/1], Step [500/600], Loss: 0.0827\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2459\n",
      "Similarity to Ideal: 0.9937275980361553 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1057\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0768\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4519\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4135\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3716\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2702\n",
      "Similarity to Ideal: 0.9810725801524819 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3884\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1907\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1917\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2930\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2567\n",
      "Similarity to Ideal: 0.9743449140991339 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2710\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1563\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7534\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2917\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6059\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3155\n",
      "Similarity to Ideal: 0.9715837893090649 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3636\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3899\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8359\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2984\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4579\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4047\n",
      "Similarity to Ideal: 0.9553790590582345 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3551\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7024\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8787\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3548\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6977\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5137\n",
      "Similarity to Ideal: 0.9443364084602639 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5760\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6621\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1825\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4108\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6425\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6714\n",
      "Similarity to Ideal: 0.9195239501830853 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5732\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6846\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9485\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4845\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6732\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5599\n",
      "Similarity to Ideal: 0.9346407202539555 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7495\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9390\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9767\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7498\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7447\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7037\n",
      "Similarity to Ideal: 0.9094970895348032 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9970\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9251\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9390\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5905\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7576\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7756\n",
      "Similarity to Ideal: 0.8979701607939964 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8785\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9232\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0165\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6502\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8743\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7744\n",
      "Similarity to Ideal: 0.8963456261126073 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8252\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0395\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0396\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6756\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9717\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8823\n",
      "Similarity to Ideal: 0.8592075335247703 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9483\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0520\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1426\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8463\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0997\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8291\n",
      "Similarity to Ideal: 0.871794197826166 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0679\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2553\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1066\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7867\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1509\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7987\n",
      "Similarity to Ideal: 0.8788675854567334 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1805\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3115\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1771\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8303\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1633\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8431\n",
      "Similarity to Ideal: 0.8609301511816743 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1685\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1252\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3313\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8943\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3070\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9128\n",
      "Similarity to Ideal: 0.817112626322674 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8848\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2740\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1179\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8757\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2021\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8543\n",
      "Similarity to Ideal: 0.8163738612069316 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1809\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2628\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1196\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0471\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1834\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8839\n",
      "Similarity to Ideal: 0.7730056465128964 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2520\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4453\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0665\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8889\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2283\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9467\n",
      "Similarity to Ideal: 0.763512047171861 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2301\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4324\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1631\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9571\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3718\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9418\n",
      "Similarity to Ideal: 0.6841057184660634 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3105\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4509\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2580\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1162\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4906\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8727\n",
      "Similarity to Ideal: 0.7322630504214434 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3408\n",
      "Epoch [1/1], Step [200/600], Loss: 1.7662\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1959\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1356\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3697\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9836\n",
      "Similarity to Ideal: 0.6919464048664115 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2922\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3652\n",
      "Epoch [1/1], Step [200/600], Loss: 1.7175\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3622\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0820\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4825\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0423\n",
      "Similarity to Ideal: 0.586974913008705 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3007\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2932\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2987\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3065\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 32\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0673\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0651\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1149\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0510\n",
      "Epoch [1/1], Step [500/600], Loss: 0.0806\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3595\n",
      "Similarity to Ideal: 0.9939904233687845 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0990\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0541\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4500\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3825\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3862\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3031\n",
      "Similarity to Ideal: 0.9804885335452938 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3585\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1273\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2195\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1528\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2488\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3103\n",
      "Similarity to Ideal: 0.9796147476056318 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2486\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1524\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6608\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2678\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4928\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2569\n",
      "Similarity to Ideal: 0.9713976078129976 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2987\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3034\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.04 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3439\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6206\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8956\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3775\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6499\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4880\n",
      "Similarity to Ideal: 0.9625713444444599 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4971\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5933\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0296\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3501\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6157\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6314\n",
      "Similarity to Ideal: 0.9286618664428857 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5789\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6820\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9488\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4372\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7010\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6472\n",
      "Similarity to Ideal: 0.9339347514045746 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6633\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9219\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9735\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6432\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6462\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6288\n",
      "Similarity to Ideal: 0.8985683256039737 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8960\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0455\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0920\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5920\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7894\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8559\n",
      "Similarity to Ideal: 0.9024004117928008 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8689\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0672\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1153\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6311\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9686\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8754\n",
      "Similarity to Ideal: 0.8907926496568771 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9926\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9987\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0016\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7281\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9956\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7472\n",
      "Similarity to Ideal: 0.8860409227425217 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8443\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0704\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1471\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7501\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9187\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7610\n",
      "Similarity to Ideal: 0.8777933470833428 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9301\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2441\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0993\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7778\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0017\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7862\n",
      "Similarity to Ideal: 0.8848365986115869 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0483\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2110\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1206\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7729\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1783\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7643\n",
      "Similarity to Ideal: 0.885017406098017 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3654\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1962\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3164\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8652\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3269\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9731\n",
      "Similarity to Ideal: 0.8089832067300013 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0027\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1192\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8686\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1338\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7809\n",
      "Similarity to Ideal: 0.8352497849088308 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2174\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3247\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0336\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9202\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2375\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8610\n",
      "Similarity to Ideal: 0.7798764569650717 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2449\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4219\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0712\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9109\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2834\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9063\n",
      "Similarity to Ideal: 0.7232792224399621 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3593\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5271\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2218\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0522\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3941\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0016\n",
      "Similarity to Ideal: 0.6934543046276133 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2969\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2935\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.2 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3405\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5734\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2462\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1346\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3394\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9348\n",
      "Similarity to Ideal: 0.7480447154630272 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3942\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5104\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3627\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1191\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4247\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0364\n",
      "Similarity to Ideal: 0.627599470471458 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3019\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3040\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2973\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3045\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2835\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6066\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3265\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2207\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4592\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0951\n",
      "Similarity to Ideal: 0.6340124376190559 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4653\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4463\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4445\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2188\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5841\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1911\n",
      "Similarity to Ideal: 0.5814106925705063 \n",
      "\n",
      "Trial: 33\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0968\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0569\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1060\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0508\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1199\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2628\n",
      "Similarity to Ideal: 0.994464215799391 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1424\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0876\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4628\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4585\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4081\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2765\n",
      "Similarity to Ideal: 0.9836016972839285 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4298\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1416\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3375\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1219\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2585\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3222\n",
      "Similarity to Ideal: 0.970962379864607 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3072\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2028\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6916\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3048\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5470\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3304\n",
      "Similarity to Ideal: 0.9636021048903853 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4178\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4413\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8463\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3708\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5169\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3841\n",
      "Similarity to Ideal: 0.9580713590310701 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3659\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6831\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8876\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3921\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6872\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5193\n",
      "Similarity to Ideal: 0.9361030103855245 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6355\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7020\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0226\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4738\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7340\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6854\n",
      "Similarity to Ideal: 0.9226109008923314 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5902\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6265\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9764\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4604\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6986\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6302\n",
      "Similarity to Ideal: 0.9085181184454216 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7512\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9130\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1134\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7547\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7130\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6855\n",
      "Similarity to Ideal: 0.9148731684982868 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9226\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9906\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9011\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5853\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7343\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7689\n",
      "Similarity to Ideal: 0.9126033865581267 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9171\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8909\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0928\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6444\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0069\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8418\n",
      "Similarity to Ideal: 0.8946296402801823 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8873\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9364\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0738\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6119\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9022\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6906\n",
      "Similarity to Ideal: 0.8891710297666868 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9912\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0829\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1084\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8608\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9880\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7684\n",
      "Similarity to Ideal: 0.906177770887289 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0561\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2357\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2615\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7908\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0590\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8540\n",
      "Similarity to Ideal: 0.851045883052201 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0196\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2342\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1078\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7392\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0874\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8344\n",
      "Similarity to Ideal: 0.8889142287481772 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1322\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1552\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1983\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8687\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1418\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8105\n",
      "Similarity to Ideal: 0.8234911153285069 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0546\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4056\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1259\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9591\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1628\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8946\n",
      "Similarity to Ideal: 0.8423231994550247 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2009\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4438\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1012\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0104\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1508\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9176\n",
      "Similarity to Ideal: 0.7873670594425289 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4050\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4801\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1131\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9814\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3038\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0261\n",
      "Similarity to Ideal: 0.7711026591390684 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4042\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3903\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2630\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0420\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3712\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0230\n",
      "Similarity to Ideal: 0.7560748143110085 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3869\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5431\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2184\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0374\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4283\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9258\n",
      "Similarity to Ideal: 0.7599033364564418 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3044\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5923\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3113\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1177\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2929\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9611\n",
      "Similarity to Ideal: 0.6673979286470648 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4636\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5166\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2936\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1424\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4018\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0017\n",
      "Similarity to Ideal: 0.6933949172970613 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3045\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3424\n",
      "Epoch [1/1], Step [200/600], Loss: 1.7227\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4991\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2811\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4577\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1295\n",
      "Similarity to Ideal: 0.699514149615984 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2981\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3064\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 34\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0717\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0338\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1629\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0459\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2040\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3019\n",
      "Similarity to Ideal: 0.9955071153837654 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1406\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1142\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4314\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4054\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3501\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2771\n",
      "Similarity to Ideal: 0.97814942780897 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3558\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0744\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2711\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1772\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1499\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2292\n",
      "Similarity to Ideal: 0.9782291666157905 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3150\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1372\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6992\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3517\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5631\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2448\n",
      "Similarity to Ideal: 0.9705046185614202 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4373\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4630\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9250\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3418\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5660\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4217\n",
      "Similarity to Ideal: 0.9600042704092324 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4333\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7124\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8581\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4029\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7886\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6366\n",
      "Similarity to Ideal: 0.9205773895285064 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5137\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8173\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1029\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4357\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6264\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6290\n",
      "Similarity to Ideal: 0.9356984987268889 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6850\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6837\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9540\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4685\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8665\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6613\n",
      "Similarity to Ideal: 0.9101062301071547 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8058\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9879\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2181\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8713\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7632\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7696\n",
      "Similarity to Ideal: 0.8890412454578692 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9121\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9749\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9857\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5925\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8320\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8354\n",
      "Similarity to Ideal: 0.9084638179371686 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8994\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9521\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0273\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6440\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8906\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8106\n",
      "Similarity to Ideal: 0.8947179468278087 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8288\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9616\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9596\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6448\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9660\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6849\n",
      "Similarity to Ideal: 0.9010710848768803 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8554\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0854\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1271\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7155\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9451\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7463\n",
      "Similarity to Ideal: 0.8859441439900427 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0247\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1997\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2477\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8729\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1559\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8343\n",
      "Similarity to Ideal: 0.8900022186570332 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0874\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1995\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0884\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6972\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0139\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6870\n",
      "Similarity to Ideal: 0.8976393012186358 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0812\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1596\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2363\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8769\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1576\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8783\n",
      "Similarity to Ideal: 0.833384996514203 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1138\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3397\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2729\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0812\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2191\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8772\n",
      "Similarity to Ideal: 0.7600853785387853 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2257\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3204\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1651\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0120\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1855\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8623\n",
      "Similarity to Ideal: 0.8010015985657009 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2452\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5163\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0674\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8872\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2319\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9261\n",
      "Similarity to Ideal: 0.8394774087844988 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2999\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3081\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3017\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3062\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2941\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3062\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3026\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.19 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3438\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5789\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3072\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1153\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5057\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9529\n",
      "Similarity to Ideal: 0.6778120562990301 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2850\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6005\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2689\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1212\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3379\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9032\n",
      "Similarity to Ideal: 0.651263453596234 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3020\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3048\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3057\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3183\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6384\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2773\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1484\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5116\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0692\n",
      "Similarity to Ideal: 0.6300525886097876 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2983\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3059\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3064\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 35\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1286\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0234\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1325\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0221\n",
      "Epoch [1/1], Step [500/600], Loss: 0.0621\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2760\n",
      "Similarity to Ideal: 0.9944868664872182 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1026\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0647\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3834\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3453\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3685\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3240\n",
      "Similarity to Ideal: 0.9772788807385298 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4162\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1176\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3234\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2029\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2424\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3227\n",
      "Similarity to Ideal: 0.9793060921688028 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2702\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1502\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7328\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2482\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5679\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2912\n",
      "Similarity to Ideal: 0.9670172267577187 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4260\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4207\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9016\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3120\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4918\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3356\n",
      "Similarity to Ideal: 0.9588567188912245 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3738\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6435\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8841\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3537\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6938\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4778\n",
      "Similarity to Ideal: 0.9373438685837743 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6329\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6687\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0867\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5316\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7471\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8188\n",
      "Similarity to Ideal: 0.9263758624115342 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5998\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6175\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9687\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4752\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7183\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6202\n",
      "Similarity to Ideal: 0.9168743801732178 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6728\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0088\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0155\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7540\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6704\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6715\n",
      "Similarity to Ideal: 0.9024894228500205 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0157\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9526\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9551\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6140\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8498\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8124\n",
      "Similarity to Ideal: 0.9265887345915088 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9331\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9892\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0967\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7620\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9857\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8373\n",
      "Similarity to Ideal: 0.8824464708489416 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8633\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9117\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0086\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6818\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9170\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7491\n",
      "Similarity to Ideal: 0.8744496867834471 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7967\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1057\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0756\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7823\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9528\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7614\n",
      "Similarity to Ideal: 0.8999442577448226 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9905\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2050\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1852\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8215\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0578\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8756\n",
      "Similarity to Ideal: 0.8622617579669762 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1582\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2274\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1578\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6894\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0777\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7942\n",
      "Similarity to Ideal: 0.8037669683418284 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1554\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2108\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2844\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9217\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2711\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9396\n",
      "Similarity to Ideal: 0.7489909410149351 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9670\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3698\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1703\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9447\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1653\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8583\n",
      "Similarity to Ideal: 0.8417539212879037 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3051\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3012\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2956\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3050\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3086\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.17 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2913\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3942\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0953\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8253\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2878\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8764\n",
      "Similarity to Ideal: 0.8193710647922976 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3414\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3961\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1907\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9511\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4054\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0172\n",
      "Similarity to Ideal: 0.7426817592523776 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3765\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4559\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2308\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0982\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4232\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8601\n",
      "Similarity to Ideal: 0.7249124815284023 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2968\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.21 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3015\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2921\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3014\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2920\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3013\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.22 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3020\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2976\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2976\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3059\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3023\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2976\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2979\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3007\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2930\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3019\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2991\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3065\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 36\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0435\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0423\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1432\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0601\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1711\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4283\n",
      "Similarity to Ideal: 0.991099547867763 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1551\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1055\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4163\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3794\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3680\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2329\n",
      "Similarity to Ideal: 0.9821997360788173 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3830\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0765\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2685\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1357\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2592\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2993\n",
      "Similarity to Ideal: 0.9827267300940148 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3310\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1547\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7679\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3700\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6244\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3170\n",
      "Similarity to Ideal: 0.9669572772192851 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4316\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3871\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9578\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3483\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5708\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4987\n",
      "Similarity to Ideal: 0.9457515220137351 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3513\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5869\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8635\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3533\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7439\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5386\n",
      "Similarity to Ideal: 0.9397390701299138 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5259\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6619\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0441\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4051\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6071\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6991\n",
      "Similarity to Ideal: 0.9247394923781975 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5807\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6158\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9572\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4581\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7054\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6248\n",
      "Similarity to Ideal: 0.9061778258139477 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6700\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9640\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9883\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6756\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7218\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6967\n",
      "Similarity to Ideal: 0.9039778516801131 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9689\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9837\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8834\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5435\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7445\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8164\n",
      "Similarity to Ideal: 0.9044790321578823 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1943\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0213\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2101\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6888\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9628\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9750\n",
      "Similarity to Ideal: 0.8731780964497546 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9381\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9405\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8957\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6455\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0189\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7476\n",
      "Similarity to Ideal: 0.914067912767108 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8793\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1616\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1107\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7527\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0305\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7760\n",
      "Similarity to Ideal: 0.8908205502513487 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9457\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2836\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1094\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7428\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0946\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7661\n",
      "Similarity to Ideal: 0.859112278286957 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0793\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2165\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1521\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7422\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1348\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7225\n",
      "Similarity to Ideal: 0.8830729019675325 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1149\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1736\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2493\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8555\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1538\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9118\n",
      "Similarity to Ideal: 0.8056947774989407 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9695\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2779\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1912\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9870\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1369\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8777\n",
      "Similarity to Ideal: 0.7851443382988657 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2878\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3686\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1525\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9908\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1657\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9235\n",
      "Similarity to Ideal: 0.7643202993435928 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2805\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3398\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1323\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8850\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1680\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9246\n",
      "Similarity to Ideal: 0.7605565600543942 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2963\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3674\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1401\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9683\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2790\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9186\n",
      "Similarity to Ideal: 0.7689819183700961 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3324\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4614\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2650\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0059\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4631\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8528\n",
      "Similarity to Ideal: 0.6980968833691328 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4040\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5888\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2738\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1609\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2431\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9671\n",
      "Similarity to Ideal: 0.7416442857389429 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4340\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4970\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2726\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1147\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3641\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0942\n",
      "Similarity to Ideal: 0.6813713936978228 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3020\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3040\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2973\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3045\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4293\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5807\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4318\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1778\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4650\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0546\n",
      "Similarity to Ideal: 0.613166148740345 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4687\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5161\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4621\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2163\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5563\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1808\n",
      "Similarity to Ideal: 0.6560772092943656 \n",
      "\n",
      "Trial: 37\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0617\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0290\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3063\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1484\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1758\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3522\n",
      "Similarity to Ideal: 0.9921910518629529 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1151\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1061\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4409\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3677\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3855\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2496\n",
      "Similarity to Ideal: 0.9745557286009164 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4495\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1382\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3276\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2152\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2536\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3007\n",
      "Similarity to Ideal: 0.9788186020043763 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3526\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2012\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7206\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2860\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6184\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2853\n",
      "Similarity to Ideal: 0.9630788730726656 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4232\n",
      "Epoch [1/1], Step [200/600], Loss: 0.3270\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9814\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2938\n",
      "Epoch [1/1], Step [500/600], Loss: 0.4695\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3459\n",
      "Similarity to Ideal: 0.962358531607701 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3348\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6127\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8014\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3091\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7015\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5770\n",
      "Similarity to Ideal: 0.9475343224195423 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5025\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5888\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9898\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3916\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6062\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5573\n",
      "Similarity to Ideal: 0.922073139230038 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6351\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6971\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9767\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4448\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6878\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6675\n",
      "Similarity to Ideal: 0.8923074712324048 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7766\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0019\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2117\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7946\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7106\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8053\n",
      "Similarity to Ideal: 0.8847896872842759 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9134\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9789\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8787\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5674\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7765\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8501\n",
      "Similarity to Ideal: 0.9146720670138715 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0307\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9161\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0681\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7357\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9327\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7855\n",
      "Similarity to Ideal: 0.8853737959484446 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8461\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0467\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9461\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6172\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9655\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8161\n",
      "Similarity to Ideal: 0.8685817642212262 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9106\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1177\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1264\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6833\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8942\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7708\n",
      "Similarity to Ideal: 0.8910631160372595 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9851\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2755\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1905\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8888\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1331\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8685\n",
      "Similarity to Ideal: 0.8160305123127207 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3058\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2890\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3127\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3052\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2926\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3060\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2890\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3127\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3052\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2926\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3061\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2890\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3127\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3052\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2926\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3061\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2890\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3127\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3052\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2926\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3061\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2890\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3127\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3052\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.14 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2186\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1759\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2258\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9608\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2098\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8798\n",
      "Similarity to Ideal: 0.8092710501418584 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9808\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3185\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1891\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9021\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1266\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8265\n",
      "Similarity to Ideal: 0.8083593946336374 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2436\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3503\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0827\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9248\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1346\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8958\n",
      "Similarity to Ideal: 0.8285802510861777 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2636\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3010\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0796\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9934\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2956\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9530\n",
      "Similarity to Ideal: 0.7909913345383218 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2881\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4773\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1612\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0690\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3422\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9230\n",
      "Similarity to Ideal: 0.7601974882455911 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4128\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6235\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2937\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1977\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5240\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0265\n",
      "Similarity to Ideal: 0.7421326194834468 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2523\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5664\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1695\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1404\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2573\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0101\n",
      "Similarity to Ideal: 0.7105971360897709 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4842\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5970\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3965\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1524\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3648\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0156\n",
      "Similarity to Ideal: 0.6973490390294261 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3048\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3057\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3047\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3039\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3058\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.23 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4281\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5094\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3527\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1657\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4772\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9594\n",
      "Similarity to Ideal: 0.6145229219819274 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2341\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4840\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2719\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1379\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4900\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0282\n",
      "Similarity to Ideal: 0.6255267986349424 \n",
      "\n",
      "Trial: 38\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2138\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1752\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4000\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1920\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2523\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4304\n",
      "Similarity to Ideal: 0.9827218108775994 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1195\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0871\n",
      "Epoch [1/1], Step [300/600], Loss: 0.3709\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5238\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3762\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2920\n",
      "Similarity to Ideal: 0.9796153096040165 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3492\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0757\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1979\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1428\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2399\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2851\n",
      "Similarity to Ideal: 0.9799366272184039 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3279\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1632\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7233\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2771\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5081\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3295\n",
      "Similarity to Ideal: 0.9616173762897832 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5527\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6652\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9949\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5139\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7820\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4411\n",
      "Similarity to Ideal: 0.9392268239049271 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2951\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3094\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3098\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3099\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2994\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3066\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.05 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4837\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5568\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9543\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4033\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5956\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6543\n",
      "Similarity to Ideal: 0.9217398543461115 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6424\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7500\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1388\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6093\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7058\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8021\n",
      "Similarity to Ideal: 0.8777014113813696 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7805\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8931\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1191\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7016\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7780\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7665\n",
      "Similarity to Ideal: 0.9196731238425897 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9077\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0817\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0047\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6911\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8503\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8283\n",
      "Similarity to Ideal: 0.8816238005907733 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9290\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0647\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0568\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6991\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9241\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8105\n",
      "Similarity to Ideal: 0.8805721396269685 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8954\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9522\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0338\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5989\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9306\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7300\n",
      "Similarity to Ideal: 0.8806033722647356 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8710\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1310\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1102\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7926\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9204\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7041\n",
      "Similarity to Ideal: 0.9074293433161914 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2955\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3071\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3080\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.13 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0319\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1497\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1107\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7327\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0859\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7446\n",
      "Similarity to Ideal: 0.8679655885767907 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0902\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1745\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1321\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7773\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1642\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8135\n",
      "Similarity to Ideal: 0.8259020849090881 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9449\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2704\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1366\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9235\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1550\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8161\n",
      "Similarity to Ideal: 0.8770140310362281 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1991\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3373\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0919\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9524\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1594\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9071\n",
      "Similarity to Ideal: 0.7685567942684208 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2789\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3656\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1513\n",
      "Epoch [1/1], Step [400/600], Loss: 0.8920\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2497\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0348\n",
      "Similarity to Ideal: 0.7123819474820984 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2942\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3017\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3062\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3023\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3026\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3027\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2940\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3082\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3016\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3063\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.19 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3051\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5475\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1678\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0832\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5308\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8819\n",
      "Similarity to Ideal: 0.6891933129859122 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3652\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5584\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2852\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0977\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3746\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0069\n",
      "Similarity to Ideal: 0.7006835677851869 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4176\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6065\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3507\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1663\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3507\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0659\n",
      "Similarity to Ideal: 0.6092112999358077 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4139\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5105\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3789\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1194\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4558\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9907\n",
      "Similarity to Ideal: 0.6566593531074794 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3278\n",
      "Epoch [1/1], Step [200/600], Loss: 1.7099\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4219\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1978\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5982\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0914\n",
      "Similarity to Ideal: 0.6931399739103559 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2990\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3061\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3055\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3066\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2927\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2997\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3000\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3025\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3056\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.25 \n",
      "\n",
      "Trial: 39\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0629\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0328\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1554\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0783\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1486\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3303\n",
      "Similarity to Ideal: 0.9949267232879615 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.1023\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0764\n",
      "Epoch [1/1], Step [300/600], Loss: 0.5565\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4157\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3853\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2926\n",
      "Similarity to Ideal: 0.978710913009835 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3603\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1170\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2754\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1246\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2211\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3054\n",
      "Similarity to Ideal: 0.9797243139162933 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.2987\n",
      "Epoch [1/1], Step [200/600], Loss: 0.2037\n",
      "Epoch [1/1], Step [300/600], Loss: 0.6798\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3452\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5506\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3196\n",
      "Similarity to Ideal: 0.9679743369733069 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2983\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3034\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2975\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2996\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3036\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2974\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3093\n",
      "Epoch [1/1], Step [500/600], Loss: 2.2995\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3067\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.04 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3081\n",
      "Epoch [1/1], Step [200/600], Loss: 0.5956\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9112\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3836\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6581\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5046\n",
      "Similarity to Ideal: 0.9562023471474423 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5192\n",
      "Epoch [1/1], Step [200/600], Loss: 0.7407\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0243\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3797\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6385\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6596\n",
      "Similarity to Ideal: 0.9347370711110621 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5917\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6124\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9856\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4830\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6797\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6746\n",
      "Similarity to Ideal: 0.9253844824377615 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.6565\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8700\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9950\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6737\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6561\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7100\n",
      "Similarity to Ideal: 0.9056937807704284 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9553\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9055\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9006\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5510\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7972\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7391\n",
      "Similarity to Ideal: 0.9143578410180322 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8783\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9445\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9831\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6702\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9188\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8390\n",
      "Similarity to Ideal: 0.8954409283758694 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8330\n",
      "Epoch [1/1], Step [200/600], Loss: 1.0780\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9443\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6014\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9136\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6913\n",
      "Similarity to Ideal: 0.8882257474027858 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2955\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3118\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2945\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3056\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2951\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3118\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3057\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3036\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2950\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3118\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3057\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3036\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2950\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3118\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3057\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3036\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2950\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3118\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3057\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3036\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.12 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9412\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2309\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1047\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7508\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9921\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7374\n",
      "Similarity to Ideal: 0.8865816129154233 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1225\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2082\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0976\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7689\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1009\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9029\n",
      "Similarity to Ideal: 0.7638539896629054 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1192\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1167\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2111\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9227\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2212\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7967\n",
      "Similarity to Ideal: 0.8413596457008155 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9585\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2559\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2009\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9510\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1699\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8578\n",
      "Similarity to Ideal: 0.8033892385871572 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4053\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5417\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2702\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1031\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2424\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0623\n",
      "Similarity to Ideal: 0.8282128277192793 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2075\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5793\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1092\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0151\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2253\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9160\n",
      "Similarity to Ideal: 0.8088890057803009 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3677\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5178\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1689\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9660\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3490\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9201\n",
      "Similarity to Ideal: 0.7594405675912088 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3037\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3067\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2971\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3041\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2934\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3068\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3046\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3034\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.2 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2969\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2948\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3024\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3076\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2947\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3022\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3004\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2967\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2946\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3021\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3033\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.21 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.4616\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6183\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3681\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2351\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3549\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0455\n",
      "Similarity to Ideal: 0.6749823052135188 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3853\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5610\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3711\n",
      "Epoch [1/1], Step [400/600], Loss: 1.2333\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6093\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0642\n",
      "Similarity to Ideal: 0.6062529582234207 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2948\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3006\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2930\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3077\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3008\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2944\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2929\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2943\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2928\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3009\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3020\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.24 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3608\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4192\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4888\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1858\n",
      "Epoch [1/1], Step [500/600], Loss: 1.6008\n",
      "Epoch [1/1], Step [600/600], Loss: 1.2365\n",
      "Similarity to Ideal: 0.6338464092144303 \n",
      "\n",
      "Trial: 40\n",
      "__________________________________________________\n",
      "training 0.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0562\n",
      "Epoch [1/1], Step [200/600], Loss: 0.0183\n",
      "Epoch [1/1], Step [300/600], Loss: 0.1825\n",
      "Epoch [1/1], Step [400/600], Loss: 0.0780\n",
      "Epoch [1/1], Step [500/600], Loss: 0.1662\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3547\n",
      "Similarity to Ideal: 0.9953563896931673 \n",
      "\n",
      "training 1.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.0879\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1227\n",
      "Epoch [1/1], Step [300/600], Loss: 0.4396\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3406\n",
      "Epoch [1/1], Step [500/600], Loss: 0.3633\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3052\n",
      "Similarity to Ideal: 0.9817770553851154 \n",
      "\n",
      "training 2.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3769\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1558\n",
      "Epoch [1/1], Step [300/600], Loss: 0.2680\n",
      "Epoch [1/1], Step [400/600], Loss: 0.1557\n",
      "Epoch [1/1], Step [500/600], Loss: 0.2706\n",
      "Epoch [1/1], Step [600/600], Loss: 0.2698\n",
      "Similarity to Ideal: 0.9803199617738504 \n",
      "\n",
      "training 3.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3255\n",
      "Epoch [1/1], Step [200/600], Loss: 0.1583\n",
      "Epoch [1/1], Step [300/600], Loss: 0.7335\n",
      "Epoch [1/1], Step [400/600], Loss: 0.2835\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5358\n",
      "Epoch [1/1], Step [600/600], Loss: 0.3326\n",
      "Similarity to Ideal: 0.9768615578927901 \n",
      "\n",
      "training 4.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4206\n",
      "Epoch [1/1], Step [200/600], Loss: 0.4611\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0197\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4367\n",
      "Epoch [1/1], Step [500/600], Loss: 0.5752\n",
      "Epoch [1/1], Step [600/600], Loss: 0.4003\n",
      "Similarity to Ideal: 0.9580326014553732 \n",
      "\n",
      "training 5.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.3028\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6119\n",
      "Epoch [1/1], Step [300/600], Loss: 0.8427\n",
      "Epoch [1/1], Step [400/600], Loss: 0.3071\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6848\n",
      "Epoch [1/1], Step [600/600], Loss: 0.5146\n",
      "Similarity to Ideal: 0.9501763450553617 \n",
      "\n",
      "training 6.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.4774\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6793\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9177\n",
      "Epoch [1/1], Step [400/600], Loss: 0.4207\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6036\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6606\n",
      "Similarity to Ideal: 0.92025269202689 \n",
      "\n",
      "training 7.000000000000001% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.5667\n",
      "Epoch [1/1], Step [200/600], Loss: 0.6626\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9913\n",
      "Epoch [1/1], Step [400/600], Loss: 0.5217\n",
      "Epoch [1/1], Step [500/600], Loss: 0.6621\n",
      "Epoch [1/1], Step [600/600], Loss: 0.6371\n",
      "Similarity to Ideal: 0.9175609740859599 \n",
      "\n",
      "training 8.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.7659\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9014\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0875\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7527\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7650\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7221\n",
      "Similarity to Ideal: 0.900450983203129 \n",
      "\n",
      "training 9.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9434\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9507\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9500\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6151\n",
      "Epoch [1/1], Step [500/600], Loss: 0.7694\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9164\n",
      "Similarity to Ideal: 0.8666576950498356 \n",
      "\n",
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8856\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9888\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0315\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6403\n",
      "Epoch [1/1], Step [500/600], Loss: 0.8753\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8589\n",
      "Similarity to Ideal: 0.8924651789824697 \n",
      "\n",
      "training 11.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9021\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9427\n",
      "Epoch [1/1], Step [300/600], Loss: 0.9974\n",
      "Epoch [1/1], Step [400/600], Loss: 0.6974\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9538\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7713\n",
      "Similarity to Ideal: 0.8956951534215528 \n",
      "\n",
      "training 12.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.8037\n",
      "Epoch [1/1], Step [200/600], Loss: 0.9549\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0062\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7418\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9137\n",
      "Epoch [1/1], Step [600/600], Loss: 0.7025\n",
      "Similarity to Ideal: 0.8932594723957954 \n",
      "\n",
      "training 13.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2955\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3070\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3080\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3075\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3002\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Epoch [1/1], Step [100/600], Loss: 2.2953\n",
      "Epoch [1/1], Step [200/600], Loss: 2.3073\n",
      "Epoch [1/1], Step [300/600], Loss: 2.2910\n",
      "Epoch [1/1], Step [400/600], Loss: 2.3074\n",
      "Epoch [1/1], Step [500/600], Loss: 2.3003\n",
      "Epoch [1/1], Step [600/600], Loss: 2.3081\n",
      "Loss too high; doing additional training \n",
      "\n",
      "Model failed to converge\n",
      "Skipping: 0.13 \n",
      "\n",
      "training 14.000000000000002% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0533\n",
      "Epoch [1/1], Step [200/600], Loss: 1.2293\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0817\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7502\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1170\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8116\n",
      "Similarity to Ideal: 0.8759207081351802 \n",
      "\n",
      "training 15.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1098\n",
      "Epoch [1/1], Step [200/600], Loss: 1.1458\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2257\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9252\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1575\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9420\n",
      "Similarity to Ideal: 0.8207045925308403 \n",
      "\n",
      "training 16.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.0278\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3958\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1217\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9069\n",
      "Epoch [1/1], Step [500/600], Loss: 1.0871\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8630\n",
      "Similarity to Ideal: 0.7673113586711108 \n",
      "\n",
      "training 17.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.1922\n",
      "Epoch [1/1], Step [200/600], Loss: 1.3154\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0672\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9694\n",
      "Epoch [1/1], Step [500/600], Loss: 1.1632\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8684\n",
      "Similarity to Ideal: 0.7984284190912279 \n",
      "\n",
      "training 18.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.2412\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4203\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3071\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0326\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3462\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0139\n",
      "Similarity to Ideal: 0.7270193006073573 \n",
      "\n",
      "training 19.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3483\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4053\n",
      "Epoch [1/1], Step [300/600], Loss: 1.1621\n",
      "Epoch [1/1], Step [400/600], Loss: 0.9595\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3818\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9465\n",
      "Similarity to Ideal: 0.7908964090014625 \n",
      "\n",
      "training 20.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3896\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4457\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3135\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1736\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5060\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0179\n",
      "Similarity to Ideal: 0.7387061856744568 \n",
      "\n",
      "training 21.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3291\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6326\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2276\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1602\n",
      "Epoch [1/1], Step [500/600], Loss: 1.2354\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9417\n",
      "Similarity to Ideal: 0.7125773005493754 \n",
      "\n",
      "training 22.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3737\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4874\n",
      "Epoch [1/1], Step [300/600], Loss: 1.2520\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0905\n",
      "Epoch [1/1], Step [500/600], Loss: 1.3609\n",
      "Epoch [1/1], Step [600/600], Loss: 0.9725\n",
      "Similarity to Ideal: 0.668877195282936 \n",
      "\n",
      "training 23.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3471\n",
      "Epoch [1/1], Step [200/600], Loss: 1.6031\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4329\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1075\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5229\n",
      "Epoch [1/1], Step [600/600], Loss: 1.1052\n",
      "Similarity to Ideal: 0.6022255483140959 \n",
      "\n",
      "training 24.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3446\n",
      "Epoch [1/1], Step [200/600], Loss: 1.5960\n",
      "Epoch [1/1], Step [300/600], Loss: 1.4439\n",
      "Epoch [1/1], Step [400/600], Loss: 1.1495\n",
      "Epoch [1/1], Step [500/600], Loss: 1.5700\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0948\n",
      "Similarity to Ideal: 0.6911634686967834 \n",
      "\n",
      "training 25.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 1.3189\n",
      "Epoch [1/1], Step [200/600], Loss: 1.4213\n",
      "Epoch [1/1], Step [300/600], Loss: 1.3614\n",
      "Epoch [1/1], Step [400/600], Loss: 1.0990\n",
      "Epoch [1/1], Step [500/600], Loss: 1.4906\n",
      "Epoch [1/1], Step [600/600], Loss: 1.0547\n",
      "Similarity to Ideal: 0.6435136340531955 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot = False\n",
    "bound1 = 0\n",
    "bound2 = 25\n",
    "num_trials = 40\n",
    "trials_dict_new = {}\n",
    "\n",
    "for n in range(num_trials):\n",
    "    print(\"Trial:\", (n+1))\n",
    "    print(\"__________________________________________________\")\n",
    "    if plot:\n",
    "        list_1, list_2 = error_percentage_looper(bound1, bound2)\n",
    "    else:\n",
    "        list_1, list_2 = error_percentage_looper(bound1, bound2, plot=False)\n",
    "    data_array = np.array([list_1, list_2]).transpose()\n",
    "    trials_dict_new[\"trial {}\".format((n+1))] = data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f8d45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = [22, 23, 27, 29, 32, 34]\n",
    "\n",
    "list_1_copy = np.delete(list_1, remove_list)\n",
    "list_2_copy = np.delete(list_2, remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea9622a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(list_1_copy, list_2_copy)\n",
    "plt.title(\"Angular Similarity Between Softmaxed Outputs Distribution and Ideal Classifier Distribution Over \\\n",
    "Mislabeling Fraction\")\n",
    "plt.xlabel(\"Mislabeling Fraction\")\n",
    "plt.ylabel(\"Angular Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f5cefe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for trial in trials_dict.keys():\n",
    "    plt.scatter(trials_dict[trial][:,0], trials_dict[trial][:,1])\n",
    "    plt.xlabel(\"fraction mislabeled\")\n",
    "    plt.ylabel(\"angular similarity\")\n",
    "    plt.title(\"Angular Similarity Between Softmaxed Outputs from Model Trained with a Given Mislabeling Percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bbf93855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99497504, 0.97294104, 0.98170881, 0.96650371, 0.95990903,\n",
       "       0.93615732, 0.92943847, 0.93231885, 0.91794792, 0.8830827 ,\n",
       "       0.89247749, 0.85491714, 0.87931765, 0.89299942, 0.89183442,\n",
       "       0.8494092 , 0.79599804, 0.78354325, 0.75859965, 0.77293433,\n",
       "       0.74858863, 0.61355176, 0.64605077, 0.58399017, 0.64744825,\n",
       "       0.59860924])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials_dict['trial 1'][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f817addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAHHCAYAAAD3URpJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3yT1f7A8c+TtE2T7r2AUsosIHvIXjIE3KKgouJAr+OnXue9XsfV6x54VVxXxYFbRHGACKLIVoZMKVAKFLp306ZNcn5/lIamTZ6mUJZ+368X99rnOTk5efLkyfPNOed7NKWUQgghhBBCCCHEacdwshsghBBCCCGEEOLoSEAnhBBCCCGEEKcpCeiEEEIIIYQQ4jQlAZ0QQgghhBBCnKYkoBNCCCGEEEKI05QEdEIIIYQQQghxmpKATgghhBBCCCFOUxLQCSGEEEIIIcRpSgI6IYQQQgghhDhN/WkDuoceeghN0052M9zs3bsXTdOYM2dOi9W5bNkyNE1j2bJlrm1XXXUVbdu2bbHnqKNpGg899FCL1ytOXTk5OVx00UVERUWhaRqzZs062U06YY7H5/Wv6umnn6Zdu3YYjUZ69ux5sptzSpozZw6aprF3795mP/ZU+r5r27YtV1111Ul57uP13QfNux7UlX3mmWeOS1uOhz/r9/vRXsdHjBjBiBEjjvr5WvK9P5H3eeL0ddQB3ezZs9E0jQEDBrRke05bCxYsYPjw4cTGxmKxWGjXrh1Tpkxh4cKFJ7tpx83KlSt56KGHKC4ubtF6R4wYgaZprn8BAQGkpKRw/fXXs3///qOq8+DBgzz00ENs3LixRdt6KnE6nbz77rsMGDCAyMhIQkJC6NixI9OnT2f16tVHVeftt9/OokWLuO+++3jvvfcYP34833777Z/yi/9Y7du3jxtuuIG2bdtiMpmIjY3lvPPOY8WKFcdU7+zZs09YULlt2zYeeuihowoqvPn++++5++67GTx4MG+//TaPPfZYi9V9PNRdfzp06OBx/+LFi13Xps8+++wEt+7o1N0Q+vJP+O5UvhbWfR+cddZZREdH4+/vT2xsLGPHjuX111/HZrOd7CY2S92PFgaDweN9QGlpKWazGU3TuPnmm09CC/86Gt6jRUZG0q9fP9566y2cTufJbt4x++CDD07LH6/9jvaBc+fOpW3btqxdu5Zdu3bRvn37lmzXaeWZZ57hrrvuYvjw4dx3331YLBZ27drFDz/8wEcffcT48eMBSE5OprKyEn9//xZ77mHDhlFZWUlAQECL1elNZWUlfn5HTpmVK1fy8MMPc9VVVxEeHt6iz9WqVSsef/xxAKqrq9m2bRuvvvoqixYtYvv27VgslmbVd/DgQR5++GHatm37p+0huPXWW3n55Zc599xzueyyy/Dz8+OPP/7gu+++o127dgwcOLDZdS5dupRzzz2XO++807XtpZde4uWXXz5lb2ROhhUrVnD22WcDcO2115KWlkZ2djZz5sxh6NChvPDCC9xyyy1HVffs2bOJjo4+Ib0e27Zt4+GHH2bEiBEt9uvv0qVLMRgMvPnmmyfkOtUSAgMD2bVrF2vXrqV///5u++bOnUtgYCBVVVUnqXXN16VLF9577z23bffddx/BwcH885//bNHn+uOPPzAY/nyDfzx9f3/77ben5LWwsrKS888/n0WLFjFo0CDuvPNO4uLiKCws5KeffuJvf/sba9as4c0333R7TP3v91OVyWTiww8/5O6773bbPm/ePI/lj8d916ngjTfeOKnBU/17tLy8PN59912uueYadu7cyRNPPHHS2tUSPvjgA7Zs2cJtt912spvSLEf16c3IyGDlypXMmzePmTNnMnfuXB588MGWbtspQylFVVUVZrO50T673c4jjzzCWWedxffff99of25uruu/NU0jMDCwRdtmMBhavM76nE4n1dXVBAYGHtfnaSgsLIzLL7/cbVtKSgo333wzK1as4KyzzjphbTkd5OTkMHv2bK677jpef/11t32zZs0iLy/vqOrNzc1t8WD9z6aoqIiLLroIs9nMihUrSE1Nde274447GDduHLfddht9+vRh0KBBJ7GlJ0dubi5ms7nJYK7+teZkS01NxW638+GHH7oFdFVVVXzxxRdMnDiRzz///CS2sHni4uIaXU+feOIJoqOjG22v72jeE5PJdNTtPJUdj+/v46VuZMWsWbP4v//7P7d9f//730lPT2fx4sVu20+X13b22Wd7DOg++OADj5/L0+l9a46THaA2vEebOXMmnTp14qWXXuKRRx45pvbZ7XacTudp8wPgqeKofkabO3cuERERTJw4kYsuuoi5c+c2KlN/HPHrr79OamoqJpOJfv36sW7dukblP/30U9LS0ggMDKRbt2588cUXjcYIexpHXP+5mhqW9PbbbzNq1ChiY2MxmUykpaXxyiuvNCrXtm1bJk2axKJFi+jbty9ms5nXXnvNY535+fmUlpYyePBgj/tjY2N123nVVVcRHBzMvn37mDRpEsHBwSQlJfHyyy8DsHnzZkaNGkVQUBDJycl88MEHbvV7OyYNPfPMMwwaNIioqCjMZjN9+vTxOFyobrjC3Llz6dq1KyaTyTVstP4Y+4ceeoi77roLqA206rre9+7dy/Dhw+nRo4fHdnTq1Ilx48bpttWb+Ph4gEa/ImZlZTFjxgzi4uIwmUx07dqVt956y7V/2bJl9OvXD4Crr77a1dY5c+bw3//+F6PR6DZs9Nlnn0XTNO644w7XNofDQUhICPfcc49rm9PpZNasWXTt2pXAwEDi4uKYOXMmRUVFjdr+3XffMXToUIKCgggJCWHixIls3brVrUzduZCVlcV5551HcHAwMTEx3HnnnTgcDt1jk5GRgVLK43moaZrbeQiwZ88eLr74YiIjI7FYLAwcOJBvvvnGtb9uPo9Sipdfftl1zK666irXudlwmFb9z/zLL79Mu3btsFgsjB07lv3796OU4pFHHqFVq1aYzWbOPfdcCgsL3dr15ZdfMnHiRBITEzGZTKSmpvLII4+4vf7t27djNpuZPn2622N/+eUXjEaj23tUXFzMbbfdRuvWrTGZTLRv354nn3yy0S+bxcXFXHXVVYSFhREeHs6VV17p81Di1157jezsbJ5++mm3YA7AbDbzzjvvoGka//73v13bvc15ajiPqm3btmzdupWffvrJdazr5nXUlf3555+ZOXMmUVFRhIaGMn369EbnoLf5MfXnO82ZM4eLL74YgJEjR7qer+7a8uuvvzJu3Diio6Mxm82kpKQwY8YM3WOjaRpvv/02FRUVbp+7un3erjUbNmxgwoQJhIaGEhwczOjRoxsNG657/b/88gu33norMTExhIeHM3PmTKqrqykuLmb69OlEREQQERHB3XffjVJKt731TZ06lY8//tjtXFmwYAFWq5UpU6Z4fIwv7QbYunUro0aNwmw206pVKx599FGvv7b7cu1oKXrvia/fIQ3n0NW9TytWrOCOO+4gJiaGoKAgzj//fI8/NPn6eufPn0+3bt3c7hl8cccddxAVFeV2Ltxyyy1omsZ///tf17acnBw0TXPdIzT8/ta7Ftbny/1PQ4WFhdx55510796d4OBgQkNDmTBhAps2bWrysfv37+d///sf48ePbxTM1enQoQN/+9vf3LbVv0Z89tlnaJrGTz/91Oixr732GpqmsWXLFte2HTt2cNFFFxEZGUlgYCB9+/blq6++cntcc88Db6ZNm8bGjRvZsWOHa1t2djZLly5l2rRpjcp7uu/Kzs7m6quvplWrVphMJhISEjj33HN1h5pXV1fzwAMP0KdPH8LCwggKCmLo0KH8+OOPXh/z/PPPk5ycjNlsZvjw4W7HrI4vx86ThvfHx+Oeuznq7iMqKipc76cv37/12z1r1ixXu7dt2+Y6PlOmTCEmJgaz2UynTp0ajSpo6h4Qjtwrf/LJJ/znP/+hVatWBAYGMnr0aHbt2uUqN2LECL755hsyMzNdn+m6Y9Kcc6CgoIArrriC0NBQ1z3Fpk2bPMYqR3sONHRUPXRz587lggsuICAggKlTp/LKK6+wbt06101zfR988AFlZWXMnDkTTdN46qmnuOCCC9izZ48rgv/mm2+45JJL6N69O48//jhFRUVcc801JCUlHU3zvHrllVfo2rUr55xzDn5+fixYsIC//e1vOJ1ObrrpJreyf/zxB1OnTmXmzJlcd911dOrUyWOdsbGxmM1mFixYwC233EJkZGSz2+VwOJgwYQLDhg3jqaeeYu7cudx8880EBQXxz3/+k8suu4wLLriAV199lenTp3PmmWeSkpLSrOd44YUXOOecc7jsssuorq7mo48+4uKLL+brr79m4sSJbmWXLl3KJ598ws0330x0dLTHD/gFF1zAzp07+fDDD3n++eeJjo4GICYmhiuuuILrrruOLVu20K1bN9dj1q1bx86dO7n//vt9Oib5+fkA1NTUsH37dh588EHat2/vFrTk5OQwcOBA141ITEwM3333Hddccw2lpaXcdtttdOnShX//+9888MADXH/99QwdOhSAQYMGUVJSgtPp5JdffmHSpEkALF++HIPBwPLly13Ps2HDBsrLyxk2bJhr28yZM5kzZw5XX301t956KxkZGbz00kts2LCBFStWuM7v9957jyuvvJJx48bx5JNPYrVaeeWVVxgyZAgbNmxwO74Oh4Nx48YxYMAAnnnmGX744QeeffZZUlNTufHGG70er+TkZKD2In3xxRfrDknNyclh0KBBWK1Wbr31VqKionjnnXc455xz+Oyzzzj//PMZNmwY7733HldccQVnnXWWK3hKTU3l4MGDLF68uNEQrjpz586lurqaW265hcLCQp566immTJnCqFGjWLZsGffccw+7du3ixRdf5M4773S78M6ZM4fg4GDuuOMOgoODWbp0KQ888AClpaU8/fTTQO3wsUceeYS77rqLiy66iHPOOYeKigquuuoqOnfu7AqcrFYrw4cPJysri5kzZ9KmTRtWrlzJfffdx6FDh1xj5JVSnHvuufzyyy/ccMMNdOnShS+++IIrr7zS6zGsb8GCBQQGBnq9yU9JSWHIkCEsXbqUyspKjz393syaNYtbbrnFbWhcXFycW5mbb76Z8PBwHnroIf744w9eeeUVMjMzXV9gvho2bBi33nor//3vf/nHP/5Bly5dgNrjnZuby9ixY4mJieHee+8lPDycvXv3eh3mVOe9997j9ddfZ+3atfzvf/8DcOul9HSt2bp1K0OHDiU0NJS7774bf39/XnvtNUaMGMFPP/3UaN72LbfcQnx8PA8//DCrV6/m9ddfJzw8nJUrV9KmTRsee+wxvv32W55++mm6devW6IcAb6ZNm8ZDDz3EsmXLGDVqFFD7fTZ69OhGP5AAPrc7OzubkSNHYrfbuffeewkKCuL111/3eF4059rRUrxd/5vzHeLJLbfcQkREBA8++CB79+5l1qxZ3HzzzXz88cfNfr3ff/89F154IWlpaTz++OMUFBS4btCbMnToUJ5//nm2bt3q+n6qf82/9dZbXdsAt2t+fTNnzmzyWujL/Y8ne/bsYf78+Vx88cWkpKSQk5PDa6+9xvDhw9m2bRuJiYleH/vdd9/hcDh0e16bMnHiRIKDg/nkk08YPny4276PP/6Yrl27uo7d1q1bGTx4MElJSa7z+ZNPPuG8887j888/5/zzz3d7vC/ngZ5hw4bRqlUrPvjgA9e1/uOPPyY4ONin8xDgwgsvZOvWrdxyyy20bduW3NxcFi9ezL59+7x+pkpLS/nf//7H1KlTue666ygrK+PNN99k3LhxrF27ttFUjnfffZeysjJuuukmqqqqeOGFFxg1ahSbN292XcObe+x8cTLvuffs2YPRaCQ8PNzn7986b7/9NlVVVVx//fWYTCYiIyP5/fffGTp0KP7+/lx//fW0bduW3bt3s2DBAv7zn/8Avt0D1vfEE09gMBi48847KSkp4amnnuKyyy5jzZo1APzzn/+kpKSEAwcO8PzzzwMQHBwM+H4OOJ1OJk+ezNq1a7nxxhvp3LkzX375pcd7ihY9B1Qz/frrrwpQixcvVkop5XQ6VatWrdT//d//uZXLyMhQgIqKilKFhYWu7V9++aUC1IIFC1zbunfvrlq1aqXKyspc25YtW6YAlZyc7Nr2448/KkD9+OOPHp/r7bffdm178MEHVcOXZ7VaG72ecePGqXbt2rltS05OVoBauHCh7rGo88ADDyhABQUFqQkTJqj//Oc/6rfffmtUzlM7r7zySgWoxx57zLWtqKhImc1mpWma+uijj1zbd+zYoQD14IMPurZ5OiZXXnml23Hz9Nqrq6tVt27d1KhRo9y2A8pgMKitW7c2an/D53766acVoDIyMtzKFRcXq8DAQHXPPfe4bb/11ltVUFCQKi8vb1R3fcOHD1dAo39dunRRe/bscSt7zTXXqISEBJWfn++2/dJLL1VhYWGu171u3bpGx14ppRwOhwoNDVV33323Uqr2fI6KilIXX3yxMhqNrnPyueeeUwaDQRUVFSmllFq+fLkC1Ny5c93qW7hwodv2srIyFR4erq677jq3ctnZ2SosLMxte9258O9//9utbK9evVSfPn10j5lSSk2fPl0BKiIiQp1//vnqmWeeUdu3b29U7rbbblOAWr58uWtbWVmZSklJUW3btlUOh8O1HVA33XST2+NvuummRp8tpY6c3zExMaq4uNi1/b777lOA6tGjh6qpqXFtnzp1qgoICFBVVVWubZ4+ozNnzlQWi8WtnMPhUEOGDFFxcXEqPz9f3XTTTcrPz0+tW7fOVeaRRx5RQUFBaufOnW713XvvvcpoNKp9+/YppZSaP3++AtRTTz3lKmO329XQoUM9njMNhYeHqx49euiWufXWWxWgfv/9d6WU5+uTUkq9/fbbjT5TXbt2VcOHD/datk+fPqq6utq1/amnnlKA+vLLL13bGn526yQnJ6srr7zS9fenn37q8Rr7xRdfKMDt+PrqyiuvVEFBQY22e7vWnHfeeSogIEDt3r3bte3gwYMqJCREDRs2zLWt7vWPGzdOOZ1O1/YzzzxTaZqmbrjhBtc2u92uWrVq5fE4NjR8+HDVtWtXpZRSffv2Vddcc41Sqva6HBAQoN555x3XdffTTz9tdrvrPn9r1qxxbcvNzVVhYWFu731zrh3ezic9ns4rveu/r98hDc+puvdpzJgxbu/T7bffroxGo+ta0ZzX27NnT5WQkOB2nfn+++8b3TN4kpubqwA1e/ZspVTt95XBYFAXX3yxiouLc5W79dZbVWRkpKvNnr6/m7oW+nL/40lVVZXbdbiuTpPJ1Oj7oaHbb79dAWrjxo1u2202m8rLy3P9a/id2fAaMXXqVBUbG6vsdrtr26FDh5TBYHBrw+jRo1X37t3drs9Op1MNGjRIdejQwbXN1/PAm7pzPC8vT915552qffv2rn39+vVTV199tet11P/Oavi+FRUVKUA9/fTTus83fPhwt8+H3W5XNpvNrUxRUZGKi4tTM2bMaPR8ZrNZHThwwLV9zZo1ClC33367a5uvx86X+7zjcc+td2w6d+7sOpe2b9/u+o6bPHmyUsr379+6doeGhqrc3Fy3ssOGDVMhISEqMzPTbXv988fXe8C6Y9ilSxe39/GFF15QgNq8ebNr28SJEz0eB1/Pgc8//1wBatasWa5tDodDjRo1qtE1xNdzwBfNHnI5d+5c4uLiGDlyJFDbTX/JJZfw0UcfeRwWdskllxAREeH6u653ZM+ePUBtsorNmzczffp0VxQMMHz4cLp3797c5umq/wtoSUkJ+fn5DB8+nD179lBSUuJWNiUlxeehgQ8//DAffPABvXr1YtGiRfzzn/+kT58+9O7dm+3bt/tUx7XXXuv67/DwcDp16kRQUJDbr/6dOnUiPDzcdeyao/5rLyoqoqSkhKFDh7J+/fpGZYcPH05aWlqzn6NOWFgY5557Lh9++KFrWIvD4eDjjz/mvPPOIygoqMk62rZty+LFi1m8eDHfffcds2bNoqSkhAkTJri685VSfP7550yePBmlFPn5+a5/48aNo6SkxOPrq89gMDBo0CB+/vlnoHY4X0FBAffeey9KKVatWgXU/lrbrVs313yyTz/9lLCwMM466yy35+3Tpw/BwcGuLvjFixdTXFzM1KlT3coZjUYGDBjgsav+hhtucPt76NChPr3nb7/9Ni+99BIpKSl88cUX3HnnnXTp0oXRo0eTlZXlKvftt9/Sv39/hgwZ4toWHBzM9ddfz969e11DHY7WxRdfTFhYmOvvup6Jyy+/3G247IABA6iurnZrW/3ztKysjPz8fIYOHYrVanUbYmMwGJgzZw7l5eVMmDCB2bNnc99999G3b19XmU8//ZShQ4cSERHhduzHjBmDw+Fwvefffvstfn5+bj2gRqPR5yQmZWVlhISE6Jap219aWupTnc1x/fXXu/3af+ONN+Ln58e3337bYs9Rd95//fXX1NTUtFi9Da81DoeD77//nvPOO4927dq5tickJDBt2jR++eWXRsfwmmuuceuJHDBgAEoprrnmGtc2o9FI3759m33tnDZtGvPmzaO6uprPPvsMo9Ho8RfT5rT722+/ZeDAgW5z82JiYrjsssvc6jyaa0dL8Hb9b853iCfXX3+92/s0dOhQHA4HmZmZgO+v99ChQ2zcuJErr7zS7Tpz1lln+fS9FRMTQ+fOnV2f/xUrVmA0GrnrrrvIyckhPT0dqL3mDxky5JgyfzZ1/+ONyWRyJZZxOBwUFBQQHBxMp06dmjzededZ/fspqD3vYmJiXP/qRnXotT03N9dtOsdnn32G0+nkkksuAWqHhi5dupQpU6a4rtf5+fkUFBQwbtw40tPT3a7v0PR54Itp06axa9cu1q1b5/p/T8MtPambz7ts2TKP0yO8MRqNrjldTqeTwsJC7HY7ffv29fienHfeeW49Xv3792fAgAGu6/LRHDtfnKh77h07drjOpS5duvDiiy8yceJE14gbX79/61x44YXExMS4/s7Ly+Pnn39mxowZtGnTxq1s3flzNPeAV199tdvcPF8/k+D7ObBw4UL8/f257rrrXNsMBkOjkYAtfQ40a8ilw+Hgo48+YuTIkWRkZLi2DxgwgGeffZYlS5YwduxYt8c0fCPqTrS6D1Ldh9hTlsz27dv7/GXhixUrVvDggw+yatUqrFar276SkhK3L4fmDmmcOnUqU6dOpbS0lDVr1jBnzhw++OADJk+ezJYtW3Qn5QYGBrqdyFAbFLVq1arRl0lYWFizLkJ1vv76ax599FE2btzolq7Y05dVc1+7J9OnT+fjjz9m+fLlDBs2jB9++IGcnByuuOIKnx4fFBTEmDFjXH+PHz+eIUOG0LdvX5544gmeffZZ8vLyKC4u5vXXX2+UCKRO/aQ03gwdOpSHHnqIyspKli9fTkJCAr1796ZHjx4sX76cs846i19++cUtuE5PT6ekpMTj0Kv6z1t3c1A3ZKuh0NBQt789nQsRERE+ved1F4ybbrqJgoICVqxYwauvvsp3333HpZde6hpClJmZ6XG5kbohdpmZmW5DZZur4We+7nPVunVrj9vrv7atW7dy//33s3Tp0kY37g1/dElNTXXN5ezWrRv/+te/3Panp6fz+++/Nzqedereo8zMTBISEhrdAHkbZt1QSEgIZWVlumXq9jcV+B2Nhun1g4ODSUhIaNGlB4YPH86FF17Iww8/zPPPP8+IESM477zzmDZt2jElwWh4rcnLy8NqtXo89l26dMHpdLJ//366du3q2t6c8625185LL72UO++8k++++465c+cyadIkj+9hc9rt7fPX8LHNvXa0FG/X/+Z8h3jS1L2Ar6+37p7B07ISvgQ8UHvNr7uxXr58OX379qVv375ERkayfPly4uLi2LRpk89BgjdNvWZvnE4nL7zwArNnzyYjI8Ptx/KoqCjdx9adn+Xl5W7bBw8e7EqE8vTTTze5nMr48eMJCwvj448/ZvTo0UDt0MaePXvSsWNHAHbt2oVSin/961+Nrr91cnNz3QKboz0m9fXq1YvOnTvzwQcfEB4eTnx8vNfzpiGTycSTTz7J3//+d+Li4hg4cCCTJk1i+vTprnn63rzzzjs8++yz7Nixw+2HLU+fGU/nZ8eOHfnkk0+Aozt2vjhR99xt27bljTfecCWd6dChg9v9kK/fv3UaHsO6AEvvXuRo7gGP9fzz5Ryou6doOPWl4TFv6XOgWQHd0qVLOXToEB999BEfffRRo/1z585tFNAZjUaPddX13DSHty+OphJGAOzevZvRo0fTuXNnnnvuOVq3bk1AQADffvstzz//fKMJ6c2Z51JfaGgoZ511FmeddRb+/v688847rFmzptE49Pq8HaOWOnbLly/nnHPOYdiwYcyePZuEhAT8/f15++23GyVZgaN/7fWNGzeOuLg43n//fYYNG8b7779PfHy8W5DWXHUTUet+2al7zy6//HKv853OOOOMJusdMmQINTU1rFq1iuXLl7t+sRk6dCjLly9nx44d5OXlubbXPXdsbKzHhECA6yJW18b33nvP45dFwwQv3t7z5oqKiuKcc87hnHPOcc3hyczMbPJX2ZZwtOdzcXExw4cPJzQ0lH//+9+kpqYSGBjI+vXrueeeezwmjajLLHvw4EEKCgrcjrHT6eSss85qlA2tTt1NybHq0qULGzZswGazeQ1ufv/9d/z9/V1f8sdyLWtJvj5f3Zprq1evZsGCBSxatIgZM2bw7LPPsnr16kbBsK9a4lrTnPOtudfOhIQERowYwbPPPsuKFStOaGbL5l47Woqn96S53yGeNPX5P5Gvd8iQIbzxxhvs2bPHdc3XNI0hQ4awfPlyEhMTcTqdbtf8o3G03+GPPfYY//rXv5gxYwaPPPIIkZGRGAwGbrvttiZT1Xfu3BmALVu2uCUni4mJcX3/vv/++0223WQycd555/HFF18we/ZscnJyWLFihds6knVtufPOO72OaGp4E9tS9zXTpk3jlVdeISQkhEsuuaRZS2XcdtttTJ48mfnz57No0SL+9a9/8fjjj7N06VJ69erl8THvv/8+V111Feeddx533XUXsbGxGI1GHn/8cXbv3t2stsPRHTtftOQ9t56GP7o31Nzv36P5Ljiae8BjOT6n+jnQrCvk3LlziY2NdWV2qm/evHl88cUXvPrqq816Y+puMOtnmanTcFtdJN0w+5wvXfULFizAZrPx1VdfuUXox2vYCkDfvn155513OHTo0HF7Dl98/vnnBAYGsmjRIrcbzrfffvuY6tX7ZdZoNDJt2jTmzJnDk08+yfz587nuuuuOOWBxOByuXx5jYmIICQnB4XA0GSjqtbV///4EBASwfPlyli9f7sreOWzYMN544w2WLFni+rtOamoqP/zwA4MHD9Y93+uyHsbGxh5TMHss+vbty08//cShQ4dITk4mOTmZP/74o1G5uiGNTQV9x2vx4WXLllFQUMC8efPcjnX90QD1vfrqqyxevJj//Oc/PP7448ycOZMvv/zStT81NZXy8vImj3tycjJLliyhvLzcLTDxdIw8mTRpEqtWreLTTz/1mIhg7969LF++nDFjxrjOlfrXsvrLQni6ljV1vNPT011D4KH2l/lDhw651sWre76G183q6upG16amnmvgwIEMHDiQ//znP3zwwQdcdtllfPTRR25Dxo9FTEwMFovF6/lpMBga9bwdb9OmTePaa68lPDzc7ZjW15x2Jycnu3qj6mv42FPh2lHneH2H1Ofr6627PvlyDL2pC9QWL17MunXruPfee4Haa/wrr7xCYmIiQUFB9OnTR7ee43Ut/Oyzzxg5cqTbOnFQe72oS0DmzYQJEzAajcydO7fRMN7muuSSS3jnnXdYsmQJ27dvRynlGm4JuIYX+/v7n/BzdNq0aTzwwAMcOnTIa1IaPampqfz97393LePQs2dPnn32Wa/B7meffUa7du2YN2+e2/vubckuT+fnzp07XUlXTtaxa84997Hw9fvXm7rj4ykzaJ3m3AM2h7fPta/nQHJyMj/++CNWq9Wtl67h8W3pc8DnnzQqKyuZN28ekyZN4qKLLmr07+abb6asrKzZqTYTExPp1q0b7777rtsQgZ9++onNmze7lU1OTsZoNDYaezt79uwmn6cukKgfhZeUlBzzF5LVanXNs2rou+++A3wfunW8GI1GNE1z+zV+7969zJ8//5jqrZsL5y29+xVXXEFRUREzZ86kvLz8mLJuQW3wXV5e7vrV0Wg0cuGFF/L55597/NDXT4Ws19bAwED69evHhx9+yL59+9x66CorK/nvf/9LamoqCQkJrsdMmTIFh8PBI4880qg+u93uep5x48YRGhrKY4895nHu0dGuD9dQdna2x7lv1dXVLFmyBIPB4Pql5+yzz2bt2rVu521FRQWvv/46bdu2bXIeSlPv+9Hy9Bmtrq72+PnOyMjgrrvu4sILL+Qf//gHzzzzDF999RXvvvuuq8yUKVNYtWoVixYtavT44uJi7HY7UHs87Ha72xImDoeDF1980ad2z5w5k9jYWO66665G4/Crqqq4+uqrUUrxwAMPuLbX3bzWv5ZVVFTwzjvvNKo/KChI91i//vrrbufWK6+8gt1uZ8KECW7P1/C6+frrrzfqofP23hYVFTX6BbMuo1f94XfHymg0MnbsWL788ku3IaM5OTl88MEHDBky5LgNNfTmoosu4sEHH2T27Nle10VqTrvPPvtsVq9ezdq1a13l8vLyGvX2n6hrhy+O13dIfb6+3oSEBHr27Mk777zjNgx78eLFPs//TUlJISkpieeff56amhpX5uShQ4eye/duPvvsMwYOHNhkr+DxvBY2/Lx9+umnPs2nadOmDTNmzOC7777jpZde8ljG196aMWPGEBkZyccff8zHH39M//793YaWxcbGMmLECF577TWPP1wfz3M0NTWVWbNm8fjjj7vNR22K1WqlqqqqUV0hISG61zJP309r1qzxev83f/58t/dr7dq1rFmzxnVdPlnHrjn33MfC1+9fb2JiYhg2bBhvvfUW+/btc9tX9x405x6wOYKCghpN8ah7vvrPD57PgXHjxlFTU8Mbb7zh2uZ0Oht1hrX0OeBzD91XX31FWVkZ55xzjsf9AwcOJCYmhrlz57r9guOLxx57jHPPPZfBgwdz9dVXU1RUxEsvvUS3bt3cTriwsDAuvvhiXnzxRTRNIzU1la+//tqneVJjx44lICCAyZMnuwKMN954g9jY2GPqQbNarQwaNIiBAwcyfvx4WrduTXFxMfPnz2f58uWcd955XrvwT5SJEyfy3HPPMX78eKZNm0Zubi4vv/wy7du35/fffz/qeut+vfznP//JpZdeir+/P5MnT3Z9yfXq1Ytu3brx6aef0qVLF3r37u1z3SUlJa5fyux2uysdu9lsdv2aCrUpaH/88UcGDBjAddddR1paGoWFhaxfv54ffvjBtc5Zamoq4eHhvPrqq4SEhBAUFMSAAQNcX05Dhw7liSeeICwszDUxODY2lk6dOvHHH3+4rasEtXOKZs6cyeOPP87GjRsZO3Ys/v7+pKen8+mnn/LCCy9w0UUXERoayiuvvMIVV1xB7969ufTSS4mJiWHfvn188803DB482OuXbnMcOHCA/v37M2rUKEaPHk18fDy5ubl8+OGHbNq0idtuu831y+69997Lhx9+yIQJE7j11luJjIzknXfeISMjg88//7zJoSt17/utt97KuHHjMBqNXHrppcf8GgYNGkRERARXXnklt956K5qm8d577zW6+VBKMWPGDMxmsysImzlzJp9//jn/93//x5gxY0hMTOSuu+7iq6++YtKkSVx11VX06dOHiooKNm/ezGeffcbevXuJjo5m8uTJDB48mHvvvZe9e/eSlpbGvHnzPF7QPYmKiuKzzz5j4sSJ9O7dm2uvvZa0tDSys7OZM2cOu3bt4oUXXnBL1z927FjatGnDNddcw1133YXRaOStt95ynRv19enTh1deeYVHH32U9u3bExsb6zZfpLq6mtGjRzNlyhT++OMPZs+ezZAhQ9yu1ddeey033HADF154IWeddRabNm1i0aJFjX7t79mzJ0ajkSeffJKSkhJMJhOjRo3igw8+YPbs2Zx//vmkpqZSVlbGG2+8QWhoqNdeq6P16KOPsnjxYoYMGcLf/vY3/Pz8eO2117DZbDz11FMt+ly+CAsL87iGX0O+tvvuu+/mvffec60TVrdsQXJystv1+ERdO3xxvL5D6mvO63388ceZOHEiQ4YMYcaMGRQWFvLiiy/StWvXRnPHvBk6dCgfffQR3bt3d/WY9+7dm6CgIHbu3OnT/LnjdS2cNGkS//73v7n66qsZNGgQmzdvZu7cuW4Jd/TMmjWLjIwMbrnlFj766CMmT55MbGws+fn5rFixggULFvj0Q7O/vz8XXHABH330ERUVFTzzzDONyrz88ssMGTKE7t27c91119GuXTtycnJYtWoVBw4c8GntvKPlbZ09PTt37nRdL9PS0vDz8+OLL74gJydH972bNGkS8+bN4/zzz2fixIlkZGTw6quvkpaW5vGca9++PUOGDOHGG2/EZrMxa9YsoqKi3IYgnqxj5+s997Hw9ftXz3//+1+GDBlC7969uf7660lJSWHv3r188803bNy4EfD9HrA5+vTpw8cff8wdd9xBv379CA4OZvLkyT6fA+eddx79+/fn73//O7t27aJz58589dVXrrbU791r0XPA13SYkydPVoGBgaqiosJrmauuukr5+/ur/Px8VypST6lh8ZBC+6OPPlKdO3dWJpNJdevWTX311VfqwgsvVJ07d3Yrl5eXpy688EJlsVhURESEmjlzptqyZUujVKCe0jh/9dVX6owzzlCBgYGqbdu26sknn1RvvfVWozThycnJauLEiT4dl5qaGvXGG2+o8847TyUnJyuTyaQsFovq1auXevrpp91SnHpbtsBTSu/6qbPra9g2X5ctePPNN1WHDh2UyWRSnTt3Vm+//bbHY4SHNPX19zV83x555BGVlJSkDAZDo+Oo1JEU6vWXZWhKw2ULNE1TkZGR6pxzzvG4HEROTo666aabVOvWrZW/v7+Kj49Xo0ePVq+//rpbuS+//FKlpaUpPz+/Ru/DN998owA1YcIEt8dce+21ClBvvvmmx7a+/vrrqk+fPspsNquQkBDVvXt3dffdd6uDBw+6lfvxxx/VuHHjVFhYmAoMDFSpqanqqquuUr/++qurjLdzwZeU5KWlpeqFF15Q48aNU61atVL+/v4qJCREnXnmmeqNN95wS/OrlFK7d+9WF110kQoPD1eBgYGqf//+6uuvv25Ur6fzwW63q1tuuUXFxMQoTdNcbfP2mfeU4l2pI2ms66fCX7FihRo4cKAym80qMTFR3X333WrRokVu53hdmuHPP//crb59+/ap0NBQdfbZZ7u2lZWVqfvuu0+1b99eBQQEqOjoaDVo0CD1zDPPuKX6LygoUFdccYUKDQ1VYWFh6oorrlAbNmzwadmCOhkZGeq6665Tbdq0Uf7+/io6Olqdc845bstD1Pfbb7+pAQMGqICAANWmTRv13HPPeVy2IDs7W02cOFGFhIQowJVKu67sTz/9pK6//noVERGhgoOD1WWXXaYKCgrcnsvhcKh77rlHRUdHK4vFosaNG6d27drVKMW8Ukq98cYbql27dspoNLqO+/r169XUqVNVmzZtlMlkUrGxsWrSpElu5683essWeLvWrF+/Xo0bN04FBwcri8WiRo4cqVauXOlWxtP5o5R7enNf2tGQt2tvfd7OaV/arZRSv//+uxo+fLgKDAxUSUlJ6pFHHlFvvvmmx2uoL9eOlly2wNt74ut3iLdlCxq+T96WIfLl9SpVmxq8S5cuymQyqbS0NDVv3jyP333evPzyywpQN954o9v2MWPGKEAtWbLEbbun7+/mXguV8r6ESH1VVVXq73//u0pISFBms1kNHjxYrVq1qlEqfT12u129/fbbatSoUSoyMlL5+fmp6OhoNXr0aPXqq6+qyspKn9q1ePFi1/fw/v37PT7X7t271fTp01V8fLzy9/dXSUlJatKkSeqzzz5zlWnuedCQt891Qw3P4YbvW90yN507d1ZBQUEqLCxMDRgwQH3yySdu9TQ81k6nUz322GOu+7xevXqpr7/+2uvyAU8//bR69tlnVevWrZXJZFJDhw5VmzZtOqpj15xlC1r6ntsTX66RSvn2/avXbqWU2rJlizr//PNd9yqdOnVS//rXv9zK+HIP6O2a7elzXV5erqZNm6bCw8PdlnLw9RxQqjZWmTZtmgoJCVFhYWHqqquuUitWrFCA23JkSvl2DvhCU6qFZ0q2oJ49exITE+PKzCROPy+88AK33347e/fubZRdSAhx9OoWtV+3bp3bcg1CCCFEc8k99/E1f/58zj//fH755RfXMO+W1Ox16I6HmpqaRuNply1bxqZNmxgxYsTJaZQ4Zkop3nzzTYYPHy7BnBBCCCHESSb33MdfZWWl29918/JDQ0ObNf2oOY5P3uNmysrKYsyYMVx++eUkJiayY8cOXn31VeLj4xstsixOfRUVFXz11Vf8+OOPbN682S3zoBBCCCGEODnknvv4u+WWW6isrOTMM8/EZrMxb948Vq5cyWOPPdYiy/V4ckoEdBEREfTp04f//e9/5OXlERQUxMSJE3niiSeaXERTnHry8vKYNm0a4eHh/OMf//CaSEcIIYQQQpw4cs99/I0aNYpnn32Wr7/+mqqqKtq3b8+LL77IzTfffNye85SeQyeEEEIIIYQQwrtTYg6dEEIIIYQQQojmk4BOCCGEEEIIIU5Tp8QcOiFOJqfTycGDBwkJCXFb8FEIIYQQpy6lFGVlZSQmJmIwSB+F+OuSgE785R08eJDWrVuf7GYIIYQQ4ijs37+fVq1anexmCHHSSEAn/vJCQkKA2i+E0NDQk9waIYQQQviitLSU1q1bu77HhfirkoBO/OXVDbMMDQ2VgE4IIYQ4zch0CfFXJwOOhRBCCCGEEOI0JQGdEEIIIYQQQpymJKATQgghhBBCiNOUBHRCCCGEEEIIcZqSgE4IIYQQQgghTlMS0AkhhBBCCCHEaUoCOiGEEEIIIYQ4TUlAJ04pP//8M5MnTyYxMRFN05g/f36Tj1m2bBm9e/fGZDLRvn175syZc9zbKYQQQgghxKlAAjpxSqmoqKBHjx68/PLLPpXPyMhg4sSJjBw5ko0bN3Lbbbdx7bXXsmjRouPcUiGEEEIIIU4+v5PdACHqmzBhAhMmTPC5/KuvvkpKSgrPPvssAF26dOGXX37h+eefZ9y4ccermT6xV1nZ+9VTOIsOYohIpO05d+MXaDmpbRJCCCGEEH8u0kMnTmurVq1izJgxbtvGjRvHqlWrvD7GZrNRWlrq9q+l/fHmLRQ/0oN52bm8pUUzLzuX4kd68Mebt7T4cwkhhBBCiL8u6aETp7Xs7Gzi4uLctsXFxVFaWkplZSVms7nRYx5//HEefvjh49amP968hfdrzHw26jWKDJGu7W93vYiL0hdy+Zu30OmaF4/b8wshhBBCiL8O6aETfzn33XcfJSUlrn/79+9vsbrtVVbeq7HwRsepFGkRbvuKtHDe6DiV92os2KusLfacQgghhBDir0sCOnFai4+PJycnx21bTk4OoaGhHnvnAEwmE6GhoW7/WsrmD//N5x0Oz93TNPedmgFQzOswls0f/rvFnlMIIYQQQvx1SUAnTmtnnnkmS5Yscdu2ePFizjzzzJPSngWl1bXDLBsGc3U0A4WGKBaUVp/YhgkhhBBCiD8lCejEKaW8vJyNGzeyceNGoHZZgo0bN7Jv3z6gdrjk9OnTXeVvuOEG9uzZw913382OHTuYPXs2n3zyCbfffvvJaD5F5pAWLSeEEEIIIYQeSYoiTim//vorI0eOdP19xx13AHDllVcyZ84cDh065AruAFJSUvjmm2+4/fbbeeGFF2jVqhX/+9//TtqSBVFVvv1G4ms5AOVwYP31N+x5efjFxGDp2wfNaDzaJgohhBBCiD8RCejEKWXEiBEopbzunzNnjsfHbNiw4Ti2ynfJ+zQiuxZSqIUfnjPXgHISpYpJ3udlSGYDpd9/T85jj2PPznZt84uPJ+4f9xE6dmwLtVoIIYQQQpyuZMilEC2outrO/+3NAjRQTvedyglo3Lo3i+pqe5N1lX7/PVn/d5tbMAdgz8kh6/9uo/T771uu4UIIIYQQ4rQkAZ0QLehQMIzcHslDGVuIVMVu+6JUMQ9lbGHE9kgOBevXoxwOch57HJTCocGqjgEs6GtmVccAHChQipzHHkc5HD63zel0sH/r72xf8RP7t/6O0+n7Y4UQQgghxKlJhlwK0YJ69hrDb4sW0HXXAK7MXEV2awdVgX4EVtmJ32+ka00n1hcvo+e4ybr1WH/9DXt2Not6BfLhMIXB2BUDETgp4jXHVqb+rDFuQzbWX38jaED/JtuVvmYlS+e8RnlhgWtbcGQUo66aSYcBg475dQshhBBCiJNDAjohWtDYcwfxxLqv+CNgM6ARlgVh1C5RUKk5WRKwGUOk4t5z9YMoe14Oi3oF8smI/uQnTaUiKNy1L6iimE9GfAis5eq8HK911Elfs5KvnnsMp6ZxIDGFCksIQdYyWh3ay1fPPcY5d/xDgjohhBBCiNOUBHRCtCA/PwPGkEicdhs0zHuiAQqMoVH4+emPdi71y2H+sAHs6TCz0b4KSxh7OtzAfKfGhX45hOnU43Q6+P6NV/gjJY2lgydSHnykdHB5CaNWfMPiN14ltd8ADAbJnCmEEEIIcbqROXRCtKDMzExqHNU6C4tr1NhtZGZm6tazpHAP+1tf6npMwzoADrS6lCWFe3Tr2b9tK79HJ/DV2KmUB4W67SsPCuGrsVPZFB3P/m1bdesRQgghhBCnJgnohGhB5eXlLVJudaG1dpilTmBYHhzO6kKrbj0ZW/aybMQk12Pc6zAAip9GTCJjy16f2g1gd9pZtG8tb//xA4v2rcXubDpjpxBCCCGEOD5kyKUQLSg4uIn0lT6WszotPtXTVLlv8/MoiWvjvYBmoNgUyrf56Yzw4fk+2LWM/+xXFBABRAMQtXs5/2ytMa29LzUIIYQQQoiWJD10QrSg5ORkQkNDdcuEhoaSnJysWya2yrePZlPllLnEp3p8KffBrmXcsS+MAhXutr1AhXHHvjA+2LXMp+cSQgghhBAtRwI6IVqQwWBg/PjxumXGjx+PwaD/0etanU6kym+8OHkd5SRS5dO1Ol23nmhHke5+X8vZnXYe3X+4LV6Gbj663ynDL4UQQgghTjAJ6IRoYWlpaUyZMqVRT11oaChTpkwhLS2tyTqMRo3pvAVojYM65QRq9xuNXubYHdYxO8unwLBjdpZuPd/v/41CInXm9BkoJJLv9/+mW48QQgghhGhZModOiOMgLS2Nzp07k5mZSXl5OcHBwSQnJzfZM1en1J5EP+ZzG0/zLjMoPDxfDSCSQqbzFv1Yw3b7efr15DmZWv0BLwfcUhvUafWe/3BgOLX6A0rzvAR8h23KzQNaNdnuTbl5nK0/mlQIIYQQQrQgCeiEOE4MBgMpKSlH9+DqM6HqR/qa1tBHW8cO1YViIginiM5sR1NOsIXVltOxPWwMg1b9wP8Ne5r3tMaB4RXqLbquCmBl2Bjdevzs/j4129dyAA6lWF1cTm61ndgAPwaGB2P01gMohBBCCCE8koBOiFNQh2A7iTuu4GCPl0A5SdOOrBOnVO0a5Yk7rsAerD9nrSo1nPnbt3LRj104Y9Df2ROY7AoM21Vloq3swWfVWwntcpFuPaF2G7EV+eRaIt17+VyNchJnLSDUz+bT6/smr5j707M4ZKtxbUsw+fNohyQmxoT7VIcQQgghhJA5dEKcknrH2wnJ7Uvippvxt0W47fOviiRx082E5Pald7x+QLc/ZBXrulbxufM3gh6qodNXofT6RdHpq1CCHqrhc+dvrOtaxf6QVbr1VCxZzK2fzEFvTt8tn86hYsniJl/bN3nFXLtlr1swB5Btq+HaLXv5Jq+4yTqEEEIIIUQt6aET4hS0d0QKoVutBOX2pV1ubyoj/sBuKsHPFoa5qBMKAxXOSg6NSCFGp56EiHJ2VsDaTgbWdVB02b+BiHIoioTtNxpQBs1VTk/swWySTCX8n/I+dDM1IJ+sg9W69TiU4v70LJSHfYransd/pWcxPjpMhl8KIYQQQvhAAjohTkF5jhL2Ot5hoHYTSjNgKeri2ucENKX43fEmQY4rdevpG9uLnw4sBUAZNLYlew6S+sb20q0nWFmwnfMH/dhNXzzM6cOJbXIwwQsSdOtZXVzeqGeuPgUctNWwuricwREhunUJIYQQQggZcinEKSnGEsO/z9jGavvLUFXovrOykNX2l/n3GduIsej1z8Fwv7MJsoXjsUsMQEGQLZzhfmfr1mNpH4V/UAWaBgacpLGVQfxCGlsx4ETTwD+4HEv7KN16cquPDBE1KEWfQjvjDtXQp9COQSmP5ZrkdEDGctj8We3/Ox2+P1YIIYQQ4jQnPXRCnIJ6x/YmzhLHI2dsx8/+T67bnUJiVSgHA0t544wM7H4G4i3x9I7trVtPTbmTwXsv4PuObx0Z01jncPw0eO8F1PTSX7Ygw5hPex/anWHM190fG1B7yRmZU8Od223E2Y4EcTkmjWe6mPgxzt9VrknbvoKF90DpwSPbQhNh/JOQdo5vdQghhBBCnMakh06IU5DRYOTe/vcCYPczMLvTXu7v8TuzO+3F7lf7sb2n/z0YDUbdeoJCTbQr7MHYnTMIqg5331cdztidM2hX2IOgUJNuPSV233q9mirXP9TM2ZmlPLmxihibe7dhjE3x5MYqJmaW0j/U3PSTbfsKPpnuHswBlB6q3b7tK5/aLIQQQghxOpMeOiFOUWOSx/DciOd4Yu0T5FhzXNvjLHHc0/8exiTrrx0HkJAaQpBfEe0Ku9O2sDuHQndj9S/FUhNKQmkqBiDYr5CEVP35agdtFvpUhaJMpXjKVaIUUBXKQZtFt56srZu5a6cNDRNONH6NMJJv0oi2KXoVOTCg+PvOKrK2bqbtGTrz+pyO2p45vfQqC++FzhOhiaBXCCGEEOJ0JgGdEKewMcljGNl6JOtz15NnzSPGEkPv2N5N9szVMexfxdDg11lYfDcGFEmlHertrV1uYEjwGxj2x0HKUK/1RIS0Yc9ujZS0JbXr4NUL6uqmvmXs6UdESGvd9uz9fRvtnW1YGuvHM11M5AYeGSQQW+Xkzu02RuVq7Pp9m35Al7mycc+cGwWlWbXldF6XEEIIIcTpTgI6IU5xRoORfvH9ju7B5TmkBq5mfPhTLC+9hgrnkeUGgg0FDAl9i9TA1VCeo1MJhNstZJUmUrVtOKnt12EyWV37bDYLe3b3o6AgkQiLfg+ds7yUpbF+3N0zsNG+XJPG3T0DeWpjFa3KS5t8XXUUUBzmjy1Aw1StCC+pOTJVsInXJYQQQghxupOATog/s+A4AFIDV5NiWsuh6i5UOCMIMhSRELAdg+Z0K+eNsaZ2blxBQRsKCloRFpZLQEAl1dVmSkpiqZuOW1fOG/+yAp7pdni+XsOxm5oGSvFsZxMvbS3w6XXlRgWws30QNtORHkuTzUHHXRXEFlQ3+bqEEEIIIU53EtAJ8WeWPKg262PpIQyakyTT1gYFtNr9yYN0qwmosoIrZjJQUhLvvZyOH6v93IZZNqJp5Jg1fqz2Q3egZPIg9sdFsbNj4122AAOb00LouFOjdROvSwghhBDidCdZLoX4MzMYa1P4A+5rFtT7e/wTTSYO6ZtyJgGYdNezC8BE35QzdevZGxjRZJN9KVfjsLMpNbj2D089fcCm1CBqHM1Yz04IIYQQ4jQkAZ0Qf3Zp58CUdyE0wX17aGLtdh/Wa2t/RneGVnesjQEbBnWHk0oOre5I+zO669ZTavCQIvMoyv28+kPMfhWgaTgxsI2urGQI2+iKEwNoGma/Cn5e/aFPzyeEEEIIcbqSIZdC/BWknVObwj9zZW2ikOC42mGWPmbLLCnJJsUZy+jq7qzy34kVm2tfECYGVnckxRlLSUk2oSR6rSewoIgQq50ys7FxzxqAUoRUOggsKNJtT7H1EOH+sI4BvMsMCrUjyV4iVT7TeYt+rKHYesin1yeEEEIIcbqSgE6IvwqD8ahT+JebyjDay2lrjCHZGUO2oZhKbJgxEe8MR1NQ4SjFaXLq1tPe6mRXegZlZ7TH2/oHUekZtLfq1xNiTmCdfQCzuKvRvkIimcVd3MbT9DYneHi0EEIIIcSfhwy5FEI0KTgigvUFSwDQFCQ6I0h1xpPojEA7PARzQ8ESgiP0576FxtVQmm2k7e/pBFe6Z8QMrnTQ9vd0SrONhMbV6NZT3aojc7i29o9Gc+gMgGIO11LdykPWFCGEEEKIPxHpoRNCNCmpS1dKAgtZkTuf3lGjsfiFuvZZHWVsKFhCqbmQpC5ddeup0QIZ4L+fH7NT0Q4eoGtoLv4BippqjT2lsWQbLIz0302N1niduvpWl1ZTrEV6L6AZKCaS1aXFTGrWKxVCCCGEOL1IQCeEaJLBYGTUVdfz1XOPcdCaTnRgK8zGYCod5eRXHUChOOeGf2BoYk5eoLWGZKOVc8tWEpm7i2DHkWUOyo0WCmPbExEYQKDVX7ceW64T9IscKSeEEEII8ScmQy6FED7pMGAQ59zxD4Iio8ir2s++iu3kVe0nOCqKc+74Bx0GNL3mm9E/AL/SIlof+p0gh/uadUEOK60P/Y5faRFG/wDdelrt9bZ+wtGVE0IIIYQ4XUkPnRDCZx0GDCK13wCytm+lvLiI4PAIkrp0bbJnrk6r5DJs2zLrVjpwU7cigjknk1a9w3TriSu0E1vlJNekec2WGVeliCuUdeiEEEII8ecmAZ0QolkMBiOtu55xVI+Nqa5kt93eKJirowHY7cRUV+rWkxUWzJ3bbdzdM9Brtsy/77CRFRZ8VO0UQgghhDhdyJBLIcQJEx7ezvXfCrBbQqgJjcRuCXFbr7x+OU92lxfQLbeaJzdWEmtzH1YZV6V4cmMlXXOr2V1e4HPbnE4nGRkZbN68mYyMDJzOP8f8O4dSrCgq44ucIlYUleFQMgxVCCGE+DORHjohxAkT2vFM4BtqQsKxxbVB1Zsrp9VUY8rZh39Z8eFy3lmrq/moKpNbctoyPKecjZF+5Js0om2KnoV2jMCLtkys1Raf2rVt2za+XbiQP7QArAEmLNU2Oqlqzh4/nrS0tGN4xSfXN3nF3J+exSHbkWUgEkz+PNohiYkx4SevYUIIIYRoMdJDJ4Q4YZLSumOMjacqKRXl556mUvn5U5WUil9sPElp3XXriQ0yYcn9hhW586l2lNG3yMH4bDt9ixzYHGWsyJ2PJfdbYoNMTbZp27ZtPLF0Oa91GsA+SySqopp9lkhe6zSAJ5YuZ9u2bcf0mk+Wb/KKuXbLXrdgDiDbVsO1W/byTV7xyWmYEEIIIVqU9NAJIU4gjeqkVKis8rAguAZKYUtKpXHKFHfjEovY6Kggy7rT6zIKIcDQxCLdepxOJ/9d9RuVNnjj0bsIjy7AEaYwlmgU50fx8kVX8t9VvzG7c2cMBt9+/3I4FWszCsktqyI2JJD+KZEYDfqvp6U5lOL+9Cw8Da6sS0jzr/QsxkeHYfSUVEYIIYQQpw0J6IQQJ0xmZibWKpvnzJQAmoa1ykZmZiYpKSle6ymr2eL6b4Uir2p/k+U82bN3L+X5Jdy74UVK77RTEHFkn6Eoh3s/fY7ne93Mnr17ad9Of14fwMIth3jkq820Lt9ELMXkEs7+4B7865zujO+W0OTjW8rq4vJGPXP1KeCgrYbVxeUMjgg5Ye0SQgghRMuTgE4IccKUlZW1SLmqHb4tR9BUuZUFxVyz822Kr2tczhkOxdfZueaDOawsGEz7JuK5hVsOMf+DV/nU/10SAwpd2w/aIvn3B9Nh2g0nLKjLrfbt+PhaTgghhBCnLplDJ4Q4YUxlvg3va6pcQYADtCaWJNBCasvpKN2yGs4uPly+4eMP//+E4tpyOhxOxbL5bzHbfxbxFLrti6eQ2f6zWDb/LRzOE5NhMjbAt9/qfC0nhBBCiFOXBHRCiBMmyRJDkDLhcXIXgIIgZSLJEqNbT3VwOf6Wkbpl/C0jqA4u1y0TUfUbzgi8T9nTwBlZW07P2t153FrzPwAaTper+/vWmjdZuztPt56WMjA8mDg/BygvSy8oJ/F+DgaGyzp9QgghxOlOAjohxAnjFxrIwJqOtX80DOoO/z2wpiN+oYG69SREOqgMjsYvaFLjnjotBL+gSViDo0mI1O+hiwj2Ps+sOeUce1eQqBU2CubqGDRI1Apw7F3h0/MdKwNOruBNQGsc1CknoHE5b2Hgz7HWnhBCCPFXJuNthBAnjCkljPYhraAMVvvvpAKba18QJgbWdKR9SGtMKWG69Yyq7sitKfMY8scMDP6pKPtBUBWgBaH5JaJpBjalvMWM6q669dhihmCi6SDLFjNEd38s+tk0m1vuWBUXr6NXzSJuo5j3nDMILggjuNJJudlAeVQJVxjeolfNGoqL1xERMfCEtEkIIYQQx4cEdEKIE0YzaIRPTiXl/WqSbTFkG4qpxIYZE/HOcAxohE9uh9ZEmv9SewSpjki+7/gmg/deSLDW2rWvLKCIlW0/p7sjilJ7BLE69WTsCqBHaw2Cledhlwoo18jYH+Bh5xFBliO9hAooDvPHFqBhqlaEl9S4qq5f7niy2XIB6Hygmls3FGOvPDIYw89cTFyvamh1pJwQQgghTl8S0AkhTihzt2iiLu9C8YLdJJYcWSfAGGYifHI7zN2im6yjOqkjid92gvZf8HXfh7EUp2KpCcXqX0pl2G6G5g0ncdf5VJ+tn4SksjCL9vYKdnW3oJT7agrqcIyXmmFldWmWbj0Fwe0xq1BqoqtIbx+EzWR07TPZHHTYVYFffiAFwe1JavLVHTuTKZayA73IWnljo332ynCyVt5I0qBXMPXSC3eFEEIIcTqQgE4IccKZu0UTmBaFLaMEZ1k1hpAATClhTfbM1VkVkAPEk7jrfKbsnkxR65+pDMzDXN6aiO03YlB+rnJpOvV0itiPPesM9hV1Jb7PtwTUmytXUxFA9m8TaGvbSqckz+vc1akqKOCn6G6Epv3RaJ8twMCWtBBKt3UiqaDAp9d3rEJD+5K78bLDfzU8pgZAkbtxGqGX9T0h7RFCCCHE8SMBnRDipNAMGoGp4Uf12F2OXwkPGExQdTgG5UfUvlFu+xWK8oBiDjh+BaZ5raeX08APeWMoL/+Jwj/aE9M+DP9gRU25Rt6uElA7WRI8htEJGbrtsRSn49d+Lwqt8ZrpmoZSYGyfiaU4HTjrqF5zc2TvKqPGqjcPUaPGGk72rjKSOkXolDt1OZ2KQ+nFVJTaCAo1kdAhHIOPPwgIIYQQfyYS0AkhTjtRzmB+bjuPsTtnoJSDiOLdmKpLsQWEUhSeCpqBlW3nMcyZqlvPwf1JlFf8RmhUGgXRYSyPCMMaYMJispFqKCEqv4TSwvUc3N8NvZqMpgwspmqv+zUNgkw2jE79wLClVJTami7UjHKnmt0bcln+cToVxfWS6oSbGHpJB1JlGKkQQoi/GAnohBCnnQmVnXk34guy/J/l4p8LMNtKXfsqTaF8OiyKvRH7ebxyom496bZAQiPbsLxLKivan0FFoNm1L6iqksG7fmfo9tpyQ3XqyY+0Q2XT7c6PtDdd6DCn00lmZibl5eUEBweTnJyMweDbSjNBoaYWLXcq2b0hl4WvbWm0vaLYxsLXtjB+ZjcJ6oQQQvylSEAnhDjtJAaGcPG3AVy4unGPl8lWyhWLS7GUWUi8IES3HmuInU3xnfi+a+9G+ypMgXzftT8m5UeP7Hzdev6wx5By+L+dGNhBF4qJIJwiOrPdtd7bH/YY3cCwzrZt2/hu4XeUlZa5toWEhjBh/ATS0vRmBdZK6BCOZq7BWemH5iF9p0JhMNtJ6BDuQ2tOHU6nYvnH6bplfvkknZQeMTL8UgghxF+GBHRCiNOOf0wM56+p7RLznPIDzl9Tif/MGN16LMF2lnY4HCA1nPymaaAUSzt04czyH3XrKSjsQLhZI93Yn/e0GRRqRzJ1Rqp8rlBv0cGxloKyDk2+tm3btvHJJ5+gamfkubaXlpbyySefMGXKlCaDOoezhqyIFSRWjvC4X0MjK2IFDudIDAb9JRlOJYfSi92GWXpSXmTjUHrxaTs3UAghhGgu38bvCCHEKUVhVMrj0nFQG+QZlaI2tPNud0R47TDLRplM6irSqAi0sDsiXLeeotIEXi0fyQvaXRQS5bavkEhe0O7i1fKRFJUm6NbjdDqZ//X8RsFc7WvSUCjmfzMfp9OpW8/3a+dxUXVf+loMBDZ4aWYN+loMXFjdh+/XztOt53hwOBWrdhfw5cYsVu0uwOHUf4/q+7PPDRRCCCGOhvTQCSFOO46CwhYpl+Pv2yWwqXLV4UbS/a6t/aNRT58BlCLdfC1n+OsHYhl7M6i2VnscJgm1QV11RTUZezNIbec9TUtVZikx9iQIgAR/yA/7A7upGD9bONElnTBoRrBHkpG5HQbpNqlFLdxyiIe+3Iwxdy8WhxWr0YIjti0Pndud8d30g11oMOdPc2KJTscYWIyjKhxrfgdQhsblhBBCiD85CeiEEKcdvxj9oZS+lrNoOT7V01S5YrMTm9HsvYCmYQs0Ueyo0K1nc9Zmn9qzOWuzbkAXb6xNClIW+yu5nediDyxy7SuriiB2x2WE5PZ1lTsRFm45xNOvfcb4gl8IqXccyvKCeDp7CMy8qMmgLqFDOEHhJrSgVcT1+gh/y5HXVWONIGfDpWA9s1lzAx1Ksbq4nNxqO7EBfgwMD8borcdWCCGEOAVJQCeEOO1Y+vbBLz4ee04OKA9D9jQNv7g4LH376NbTqTQDc5WNSlOA52GXSmG22ehUqr/cQFyxnQYjLb2X02HVrE1X4kO5nvHh7Iv9lYM9Xmq0z24q4mCPl0jcdDM943v59HzHyuFUvP7WZ0zIXdRoX7Cjggm5i3jjLTjrmZsx6iQzMRg0ep+fRW75K432+ZmLSBr0CrHBbXxOiPJNXjH3p2dxyHZkQfkEkz+PdkhiYky4T3XUcTgVazMKyS2rIjYkkP4pkbqvRQghhGgpModOCHHa0YxG4v5x3+E/PCQzAeL+cR+a0ahbT1unwrTrcO9bw8Dw8N+Bu3Jp28Q8L0uub+vLNVWusCYfq9GK8jL3T6GwGq0U1uhn3TQFZZPT+f3aPxotdF77fzmd5mIKyval2cCxzX1bk57DGdm/6DWH7tkrWJOu3xOqlINS+wu1j/P8tlNq/y9KOZps0zd5xVy7Za9bMAeQbavh2i17+SavuMk66izccoghTy5l6hur+b+PNjL1jdUMeXIpC7cc8rkOIYQQ4mhJQCeEOC2Fjh1L0guz8IuLc9vuFxdH0guzCB07tsk6KkIncV3Y2/hvLECzuQcBWpUD/40FXBv2NhWhk3TraVu6hRCrw3NvIYBShFY4aFvaeP20+py5BWyK2lT7kAZBXd3fm6I24cwt0K3nQOFOHIHFjaOnOho4zEUcKNypW0+dYw1Ydi35gRBHhW4SmxBHObuW/KBbT3HxOmy2bDStdnmIbXRlJUPYRlecGNA0sNkOUVy8Trceh1Lcn57lMWyu2/av9Cwc3t7PehZuOcSN76/nUEmV2/bskipufH+9BHVCCCGOOxlyKYQ4bYWOHUvI6NFYf/0Ne14efjExWPr2abJnrk7suWPYuvJnbvF7mQ9WX0iBJQ5MRrA5iLbmMLXT55RaWhM7aIxuPcagQiZuyuWjgfG1QV397qPDQcHZv+diDNFP0hJFEQeDDrI6djU9CnpgcVhc+yqNlWyK2sTBoINEUaRTC+yvKQMfDsH+mjLaNlGmLmBBQWu7gSClUaEpsoprA5ZXLu/d5Ny3wNK8phvjQ7nKqlwA1jGA99TVmErBUm3DGmDCFgpXaG/TjzVUVuWit2jB6uLyRj1z9SngoK2G1cXlDI7wvpahw6l4eME2r4GhBjy8YBtnpcXL8EshhBDHjQR0QojTmmY0EjSg/1E9tkgpXgubwUze4vkBD7HNmkqJLZQwUylplt0sqz6b18Jm0LOJnhotcRgTX3sHu+MmFvWyUBZ0JJoKtToZu8HKxOXvkD9zvG49fWIS8N9jIctykEOWLHprIUQYDBQ5naxXZTjRMNVY6NNaP4Aqs/vhS57HMrv+V0BdwNK+2sDoSn9C1JFBHWWak6XmGp8ClviYYPb70J74mGDd/XsKA1nHAL7Mv4wJu34juPpIr1h5QCBftr8MosFUGEiiziHKrdafy+hrubUZhY165upTwKGSKtZmFHJmqg+TLIUQQoijIAGdEOIvKzag9hL4WtgM/qeu4Hz71yT4ZbPdkMZjgY/iMPu7lfOm5/ZC2LeJMT+9QNutRvYnxFJhCSHIWkbrQ7m0z3fQ6sBWWm3XDzx3/l5IVcVkerafywURNUT4Vbr2TbJrzCvyZ+OuyewsL6TzKO/1HKw20L4yDEdgiedhlwqMleEcrNYfdb82o5DgvGrOtQaglBOHfT+oCtCCCPJL5BxrAF/mVTcZsIT17I1z6bdo9hpvzUH5+RPWs7due/Jsnfgh7zzGbl/HkT6wWkHVlYzdto4fupxLp/BOuvU09X76Wi63zHswdzTlhBBCiKMhAZ0Q4i9rYHgwCSZ/sm01ODR/Pgs5322/Rm3Ww4Hh+j1H+4t34h8WxO7ISjQntDlYb3kCpdgdCWFlQdQU76SLTj0rs0PoHGtgRnR1o33hRsWM6GpmZxlYmR3COTr1tN5XRER6LPkXlTSMe1yTxCK+iaF1B/2hmzkllYyrDMBRnY7dugxU+ZGdWjB+lhGM1TqQU1LptQ4A/+wcbHFtCMza7a052OLa4J+tnxQlL8BAz107QGfh9Z67d5LXVX9xvfrvu6e+V1/f99iQQN39zS0nhBBCHA1JiiKE+MsyahqPdkgCvGdffKRDUpPrklW0srAtMfrwAz2nX9yWGEVFKwt6io0hTO38uV41XNrpc4qN3ud1AcT4mSlcn0/JT30xVoW77TNWhVPyU18K1+cT46ezdh5gLrYTYNuFveJr92AOQJVjr/gak20X5iaWY6g4VIK/n4mqpHYoP3/3avz8qUpqh78xgIpDJbr1BNgKCK5x6i68HlztIMCmnzSmpd73/imRJIQF6iZ7SQirXcJACCGEOF4koBNC/KVNjAnnf93aEm9yDzQSTP78r1tbn9Yjs/ToR1WAn+e17AA0jaoAfyw9+unWk9o3ksjAYr1qiDIXk9pXP0BICurCtsRoMnaUs/69BPIW9qX8l37kLezL+vcSyNhRzrbEKJKC9PoLIajIRo31R90yNdZlBBXZdMsUmUPovX499pAIrCld8Q+JJSggBP+QWKwpXbGHRNB7wwaKzPqBamn+H7r7m1Ou7n2PC/DDUGjDcMiKodBGfICfz++70aDx4OQ0wHtg+ODkNEmIIoQQ4riSIZdCiL+8iTHhjI8OY3VxObnVdmID/BgYHtxkD02dVoZY9BckOFJOz/mtNDLLav/biYEddKGYCMIpojPbMeB0ldOTV1NdG2BSm2QzK7PCvcDhADOvppo4D4+vsy/r18Y9cw2pstpyeJ+3pqWFYMovZ9QPPxBcYcVcdWROWWVgIOVBFpTVSXWafkBXXKY/RLS55Yw5lQT+nENAvcQmprByjGFR4OPC4uO7JfDK5b15eME2twQp8WGBPDg5rckMoEIIIcSxkoBOnHJefvllnn76abKzs+nRowcvvvgi/ft7TiZRU1PD448/zjvvvENWVhadOnXiySefZPx4/WyCQjRk1DTdFPV6/HJ9S8vfVLnKzaugbW1a/neZQaEW7doXqfKZzlu1afk3r4J+073Ws/vAPp/as/vAPrrp7LcF+Pa6miqXFlfC3LZdmLRjdaN9gVVVBFZV8XXngVwWpz/ksjQ/B4PRitlh9jjsUqGoNFbizNefiwdHlmNoOIcup8T35RjqjO+WwFlp8azNKCS3rIrYkNphltIzJ4QQ4kSQIZfilPLxxx9zxx138OCDD7J+/Xp69OjBuHHjyM3N9Vj+/vvv57XXXuPFF19k27Zt3HDDDZx//vls2LDhBLdc/JWV2w5hMlWDxxQbAAqTqZpym/4i04W7FCurBjGLuyjEPWtkIZHM4i5WVg2icJf+MgplRv3AyNdy9kqrT/U0Vc4cEM2IrNrFvr0NTRxxcB3mgGj0xBysIt9Qiqa0xodagaY08g2lxBzUzyrZ1PpxULt+nMPZ9MLidQzKyRn5uxlxYCNn5O/GoJw+P1YIIYQ4FhLQiVPKc889x3XXXcfVV19NWloar776KhaLhbfeestj+ffee49//OMfnH322bRr144bb7yRs88+m2efffYEt1z8lRWHZjEiNhPQPMUZgMaI2EyKQ7N067FWh/CeNqP2j0ZZUQyA4n1mYK3W70k0mqsJ9rOhF2CG+FVhNDfOplmfJTAKp58/CnBqUJlsprKrmcpkM87DMZXTzx9LoP4aa37pipAyBxrg0DQ2dujCkr6D2NihCw6ttq8tpNSBX7p+ABVtDuCMAxMIKe6CwRngts/gNBFS3IXuB8YTbQ7wUkOt5qwf54vS779n1+gx7LvySg7eeSf7rrySXaPHUPr99z49/nhwKMWKojK+yCliRVEZjibWUhRCCHH6kiGX4pRRXV3Nb7/9xn333efaZjAYGDNmDKtWrfL4GJvNRmCge0pws9nML7/84vV5bDYbNtuRJA6lpaXH2HLxVxcbUk16m0nM79yLUSu/JbTiyDlVFhTG0kETaGfdQPsQ/QBqS0wapYER3gtoBkrMEWyJSWOCTj35AZGMj/uRr7K64G3dgpFxe1gY0Eu3PRGxsWTEtUEFH6TLgF1EmI+8rqLKULavaY9WnkhErP7cwPRd67AAP/fsx0tTriQv4kgAGFNUwM2fvMOwjetI37WOPmcO9lpPQlh/qpQZf1sIprxoagJKcBqqMTgD8K8Ocw3DTAjTX++vJdePK/3+e7L+77bayYr12HNyare/MIvQsWN9er6W8k1eMfenZ3HIVuPalmDy59EOST4lexFCCHF6kYBOnDLy8/NxOBzExbmnaYiLi2PHjh0eHzNu3Diee+45hg0bRmpqKkuWLGHevHk4HA6vz/P444/z8MMPt2jbxV9baHEsD7YfT26gkV0pabQ6tJcgaxkVlhAOJLRFaRoPVXXmq+KFuvXkRxwE9IOsI+W82xbYmwtDPmNS0naW5aRSbje59oX42Rget4egkNpyesZMnsi6zO8Z3GN9o6GSEYGlnDl8PSs2RjNm8kTderbYDlLVsx8PXn97o3154RE8eP3tPPz68wTaDtJHp57AgEigds07pWkcDIum3GwguNJJm3w7mqpfzrv668IZgB4YiUKjAMUmHDg9lPNEORzkPPZ4o2CudqcCTSPnsccJGT0azWjUraulfJNXzLVb9jbqm8221XDtlr0+Z/AUQghx+pCATpzWXnjhBa677jo6d+6MpmmkpqZy9dVXex2iCXDfffdxxx13uP4uLS2ldevWJ6K54k/qN3t/csNrL6caEGtuQ7RBkW/SyNI0lKaRY/bjt4r+JOvU09aon/7f13KR8W14+MB0XgmZRWpwAYcqwyi3BxDsV02CuQSDBjfW3EZ0fBvdegxGA706/oQGOLUGWTe17RiUk14df8Jg1B+9n9M2iXenjKv9w9NQUuXkxSlXMj20iVyh5tpQa3uSP4t6WyizHAmSQqwOxq230iWrxlXOm7r14zqW2Pk/AomtN/sgFycvUMXOML8m14+z/vob9uxs7wWUwp6djfXX3wgaoN9r2BIcSnF/epbXuYEa8K/0LMZHh/mcwVUIIcSpTwI6ccqIjo7GaDSSk+OeoS4nJ4f4+HiPj4mJiWH+/PlUVVVRUFBAYmIi9957L+3atfP6PCaTCZPJ5HW/EM2VpWrntI3MqeHO7TbibEduqXNMGs90MfFjnL+rnDf9/UNJqMrlkCnG85p2SpFoy6W/f6huPRO6d+DytcXcWHMbD/q/S+ugI3PBDqooHq65gkXO/rzfvYNuPSu3fEeQxeY966b2Fv2C1rByy3cM6zHZaz3WknjyI3Xm2WkG8iOisBZ6/pzXqQkysLW1xrwzgxvtKzMb+GxwMBesKqJ9kH6AaTRoPNujDa1/PoQTJ9aI7dhNJfjZwogq6sijmNnfI6HJLJX2PN+ygPpa7litLi53G2bZkAIO2mpYXVx+1BldhRBCnHokKYo4ZQQEBNCnTx+WLFni2uZ0OlmyZAlnnnmm7mMDAwNJSkrCbrfz+eefc+655x7v5grhEmN2MDKnhic3VhFjc+8fibEpntxYxcicGmLM3ocCA9jbnMPDu+agAVqDLImacqIBD+16B3ubc3TrOTM1BrO/YqGzP0Ns/+XS6vu5tfpmLq2+nyG2F1jo7I/ZX3FmaoxuPdkbPmYdA3Szbq5jANkbPtatB01/6KKv5QIIY3Evy+GyDXv6av9e3CuIAMJ061FORcqmQspif2PvkL+TE/YUxbbXyQl7ir1D/k5Z7G+kbCpCNZHl0hCjn5WzueWOVW61vUXLCSGEOD1IQCdOKXfccQdvvPEG77zzDtu3b+fGG2+koqKCq6++GoDp06e7JU1Zs2YN8+bNY8+ePSxfvpzx48fjdDq5++67T9ZLEH9BA1sHcfe22gQaDS+qdX/ftb2Kga2DdOv52eKH0daD//78CNEl7hkWY4oL+e/Pj2C09eBni/7gCqfTSW8y0VA4MbDamcZXzkGsdqbhxICGojeZOJ36QxO1Yivvop91811moBXrL1vQOlS/R9HXcpkRJsrMJs+9l4fbWGY2kRmh3wNvyyih2LSSIvUyUY9WED3Ln4i3/Yie5U/UoxUUqZcpNq3AlqG/rMOmtqmUWyw6uUSh3GJhU9tU3XpaSmyAb4NufC0nhBDi9CBXdXFKueSSS8jLy+OBBx4gOzubnj17snDhQleilH379mEwHLllrqqq4v7772fPnj0EBwdz9tln89577xEeHn6SXoH4K4q1tMavervX/QYg1gaRFv25mjUmI3MJ5/6PtvPhx7ewuX0XCsIiiCopovuu7RgUPHrtOLqZ9BNsfL9mCwEc7oU5nJzDRSnQIAA736/ZwsTBPbzWkxl2ptswy0Y0A4VEkxmm34N++fDBPLp4JZWBoYcDwQaUE3NlCZeP9Z7hEsCSGgrpZbplXOV0OEorKal+h4g5fihNYeugcIQpjCUa/rsg4g0/Sq58F0fppUC413q27V5H0cA2TF66AyfuwbyT2jlrSwe2IWL3OobE6eUlbRkDw4NJMPmTbavxGGRq1Ga7HBjeeMiqEEKI05cEdOKUc/PNN3PzzTd73Lds2TK3v4cPH862bdtOQKuE8M72e7rP5SwdvQdIpX5OZn72LgBGBT3T3YNEJ3D95++xcIJ+GvzswiLW1BwOHj0OTVSsqWnNkMIi3XqqE9N09/tazs9opGv1+/waeBMop3tQp2pDn641H+BnHKZbj/+OTDA2/bXlvyMTWnkfTlpq+J3g+VVU9nRSerEDZ72VIgxFEPqpkaCvKik9+3eCSPD+PBX5fN4ni51hBq76wUl0vVizMATmjDGwuX0WN1bkN9nmlmDUNB7tkMS1W/ZS+y4fUXcWPNIhSRKiCCHEn4wEdEIIcYycVSWA/nDKI+W8i9++ldjiuqGWGsboDmimMJStBEd+OgYUcUUFxG/fCl1TvNZT6jRjRW/YoYYVE6VOs257OlWWQECSbhlXOR2/5fzKVZZlDFZW3tNmUEi95CoUcoV6iw6WtfyW8yv9EwZ4rSflj9XEthtErknzmjQmrkqRkrEaxvT1Wk/Bph+pbqsovq7xnEZnOBRf5yDiDY2CTT+S0GOc13oCLUVU+lWytrOBdR01uuxXRJRDUTBsb62hDBpQSaBFP3BuSRNjwvlft7Ye16F7RNahE0KIPyUJ6IQQ4hiZ2kdQsS4bLTACzUOgoZRCVRZhaq+fxbHN4QXJ/RJ6YTrjEgzmI2nznZWF2H7/GPuhDa5y3iS3SgRqe4U0nHSM2E2YqZQSWyg7i1JRhwcH1pbzbnSghfiqYrJNYV4DqARbCaMDLbr1FBSuJsJP0Z819GUdO1S95Q/YjkFzgl9tOXQCuvKcHO602bi7Z6DnoaTA33fYKC/O8VLD4XrSc6i8+PCQ1IYv63DXVslFdsyb9OsJiUuBXXWP0ygMDqTS30ilyQGazb3cCTQxJpzx0WGsLi4nt9pObIAfA8ODpWdOCCH+pCSgE0KIYxTUry8HHr+BoM5XoJRyC+rU4UDDmvk1rfu9qlvP6E7tyE3oRWD/Gxrt0wIjCOx/A1VrX2V0J+/LcgDEhdX2vPWO3cSlnT7HaDNRXW0mIKASh8nGR39cyPrcHq5y3iwzJnLHlmLu7oHXAOr2HdUs65bIeTr1hBkdh5cDBwNO0tjqtZwep72GM7MKeZIInu0SSG7gkfbEVSnu2FHFwKxCsk3eU/cDOEyVbsMsG9HAGVlbTk+cpXZYZ5tsMwO2RRJUdeQrtSLQzpq0QvbFV7rKnUhGTZOlCYQQ4i9CAjohhDhGTg3e6LWNmT+9SuAZl6DV61lTlUVUbf6YN4bv4ykN9NKZhPTpS3GPqQCNevo0TUMpRUCPqYT08T6csPZJa4O5KUnfs2vTKKqrjwwHDQioYErq94fLee8NA6gqr2FUjpmnNlbxTBdTowDq7ztsjMo180tb/QCqo8PMJv0Wu8rpiawJpmjHZ4zyu5rhOeVsjPQj36QRbVP0LLRjBA7t+JzINP2skhFJikM+tCciSX/Zgl7WSs7IMtFrU+OAzVJlZOT6GDb2yKGXVT8wFEIIIY6FBHRCCHGM1ueu5/uUUoqrN3HV4o3EmY7MfcuxpTPnLI21KQYuzV1Pv/h+XuuxZZZhDAz3ul/TNIyB4dgyyzC3997FlF9uZWLsCnZsH95oX3W1hR3bh3N26gryyy/XfV0Jygg4Sck/yGWrd7IrPARrgAlLtY32xWWk1HQEYg+X885UWoiqdoK/wdvITah2YiotbLyznsLWAcQsWM0hIKLzRfQtOpLN0movpXjH54TsXk3euC669URFxfoU0EVFxerut21czYBtkVQDWoOxmxoaCkX/bRHYNq7Gr/1IH55RCCGEaD4J6IQQ4hjlWfMAWNvJwLr2ij77SwirslESWMVvrQ0oo+ZWzpuC9GKfnq8gvZhWOgFdpP92tu6ryzzpeZJY3oE0OvXaDrTxWk+sLZMMgx9L/DcDkFRyZF5YJbDEfzOja7oTa7MDA73WUxPgR0R6MEVpVm8jN4nYFUzNIP2vpDyTHzFAyO7V1OxeQ0mrrjgtERisRVgObCXkcF7HPJN+PVFdzse0awG2AIPXuYEmm5OoLufr1rN9Zzk1NQGNjnAdDY2aGhPbd5bTRJ9qi3M6nWRmZlJeXk5wcDDJycluS74IIYT485CATgghjlHM4TlSiRWJ9CjogUVZwAThCmKyrGyK2sTBoIOuct5UKUWgD89XpfSHApqqct2GWTamYbMFYarK1a1nZ0UOf/hV1D2kYRWgYJXfTjpVBKHXJ+ZoNYhlBbkEbCsktf2vmExHFiK32Szs2d2X6oJI2rQapNueykgLeYFhRFeVoKEIOrDFbb8C8szhVEbqJ2lZE9mb6AwjWZ2U17mB0XuNrBnQG72V8fZZjzyPU9M4kNCWCksIQdYyWh3ai+FwXfuslhMa0G3bto2FCxdSWnokeU5oaCjjx48nLc23pSiEEEKcPiSgE0KIY9Q7tjdp9jQ653ZutM/sMDMwdyA7Wu+gd2xv3XoCU8KpXHaAQK3xHDqoTbBSqcCSEq5bz4Fi/WUE6pfrr7O/SPljNdi8F9DAqtkoUvrtydgRQhkhUBBCQUFrwsJyCQiopLraTElJLHVLcmfsCCEmzns9cRWl/NajE+PXrDnSABeFBqw/oyPdmsgCerCymndzpvNvx0ukpwZhCzwyZNRkc9JhdwUPFNzMmMpq3XoC46MgHXampLFk8ETKg8Nc+4LLSxi94hs6ZmyrLXeCbNu2jU8++aTR9tLSUj755BOmTJkiQZ0QQvzJyPgLIYQ4RhoaPQp6uP674T6AHoU9Gu1rKLFTBDsPD4tTDXrh6v7eZTCQ2EkvRSNU++vv97WcyT9Sd7+v5YqL6q24jYGSknjy8lIoKYmn/teQe7nGCqrLubLtUhIHF+Fndrrt87M4SBxcxPS2SymoLtet58CaX1hk68sDh/5GyhqN3ptK6Lq9lN6bSkhZY+CBQ39jUVVfDqz5Rbee1r1C2ZmSxpdjp1IeFOq2rzwolC/HTmVnShqte4V6qaFlOZ1OFi5cqFtm4cKFOJ1O3TJCCCFOL9JDJ4QQxygzM5Nqa7XXgE1Do7qimszMTFJSvK9JZjBodL6kI+ve2kp3sxFzveoqFWypdNBjRmcMBv3AsMveavbWVFDlb6HxWEkARWCNlS57q6Fx3hSXrgFO/tB9piPl9ISE6Q+B9LVcbJiVyIOl0BpCk6qw5gVgrzLiF+jAElONZgCoIjbMqltPcH4W0I5Fzv4stvWlf94OYikml3DWOjvjPBxk1pbzLqy1iaWDJ9b+0bBHVdNAKX4cfDb/bF2gW09LyczMdBtm6UlpaWmT56EQQojTiwR0QghxjMrL9XuEmlMutVcszIDlH+8ksLyGQA2qFNiC/Rkyo3Pt/ibElwXQZ80GVgweDJqi4dBEFPRZs4H4hJ669SSnpMD2bWDwnjwEp7O2nI799vkYHGachmpv8SUGZwD77fM5kz5e6wkqPxKoaQYIivM8JLJ+OY/tMR4ZRurEwGqn5yGI9ct5smXzPsqCdZZI0DRKg8PZsnkDbbznnnHjUOqoFwRvyfNQCCHE6UMCOiGEOEbBwcEtWi61VywpPWI4lF5MRamNoFATCR3Cm+yZqxOQlECrA1kMXrGC9b17U2k50vNlrrDSe8MGWh3IIiApQbeegugoTDn7sSUke00eYsrZT0F0FGFe6gCoXFNEcGl3SsO31WYuaRBfAgSXtqdyzc9wlvd6NOXbXLSmymlto9D2lqDsoXiLMDW/ErS2+vUczHfoJQl1L+eDb/KKuT89i0O2I+v6JZj8ebRDEhNjwpt8fHCQbz2hvpYTQghxepCATgghjlFycjKhoaG6w91CQ0NJTk72uU6Fk4Nhu8jzzyPGEkM8vdFflvyIsEnDyHkkglYHskjMOkh+TDSVgWbMVZVE5+VjUArNEknYpGG69WRu3UxAST6a044trg3KP8C1T7NXY8rZj39ZMZlbN9OuQwev9QSWRmOyRRNanEZ56C6cxiM9awanieDSVEy2aAJLo3XbYwweTI56nxgK8RTbOhXkEoUxWC83JRj8bZjiFlGVdTneIkxT3AIM/iN06wn2cRq6L+W+ySvm2i17aZi/NNtWw7Vb9vK/bm2bDOqSVRahlFFKMN4C1VDKSFZZgP7i60IIIU4fEtAJIcQxMhgMjB8/3mN2wTrjx4/3eR2wHzJ/4Im1T5BjzXFti7PEcW//exmTPKbp9vj7Ef23v5P3zP0o4GBYNAVhEUSVFBGVlw9A9N/uwOCv/xVQtGM9AP5lxfiVFeOwhKD8/NHsNRitZa6QobbcBV7rSUzoQ34ptHXG0NUWR4lfCZXYMGMizB7GVqeTQygSE7wPtwQoCWvH6zXTecV/Fk6FW1DnPBwJPVhzBZeEtdOtJzg8Gv/QrcD72HImo+zhrn2aXwmmuAX4h24lOPwi3XoCIkIx2AtwGiO9Dkk1OAoJiNBPiuJQivvTsxoFc3Ak3PxXehbjo8N0h18arLmMZxmfMAlvgep4fsJg1V8eQgghxOlFAjohhGgBaWlpTJky5ZjX//oh8wfuWHYHqsHtfa41lzuW3cFzI57zKaiLvvZCFgcF8VigibzwI9ksY4qL+EeVjalTxzdZR4R/FhmH/1sD/Kyes1BG+OsnD9nfNpBW+6309q8NbIKcR9qjNEU/i5H1NaXsb6u/Cl+hQWORsz831tzGg/7vkkiha182UTxccwWLnP05q4mhqdrhrJzJxiK6B2yiTIujEn/M1BDin8NmYxEH65XzKthC66xvyEy6wuuQ1NbZ30CS/ip0q4vL3YZZNqSAg7YaVheXMzgiRKc9caSxiyl8zUJGUMqRsqGUMZ6fSGMXBOusDSGEEOK0IwGdEEK0kLS0NDp37kxmZibl5eUEBweTnJzsc8+cw+ngibVPNArmABQKDY0n1z7JyNYjMRr0h19+k1fMHfHxjWrKD4/gDiA0r7jJIXwRbSOp2FKJxVruLZcJFZZgItrqBz6hNdtJs7SHmsbr62mahlKKbhYD22u2ozeJLik1An7kSHZKg+fslEmp+ssx9IvtyXeVHRmY2w2AYOORQFU5a9cNXBm/hX6xPXXriQqKYvhePw6VrGVl6hlUBJpd+4JslQzavZmEIj+iOurPxcuttuvu97lc8iAITSStdDedVAa7nIMp0yIIUUW0N6zAqDkhNKm2nBBCiD8NCeiEEKIFGQyGo04Jvz53vdswy4YUimxrNutz19Mvvp/Xci01hO9g7wtZXJzBud9/6C2XCT8MmUy/3in09P6yiLUFEmAP8Tyti9qgzmQPIdam30PXv10UkSYotHnPThkVWFtOT/f0dHrlnwE4Pa4bqFD0yj+D7unpED3Aaz1Ze7dicVhIzT9ESv4hDoVFYw0wYam2kVCSfzi8tJC1dysMGOe1nhh/3+ZGNlnOYITxT1L54SsU11xHEDEEHd6VSx7h/m9gHn9jbTkhhBB/GrKwuBBCnCLyrHktUq45Q/j0WAM7kN6uK1+OnUpZg4Wzy4LC+HLsVNLbdcUa6D0hCkBSuG8JOJou5yQgaQG1r6BhuFq7LSBxAaC/Lt6BjD1Y7LU9nijwt4VhqozB3xYGqjaos9gVBzL26NaTnnNkWQMDkFSST4e8LJJcwVzjcp7EF+cTVFXpGqbZiFIEVVmJL87XrQeg0jmIgpr7cOCeYMZBNAU191HplN45IYT4s5EeOiGEOEXEWGJapFxLDeErtWYCfqS368qutl1odWgvQdYyKiwhHEhoizo8lLS2nPc2RXY6g4IVO5psT2SnM3T3r89dT4VpBYFJxV6TmZSbtjbZg1llrh0aGVAVRXBpe4xOk2ufw2CjPHQX1YEFrnLeaIHhKLz3qNYvp6eivIzBu3/n+7T+oJwcXiG9lnICGoN3b6YiKchrHbVFFcULduO5K7R2W/GCPQSmRaH5uASGEEKIU58EdEIIcYroHdubOEscudZcj/PoNDTiLHH0ju2tW09sgG+X9qbKxZKLwW7CaYxAGQzsT2qQPVI5MTiKiEW/ByrQuAMMxShnKJqHgSEKJ5qhtLacTmBY1zPpH7oVv5BtOKwpKHsIml8ZRksGmqbcynkT0b0bAWv2E1qchlJOHPb9oCpAC0LzSyS0OI3S8G1EdO+mW8+IwZP44ZM30fC+7roCRg2epFvPoZpD9FNr6KJ+4j1tBoX1etciKeQK9RbBKpBDNcn0oIfXemwZJThKPC+2XsdRYsOWUUJgarhuOSGEEKcPCeiEEOIUYTQYubf/vdyx7A7XXK46dXO97ul/T5MJUQaGB5Ng8ifbVuNxHp1G7YLVA8P1FzqPC4ohuGg2pdG3eu05Ci56n7igv+nWo1lziDL+j3znP3CiMNTrQXIeTvYSZXwZzXqtbj31eyY1TeEX5HlIZFM9mMpZu5C5ozodu3UZqHpDT7Vg/CwjCC5NrX2JOpLMdvKdQcQYKrwluSTfGUSSWb8n1BFaQ7v2azFRSV/WsUN1oZgIwimiM9vRcFLV3owj9Hzdepxl+sFcc8sJIYQ4PcgcOiGEOIWMSR7DcyOeI9YS67Y9zhLn85IFRk3j0Q5JtcFcw3lZqjZMfKRDkm5CFIAe0T0YtvFXHnr9eWKKi9z2xRQV8tDrzzNs46/0iPbeawRAcBw/Yed+rOQ3CDHzUNyPlZ+wN5lOv64Hs2EikzoaGvGW+CZ7MPf9mg1V+7BXfO0ezAGo8trtVftry+koKytjWU0qP9akYsXfbV8FAfxYk8qymlTKyjwv91An0lBAoKkSTQMDTtLYyiB+IY2tGHCiaWA2VRJpKNCtxxASoLu/ueWgdhhn1e5irBtzqdpdjHJ6mefXBIdTsWp3AV9uzGLV7gIcR1mPEEKIxqSHTgghTjFjkscwsvVI1ueuJ8+aR4wlht6xvZvsmauv84FqLvqljEW9LZRZjjwu1Opk7AYrncOr9UY3ArApZwNXLrYTVbaOIZt+ZXP7zq4Fyrvv2oGmFF13w6abNtAvyXs2SEfrM3nYcTWHsLOccnpgJAqNAhSbcKBwstNxFWe1PhO9V9hSPZjWHEWN9UfdMjXWZVhz9NcO3FMGVkzsc5rYb4sgzlCGmRoq8SfHGYI63KY9ZehmAU22RLBd95mOlNNjSgnDGBaAvaTa6zITfmEmTClhPjwbVG7Jp3jBbrdhnMawAMInp2LuFq3zSHcLtxzi4QXbOFRS5dqWEBbIg5PTGN8twed6hBBCeCYBnRBCnII0DCSWtCestDVBNSa0WN8HVDidiuUfp9OluIZOB0vYF+1HudlAcKWTNvl2DAp++SSdlB4xGHSSY5StW0PC4c4lo1L0TG8cdkSXwaF1a0AnoFubWcIhZ3ht24ANOBqUMHDIGcHazBLOTNVfcqCuB/OJtU+4LfEQZ4njnv73+NSDqTkKG/fMNaTKasvpKCo8UodCI9sZ2mQ5T8yBvi303VQ5zaCR0SOS1j8dql1mol4PrDrcU5vRI4IEHxKiVG7Jp+D97TiADRFG8k0a0TZFr6JqCt7fTtTlXXwK6hZuOcSN769vNPQ3u6SKG99fzyuX95agTgghjpEEdEIIcYrZvSGX5R+nU1F8JNlIULiJoZd0ILVXrM4jax1KL3Y91qCgbV7jOVzlRTYOpReT1Ml7r09EhW/tbapcTmmlT/X4Wu5YezBNMfpDKX0tF1rsW3ubKhce3g+TKZ4qW7bXnrVAUwLh4d4zd0LtsMZnf1rCxbk76R01GovfkQDT6ihjQ8ESPv2pIwPGt8eoE9TVZctcGuvHM11M5AYe+TEhtsrJndttnOVDtkyHU/Hwgm266yE+vGAbZ6XF67ZHCCGEPgnohBDiFLJ7Qy4LX9vSaHtFsY2Fr21h/MxuTQZ1FaX6WSd9Ldc+tR8HeKXJetqn6gcaylrsU3tqy7XyqazRYNRdmkBPdHLDHsKjK9cvIpQYbORRmyCmMUUsBvpFeO65q6NpRjp2eIDNW25yPa7eXjSgY4d/oWn6Aeua3fl03/8jBxwVZFnTCQ5PwehvwVFjpbw4A4Wi+/6DrNl9IYM6eB9va8soYbHJyd09Gy/0nmvSuLtnIE9trGJKE9ky12YUug2zbEgBh0qqWJtR2GTPrBBCCO8kKYoQQpwi6oZK6vnlk3ScTSSUCAo16e73tVxwv/7Yo8O9LtPtBOwx4QT3669bT0qwEws2Gi8GXkdhwUZKcBNpJVtIcphGoNHTwhB1rQGzUZEcpt9rFNclldGhQSg0L8uca4wKDSKuS9MLq8fGjqNT6OP42dx7TP1skXQKfZzY2HFN1pG5bTMhjgrsIeGUt+/OoYRIDkQHcighkvL23bGHhBPiKCdz22bdempKbTzT5fC50TBxzuG/n+1soqaJHwRyy7wHc0dTTgghhGcS0Ilj9uOP+skFhBC+qT9U0pu6oZJ6EjqEExTeRLAWYSKhQ7huGc1oJPmBh9FoHIrVDZlL/tfDaEb9nqOwkBAG+O+v98iGNcEA//2EhYTo1tNSHDkm4pJ3A6rRen/qcCgWm7wbR47+MfRPCefbXiHU9IgAU4Ov00AjNT0i+K5XCP4p4U22qXJLPnwWT7ufnqH1untI+P0GWq+7h3Y/PQ2fxdfub0KQw0pNSDhVSakoP/esm8rPn6qkVGpCwglyWHXr+TXAWTvM0lsWVE0jx2zg1wD9ADw25EgPn6acJFVm0aE8naTKLLR6a0LULyeEEKL5ZMilOGbjx4+nVatWXH311Vx55ZW0bt36ZDdJiNNSSw2VNBg0hl7SwePQzTpDpnTQTYhSJ3TsWFr99wVy/vMY9pwjSUj84+OJ+8d9hI4d22QdsfYQ0gxW8NvNGntrrBwJlCxUM8BvP2kGK7H2ExPQZeeZebW9hiksjwHbIwmqOvJVWBHoYF2XQmwxGp3zzOil/VhTWlEb+MRbsMWZMRRVg80BJiPOiIDawOdwucER3l9b3Zw1qE2GYynq0qhMsQ9z1rp1aM2GuDa1f3jqWVMKW1xrunXQv0YXRZkgV7fIkXI6+qdEkhAWiOXgNoYW/EKI48hkyzJjEMujhmBNTKN/SmTTTyaEEMIrCejEMcvKyuK9997jnXfe4eGHH2bUqFFcc801nHfeeQQE+L7ekRB/dS01VBIgtVcs42d2a5RcJTjCxJApviVXqRM6diwho0dj/fU37Hl5+MXEYOnbp8meuTqFO/cysKYjFf6baW0oIkeFUIk/ZmqI08owaDCwpjuFO/cS1NH3dPhH6zeziRynHyRUsj8+i7hCE2abkUqTg5xIG0oD8OM3s4luOvVk22qO/KFpOCM9vy9u5TywZZS4LQ3giaPEhq2JOWsEBaP8da65mobyN0FQEwvKm/x19/tazmjQuL19Ffs2Lmq0L9hRwYTcRbQZ1k4SogghxDGSgE4cs+joaG6//XZuv/121q9fz9tvv83f/vY3/va3vzFt2jSuueYaevRoYuFhIYRrqKTesEtfhkrWSe0VS0qPmNqhnKU2gkJrH+tLz1xDmtFI0AD9uXLeVDoqSHHGMrqmO6v9d2IwHFloO0iZGFjTkRRnLFaHj2k1j5GKrYaMw/+tQXaU5+OtYvWDLL9c33pU/XJtEO99v7NM/3l8LVdRoT+U0tdyA8ODSTD5k22r8TjPUAMSTP4MDNcPDJ1OB0VLP/WYLqZuW/GPn+K8cDyGZqyxKIQQwp0EdKJF9e7dm/j4eKKionjiiSd46623mD17NmeeeSavvvoqXbt2PdlNFOKU1ZJDJevXqbc0ga+UU2HLKMFZVo0hJABTSpju8L/6zO3CsS4/QFtjDMnOGLINxVRiw4yJeGc4moIKRymWdr5luDxW5arp+Wi+lOtghRCrgzKzAQ0nndlOOEUUE8EOuqAwEGp10sGs/zyGkCO9ao3XfXO4FluvX86T4GD9AMvXckZN49EOSVy7ZW+j+ZN17/gjHZIweptjd1jW9q2UF+ofw7KCfLK2b6V11zOabrgQQgiPJKATLaKmpoYvv/ySt956i8WLF9O3b19eeuklpk6dSl5eHvfffz8XX3wx27ZtO9lNFeKU1pJDJVtK5ZZ8ihfsdhsWaAwLIHxyqk+LSyd17cYC2zx6W0ajKUh0Hgkw6xa83lG9lsldx7d84z0IqQnBbDdTaaz0ttoAZoeZkBr9OX3VZTbGrbeyd/AWpvM2URS49hUQxbtcTdsN3ageqN+TZ0oJwxgWwGKT0/u6bzYjppQw3XqSk5MJDQ2ltLQUhSI/MJ8qYxWBjkCiq6LR0AgNDSU5OVm3HoCJMeH8r1tb7k/P4lC9IaMJJn8e6ZDExJjwJusoLy5qskxzygkhhPBMAjpxzG655RY+/PBDlFJcccUVPPXUU3TrdmTmSVBQEM888wyJiYknsZVCnD5acqjksarckk/B+9sbbXeUVFPw/naiLu/SZFBnMBjpNnIsrHHgADbW64HqWWjHCHQbMfaEDbuLi4ijx/oerI5dfSRdZ53D3VE9CnoQ1zNOt55I+yaGar9xnpqLEwPbtK4UE0E4RXRS27mNZyjQphFp7wu09VqPZtBYPTaRu0vy0XDQRW070tNn6szdPQN5JSya85t4/w0GA706nckHW97i96jfCbcmYqkJxWo6yK/Rv3JGwRkM7zQOg8G3BNcTY8IZHx3G6uJycqvtxAb4MTA8uMmeuTrB4b71DPtaTgghhGcS0Iljtm3bNl588UUuuOACTCbPSQGio6NleQMhmqGlhkoei/rZF73xJfuiciosf/jxfZyBZz30QP19u42xfxhRTuXzMM5jMbrHaH767icG5A7g96jfqfSrdO0zO8ycUXAG0dXRjO4xWreeIEMBcb0/YhUDeE+bQaF2JLCNJJ8r1Fuc2esTggwpuvU4lOLftlL6sobpvOWhp28Gj9iGco5SusGU06n4YeNv5JitXPD73QRXHzl/ygOKWNF2Hj9s/I3hEwb6/OOAUdN0M3TqSerSleDI6Nphl0oRWVGFqcaOzd+PwqBA0DRCoqJJ6iJD8YUQ4lhIQCeO2YMPPsigQYPw83M/nex2OytXrmTYsGH4+fkxfPjwk9RCIcTRaKnsi7aMEhabnNzTs/F6Y7kmjXt6BqJtrGJKU1kcW4i/nz89hvZg+4/bSbQmUhBY4BqaGFUVhYZGl5Fd8PdrIttjKzurc/ryAnc12lVIJC9od6GZn6Z7nF23mtXF5SRVLec2nm60L4ICbuNpZlXB6uI2usHVgZ0F7PT7nbE7ZzTaF1QdztidM/gp5WMO7CygTefjn03UYDAy6qrrWfPAP0g7mI+5xuHaV+lvZFtiNAPu+IckRBFCiGMkC4uLYzZy5EgKCwsbbS8pKWHkyJEnoUVCiJbQUtkXa0ptPNPlcO+9p/XRgGc7m6jxcR2+lnDp8EvpMrILNX41xFTF0LqiNTFVMdT41dBlZBcuHX5pk3VURcTxLoeDp0avywAo3mUGVRH6QzcPVlYynbdqH9ZgX20tcAVvcbCysuFD3aw7+Bt9s8Ydrse9prq/+2SNY93B33TraUlxJeX0ycwhsF4wBxBY46BPZg5xJeUnrC1CCPFnJT104pgppdA8DAMqKCggKCjoJLRICNESmsqq6Gu5XwOcbsMsG9E0cswavwY4OZE/AV06/FIuHHwhSzYtIa84j5jwGEb3GN10z9xhW+wJFGp6674ZKCSaLfZQknTqydi/gj71hlk2ZACiKeC3/Ssg8Xyv5coKK9yGWTZqDhoh1RGUFRbrtKYBpwMyV0J5DgTHQfIg8LFHTTkc5Dz2+OHnbtgWat/3xx4nZPRon9c0FEII0ZgEdOKoXXDBBQBomsZVV13lNn/O4XDw+++/M2jQoJPVPCHEMarLvqg37NIYZmoy+2JRlAlym36+oijfFlZvSf5+/ozvc3TZNSsCUoH9PpbzzpK7A3z47cuSu0N3f6zDVre8XpPlfLLtK1h4D5QePLItNBHGPwlp5zT5cOuvv2HPzvZeQCns2dlYf/3tqNc4FEIIIUMuxTEICwsjLCwMpRQhISGuv8PCwoiPj+f666/n/fffP9nNFEIcJc2gET5ZPxgJn9yuyUQmcSbferx8LXeqiDP51oPZVLmIKt8C2abKdSzz3svX7HLbvoJPprsHcwClh2q3b/uqySrseXk+tcfXckIIITyTHjpx1N5++20A2rZty5133inDK4X4EzJ3iybq8i4e1qEzET65nU/r0A0MDybB5E+2rcZtkeo6GrXrmw0M921h7FPFkddVjfKwoJ2GIsEU0OTrGpc4kB9L5hJhKm40FQ9AKSi0hTMucaBuPbGBFfgZC6hxRDaaQwegUPgbC4gNrNB/YU5Hbc+cx3fr8DoPC++FzhN1h1/6xcToP08zywkhhPBMeujEMXvwwQclmBPiT8zcLZr4e/oTfV13Ii/tRPR13Ym/p59PwRzUpr5/tEPtLDKPc6mARzok+by+GVAbdGQsh82f1f6/09H0Y1rYkdfVOHzSDv+vL68rPbY961f2rX1MwxhK1da1YWVf0mPb69bjHxHGmJD/oVEbvLlXUxtyjgl5E/8I/SGyZK5s3DPXsFGlWbXldFj69sEvPt5jWHi4Fvzi47H07aPfHiGEELqkh04cld69e7NkyRIiIiLo1auXx6QoddavX38CWyaEOB40g3ZMSwpMjAnnf93acn96FodsNa7tCSZ/HumQxMSYZtR9jHO7WlJLvK7csiomfL2JoF1+lF5sx1kvr4mhCEI/82P8H7+Te0GVbj3+8SGkBq5mfPhTLC+9hgrnkYD7/9m77/i26nPx459zJFmyLEvyku04ie04znD2dEigrBACKaMDaFktpbRw4RaartAfoxTK6KC097YNHZS2tAXKbQsUCIEALWQnziTLSYyTOLblJdmWbNnSOb8/5BHH1pESO5Pn/Xrl1jrn0aOvdHnZfvwdj0Ot5zznMxTZ1hDOudl4QK21ccecSJxiMnHorrvJvu9eNPr+BVkjWqgeuutuiuVAFCGEGBQp6MRxueqqq3oOQbn66qtP7WCEEGeERVluFma6WONrxdsRxpNkZo7bcWwzc917u46e9+ne23XtH09JUTeY9zWscjeOdj9sVkneYqFjtE7EpWPyKyTtVVB0BTs+7JW7YfrImHl279rIBKDItoZC6zqqO8YT0NJIUZvITdqJqmi9cTNuiD0gR2+bBU1XqXOOJpSUjLWjjazmvT15jowbSETXWTysmNFfuYe7XvwjHl9ve5u6tAx+cc1N7BtWzPo4DdOFEEIYk4JOHJcHH3wQiJ5meeGFFzJ58mTcbvepHZQQ4rRnUhTD5tiGhmhv1wmhaySFdmEN1pGkZ4E+HZTExjDaHKL7LEhFV7CWD1zcjDYbn05ZHVbJ19JIUZpQFY0864d9h6hDQE+nOqwywShR/lxwDuOQKYN9xUHCtt5CzNxeSFG5neGRxmicgTW+VqpDnVRPK2XllFlM2ruLDH8TDa40to0eh6aqEOpkja/1+P+bEEIIIQWdGByTycSCBQvYuXOnFHRCiBPrWPZ2FZ6XUMqIprOuohFvSzueVBuzC9MxxTm182hvV77N4+sepzbYuwQx257NktlLmJ8/P+7zkzJ611hqikJ9ViZttmSS29vIrKtH1fV+cQPRtBLe99/GQvcP0fW+vc67UvC+/8uYtFzjAakmDk24md3m3/a7Fbb62T3RD+EvMzxO0VwT6j1ER1NVtowpiRsnhBDi2ElBJwZt4sSJ7N+/n8LCwlM9FCHE2WyI9nZ1W7a9mode3UG1v3dvWq7LxoNXlLBwYpyip8vblW+z+L3F/Q4h8Qa9LH5vMU9e8GTcos6ul2FOjvBRxkjKpk+nzW7vuZccDDK9rIyCxkrsehkwL2aeEeMW8M7aPSzzfZtznb8j1dTbnqBVy+SD5i+xP3QOF40bYzgeLRJmn/b36IOBTnvRYZ/2D4ZFvoVqiv1rhD9QQfevGYqmM7I+jKNNozVZ5UCmGb2rcI7GZRiOSQghRGxS0IlBe+SRR/jmN7/Jww8/zIwZM/qdeOl0Ok/RyIQQZ5U4e7aOJW7Z9mrueK6s3+LNGn87dzxXxq9unB63qItoER5f93i/Yg66T5VUeGLdE1w44kJMBrNZiv8AzfPSWZnRv1hrS05m5bx5pDe0ovgPGI7HmR793rs/dA4VdbPJTdpJitpEQEujumM8OqY+cbHU7XqPsLUxdoACYWsDdbveI3tC7GLVgxc1bGVMdQoLNrXhauv9nPzJCsunJbMnN4CHBBudCyGEGJAUdGLQLr/8cgCuvPLKPqdd6rqOoihEIif/OHEhxFmoa28XzdUMvI9Oid6Ps7crouk89OqO6LH5aFynHGY4nRzCwgv6MCKoPPTqDi4pyTFcflnmLeuzzPJoOjo1wRrKvGXMypkVezyukbyZdS66Rv8TgxUFXdd5M2seU10jMVrkmFvsJtmp09YMOiYOd0zsN6JkZzTOSKi1xvB+onHZKVlM2f0qi7Zf0O+es03ns6uCvDbx32RPuiKh1xNCCDEwKejEoL377runeghCiI8D1RRtTfDizfSs/evRVQgtfDzugSjrKhqp9rdzt1LBNfpw0Hv3dt1BA39TKvmZv5B1FY2cUxR7KWBdsC6hYceL22YfQYfegKJEj/OvdmUSTLJi7wiR669HVRQ69FS22Ucw1SCPomgMc/6Jff6biDaw67+JbpjzTyjKBWBQGpqTsyFO7/GeOANTM6dxUXkVdM1W9hkr0YL3ovJpTM2cFv/FhBBCxCQFnRi0888//1QPQQjxcVFyZbQ1wYB96B5PqGWBt6W7mJs8wN00rtHTQdmKt2WqYZ4se1ZCQ44Xt716NwD7M3NZWTSZgC25515Kexvz9m1lVH0126t3M9Wg9mlqWMvwf60h2dxO+ehrCNl6D1Gxhpoo3vsS6Vs303T7WtIzY89irvVn4WpPQ7c29d9DB9FasT2dtf4sPmXwvrz7WrCHYi+5V1Cwh1x497WQN9b4wBchhBCxSUEnhkwwGOTAgQN0dPQ9sWzy5IF+aRJCiONUcmW0NUHlqugBKI7s6DLLBFsVeJLNzNCHdz06umJRAY1r9OEcTDb+ETndM51sezbeoHfAfXQKCtn2bKZ7phvmaW/0sT+zgOUls/vdC1htLC+ZzYId6xje+JFhnsD6tZh8Ch62kFW/FZ97NKEkJ9aOZty+vShdrR0C69eSflnsgq7K187G8s9y4ZTf9HSD6NH1Nt/Z/Rlyio0bnQeaE9sbl2icEEKIgUlBJwatrq6OW265hTfeeGPA+7KHTggx5FRTwq0JjjalbjeNhqcqqkAGU+p2w9jYywpNqokls5ew+L3FKCh9irruJYbfmf0dwwNRADKCLj4Y3bXfbYA9dOg6HxRN5FMHmwzzmJp7n6sBB80ajZYI6ZqGk95FlkfGDSQv3cGPvZNgy21cNO4ldFvv6yrt6byz+zM8553ET0sdhnlSnFbD+8caJ4QQYmBS0IlBu+eee/D5fKxdu5YLLriAf/zjH9TW1vLII4/wk5/85FQPTwgh+mpqBlwJxhmbnz+fm0bdz5/Kfw4mX++NsIubxnwtoT50bc4ZBK0GJ08qCkFbCm3OGYZ5HPml+HmalbkTWTr5auqT3T33Mtt83L71n8yr3o4jv9QwzydLx3P/a3t5zjuRv3oncFlaBdnWZmpDTt5oKiSCgkPt5JOl4w3zZBY60NBQUWPGaGhkFhoXhkIIIYxJQScG7Z133uHll19m5syZqKpKfn4+l1xyCU6nk8cee4xFixad6iEKIUQPNT2BYi7BuGXbq/nla3YUvs00ax0ZapgGzczmUBa/LFeZlFYdt/1Be1ZijczjxW0tGsfa0efwPxM+3e9evc3FI7O/wF07/s6conGca5DHYjZx93l5/ODftURQ+FdT0RF3o7OQd5+Xh8VsPPP4wcYNhsUcgIrKBxs3cPE55xjGCSGEiM34O60QCQgEAng8HgDS0tKoq4ue6DZp0iTKyspO5dCEEKKfpFlzgAgDtz6g63qkKy627vYH52HmJZz8LFTMA23j+VmomL/h5BOYeejVHUS0WK8TFayuTmjc8eK2Ha7l1xM/GX0w0NJN4DcTPsm2w/Ebr9922Sxun2jGTmef6yl0cPtEM7ddFrsNQ7eGen/cmGOJE0IIMTAp6MSgjR07lt27o6e0TZkyhaeffpqqqiqWLl1Kbq7xX6aFEOJk6zgYILqjLNaMlwKYuuJiW1fRSLE/zA9IJvOoXJkoPEIyxf4w6yoMmnQDaQ1BaA/3tBboR9ehLRyNM1BX5SeEtX8x101RCGGlrip+AbVjxw7a967hM9YtXGrZxScs+7jUsotPW7fSvncNO3bsiJsjW0+NG3MscUIIIQYmSy7FoN19991Ud/3l+MEHH2ThwoX8+c9/JikpiWefffbUDk4IIY6itXTED0ogzutv4x5s6IB6VEGnoqChczc2DvnbDPO4CuxYdvrpnJoeLd4G6B9n2eXHVWQ3zJPSYFw4JhqnaRr/fPU1dB1MCuSaWvrc13X456uvMW7cOFQ19t+Fp+WNYq+2hXbFMnCRqevY9E6m5RnvxRNCCGFMCjoxaDfeeGPP1zNmzKCyspJdu3YxcuRIMjMzT+HIhBCiPzU1aUjiRgQ0PAYLXVQUslFQApphninTHWSWVePZrFI13kW9rbf4yWzXydvlp85fzZTpxoeHjNCSgPau14YpmMhAoQGdLUTQ+sTFVvFRJR1tAaOJPjraAlR8VEnRqMKYeSypSRSXv8S2MZ8HItiz9mKy+Yi0uwnWjQZUive+hCU1/vJNIYQQsUlBJ4ac3W5n+nTjvktCCHGqJI10oIX8KElOlAGqFl3X0Tv8JI00LqDGOGz4Eni9MQ6b4f1gfRvfytnCeZUj0bytbEozU29VyAzpTGvqRMXE+/lbCNZPgxGx88xOd5JFiPGYuAdbn2LTi8ZTtLOLCLPTYzf7BtiyvyaBdxWNMyroIo17yapeScnoA3RcWY85pXepZzjgIumVTLIOHyTSuBcM20gIIYQwIgWdOC6LFy9OOPbJJ588gSMRQohj01ZWRmjzX7DNvh1d1/sUdXrXEsfQ5r/SVpZNSmn/Zt/dzM7EZvrixUVac5lXZe/auacws+nI3p3RRufzquYRaDU+dTN7fBGPrGylBFO/414yUfgByewgQvb4ogGf3y2oJba9Pl5cpL6etqka2uf29ftlw2z3o33OT1uLmUh9fUKvJ4QQYmBS0InjsmnTpoTiBvrrtxBCnErhujrC1ZtoX7cU6+TrUJLTe+7pbU2Etr1AuHoT4a4Te2OxFrowuZII+zsGPF5FB8wuK9ZC40IsJeTAFDb6caxiCmeQEjKe6bMWuCnBDLqOqvTf06frOiWKGWuB2zDPmFY/VcEgbcnJMfe+JQeDjGk1PlxFTXfjvyYcfXB0GgXQwf/ZMGq68XiEEEIYk4JOHJd33333VA9BCCGOizkrCyBatFVvxpRZjGJ1oYf8ROrL6W5n0B0Xi6IquK8oouG5nei6TkNYp10HmwIZZgVFUXBfMQpFNf7DlrmxGp20+ONuNG5b0FHZHK2bFAUdjba03YStfswhF8lNY1EUtSfOVuSOmafY0oG/rIyV8+bFPKRl+qZNFH/ifMPxtGi70YzelgJaejQulXmGuYQQQsQmBZ0QQoiPFfvMGZhzcgjX1oKuE6nf0zdAUTBnZ2OfOSNuruSJmbScM4zVyw/QFuld6JhsUjhnwUiGT4x/MFS4owZTAgVduMN4b1ukOXoqZ4tnA95xfyZsa+q5Z25Pw7PrBlK9M3viYknyeBh+qIp5K1eycfp02u29p2vagkFmbNrE8ENVJHX1H42lvfkAGE8q9sadZLqmE6rwo7V0oKYmYS10xS28hRDidCUFnTgun/70p3n22WdxOp18+tOfNoz9+9//fpJGJYQQ8SkmE9nfvZequ++Jzj4d2f+tazYq+7v3ophMcXPt2+TlnTcq+11vi+i880YlSSNTKZpmXPg0Wdqxh5tJNqXGPKQlGGmhzdJOvkGeSGsHLZ4NHJ7yv/3uha1NHJ7yvwzbchfO1tgHmUBvwasDiq6TVeslub2NNlsyrY6U6FLSnJy4Ba9dDRveP9a4odK2vR7fq/uI+HsLW5MrCfcVRSQnUIALIcTpRhqLi+Picrl6fvFwuVyG/47VL37xCwoKCrDZbJSWlrJu3TrD+KeeeoqxY8eSnJzMiBEj+PrXv057e/txvS8hxMeDc8EC8n72FObs7D7XzdnZ5P3sKZwLFsTNoWk6779QbhjzwYvlaFqMhuFdknInUtawAug9lKVb9+NNDStIyp1omEe1q3jH/Tn6YKA9a4B37F9Q7cY/+hWTieavfoXK/Hzmv72Ci959l3NWr+Gid99l/tsrqMzPp/mrX4lb8HpyJmINRQwbplvbI3hyjN/XUGrbXk/Dczv7FHMAEX8HDc/tpG27HNAihDjzyAydOC6///3vB/x6sF544QUWL17M0qVLKS0t5amnnuLSSy9l9+7deAZY3vOXv/yFJUuW8MwzzzB37lz27NnDF7/4RRRFkdM1hRCGnAsWkHrxxQQ3bCRcV4c5Kwv7zBkJzcwBVJf7CPhChjGtTSGqy33kjY29pNLuzqAquIeV3n8yPeNi7ObetgLBSAubGlZQFdzDHLfx0f4B244+yyz7USCc3EjAtgMHw2KGaZrGh//5gHkrVxFRFDYXj6fBlUaGv4mJe3cxb+UqNiQlM+266wwbi6vOXMa8H2BriRMG3IqnMGZfAHVcruH7Giq6puN7dZ9hjO/V/dhKMmT5pRDijCIFnTitPPnkk9x2223ccsstACxdupTXXnuNZ555hiVLlvSLX7VqFfPmzeP6668HoKCggM9//vOsXbv2pI5bCHFmUkwmw9YERgLNxsVconEfNTlpMaVwKLiHw8FyMm3DSTY5aIu0Ut9+CA2dVpODj5qcFBjk0dJaoTb+eLS0VsP7Ffv2M2HNav4zdRa/uPYL1KX1FpJZTQ3c+eIfmLl2FRX79lNUPDp2Il1nvVLKUmURN/F7MmjoudWoZPAnbuF25TUWxZrBG2KhCn+/mbmjRfwhQhV+w0NjhBDidCMFnRi0hoYGHnjgAd599128Xi+apvW539jYmFCejo4ONm7cyL333ttzTVVV5s+fz+rVqwd8zty5c3nuuedYt24ds2fPZv/+/bz++uvcdNNNx/+GhBAiASlO65DE1fnaeT/jXC7zvomOTl37wX4x72fMY4LPeCm5pcmb0HgsTV4MJuioffN9to2dyPe+8vX+Y3Wn8b2vfJ2Hfv1TJr35vmFBFwnUc1/R16gmkw3MZhw7cdOEjzR2MR5QuL9oFAsD9SQ2Jzo4WotxMXescUIIcbqQgk4M2k033cTevXu59dZbyc7OPu7ec/X19UQiEbKP2tOSnZ3Nrl27BnzO9ddfT319Peeeey66rhMOh7n99tv57ne/G/N1QqEQoVDvX8ybm5uPa7xCiI+33GI3KW4rAV87/TetAeg40mzkFrsN83jS7eSljGGeJ5lNDStoi7T03Es2pTIt42K2pozAk243yAK7D7tp7HTjtvoYaMWgpkNTu5vdh91kTjBIdLiS/732C9Gvj/5+rqiga/zvNTfz9MYPDMezxjyMalt0zDqwk/575Q7bslljTrxpgR6JHPcSWTU1sUbwicYJIcTpQgo6MWjvv/8+H3zwAVOmTDnpr/3ee+/x6KOP8stf/pLS0lL27t3L3XffzcMPP8z9998/4HMee+wxHnrooZM8UiHE2UZVFWaODfLvNSoxNokxY0wQNc5+rLmlw3G99hHpKWPIsxdT336ItkgrySYHmbbhoCh8HZ2JpcMN82xt7eCtis/wX1N+h6bTp6jT9GjJ+fzuz3BJYYdhAVU9ekSfZZb9KCp16ZlUjx5hOB5v+lio7T/bOGBcApqXL6f20ccI1/S2bzDn5JD93XsTOsSmuxG80bJLUwKN4IUQ4nQjp1yKQRs3bhxtbW2DzpOZmYnJZKK2tu8mkNraWnJycgZ8zv33389NN93El7/8ZSZNmsSnPvUpHn30UR577LF+Sz+73Xvvvfj9/p5/Bw/G/4VDCCGOpkciWP/wKBM//A3WkK/PPWuoiYk7fov1D4+iRyKGeSIHW8hERUVBVVQ8ySPJd5TgSR6JqkSvZ6ESOdhimCeU4abMO4VfbrkVX8jd515Tu5tfbrmVMu8UQhnuAZ/f876mJ1ZgxYvzWHtnulRdZ0ZjmEurO5nRGEY9Yt/ckXGxNC9fTtXd9xCqrWVz8XhWzJzL5uLxhLxequ6+h+bly+Pm6G4EbySRRvBCCHG6kRk6MWi//OUvWbJkCQ888AATJ07EYrH0ue90OmM8s6+kpCRmzJjBihUruPrqq4HoaWsrVqzgrrvuGvA5wWCw3ylrpq7lN0cf/93NarVitSa290UIIWIJbthIuKYGDzVk1W/F5x5NKMmJtaMZt28vCjrhrjijg1eGam/XnNEektV9lHkns8k7iTFp+3BZm/GHnOxpKkJHIVltZs5o46Im1aWCwWGZfeKMxuN2kGu1MP5AkG/sDJEd6v2eXGtV+Ml4K7tG2pnjdhjm0SMRah99jP9Mmcn/DnBIy11/+yMXPfoYqRdfHHf5ZfLETDJuHD9AHzor7itGSR86IcQZSQo6MWhut5vm5mYuuuiiPtd1XUdRFCJx/jp9pMWLF/OFL3yBmTNnMnv2bJ566ikCgUDPqZc333wzeXl5PPbYYwBcccUVPPnkk0ybNq1nyeX999/PFVdc0VPYCSHEiRCuq+v5WkEnzTdwT7oj4wYyVHu7ZnimMSPpP3zQPo7orrUj6YDCjKQqZng+a5hnYstKMtunUW/N6L+HDkDXyQrVM7FlMzA3Zh6TovA/OMjf3NhvNFkhnSc2t1M50oMpzr7r4IaNvJMzggdjHNLy4G33wK9/yrA4hXO35ImZ2EoyCFX40Vo6UFOTsBa6ZGZOCHHGkoJODNoNN9yAxWLhL3/5y6AORQG47rrrqKur44EHHqCmpoapU6eybNmynoNSDhw40GdG7r777kNRFO677z6qqqrIysriiiuu4Ac/+MGg35cQQhgxZ2UNSdxQ7e06dPAQo2llVO6bTC5eSZrN33Ovqd3F1vJ5qE0ZHDp4iMLCwph5kkNh7nzpDzx0w2LQtehBKN10DVC44//+SPJXSwzHo2s6Be98hI6CetShMdFdhzoF736EPmekYTEVqqtL6JCWa+rqSDEc0ZFPU6Q1gRDirCEFnRi07du3s2nTJsaOTWzfRTx33XVXzCWW7733Xp/HZrOZBx98kAcffHBIXlsIIRJlnzkDc04O4drankNQ+lAUzNnZ2GfOMMzTvber4bmdMWMS2dvV2tpKRsYBxpf8u//zrX4+MfF1du44n9ZW4z50loMZXLByA/tcT/H8pTcTTupd4mjubOJzb/6RCz/YgOXy82BW7DyhiiZoPbqU66WgQItCqKIJW1F6zDyb0j3UhSwx73cf0rLJ2snFhu9MCCHOTnIoihi0mTNnysEiQoiPHcVkIvu7XX0z+80cRR9nf/fehI7V797bZXL1XVZpclnJuHF8Qnu7UlKSKRq9PvpAh5bDdpr2Omk5bO9ZgTmqaD0pKcmGeerqnKwdo/Dm5I24q+/BVfsDUut/gav2B7ir7+HNyRtZO0ahrs54f3RLzcDtZo41zl84KqE8icYJIcTZRmboxKD993//N3fffTff+ta3mDRpUr9DUSZPnnyKRiaEECeWc8EC+NlT/Y/Tz85O+Dj9boPd2+Vy1WG1BvHtT6VqVTadgd7vxZaUTvLm1uIe1YLLVQfEbgi+r83Cs5dE/96rKJAUOqLgUgAdnp2vktdmwaiECiU1AvFbAETjYsu2JbbHMNE4IYQ420hBJwbtuuuuA+BLX/pSzzVFUY7rUBQhhDjTOBcsIPXii4+74fWRBrO3q7OzDt/+VD56K6//vYCZj97Ko+CSKjpLjA9pKRsJDS0GRaSi0OCCslS4xCDPHmcDaWaNjLC73x46AA2denMTPqcPow573adl1rR3oA+wR1vRdXJtSXFPyxRCiLOVFHRi0CoqKk71EIQQ4pRSTKaETlg8kSyWTKpWZXeP6Ki70am1qlXZWD5lvHzTmhMG45Z3vXEG2iwZvJD9AvdV3YaG3qeo09BRgKezX+JKy3WGeUyKwiPFeXx5+0fdE4Q9FABF4eHivLinZQohxNlKCjoxaPn5+ad6CEIIcVaIaBHKvGXUBevIsmcx3TMdk5rYTF+g2t5nmWV/Cp0BC4FqOxkZsaNm5xfwu4E7MPSLM5Jpy2SVczOP8Btur72GrHBaz716cxNPZ7/EKudmvmS7M+5rLcpy89uJBdxXXkV1qLPneq7VwsPFeSzKcscfsBBCnKWkoBPH5ZVXXuGyyy7DYrHwyiuvGMZeeeWVJ2lUQghx5nq78m0eX/c4tcHanmvZ9myWzF7C/Pz5cZ/f0pRAN/AE4sLWMSR3uGmz+PpP9AHoYO90E7aOMcyT3WjD3mZiVepm1qRuYUJwNOlhF41mPx/a96KhY28zkd1og2Hxx70oy83CTBdrfK14O8J4kszMcTtkZk4I8bEnBZ04LldffTU1NTV4PB6uvvrqmHGyh04IIeJ7u/JtFr+3GHQY1jwae6eToKWZGn0/i99bzJMXPBm3qDtMfUKvdZh6Jhjd39vCZw9N4LnCD0Cnz741pas9w2cOTeDw3hbITIuVhja/n9Id6bw7vQ4NnW0pR0z7da2bLN2RTtsk/8AJBmBSFOalpSYcL4QQHwdS0InjomnagF8LIYQ4NhEtwuPrHqegYRLzPvo0jo7eIqk1qYlVBf/giXVPcOGICw2XX3bkJhOwhbG3m6I93o6ioxOwRejINW5b4Ah28hVeY6q3kx9mpFFr7v1VITsS4VsNTcziNVYGv2Wcx51Gfq2dC8uyWFvSSDC594979nYTpTvSya+143DHLgqFEELEJwWdOCF8Ph9ut/tUD0MIIU57Zd4y7AezWbDnS/3upXS4uWTPLSznGcq8ZczKid3J2+PIZm1JIxeWedDpu1oyOiGmsK6kkcsd2QM+v9sM0w7cSjMLgnBxsI0ym5U6k4msSITp7SFMAEobM0w7gKKYefLGT8CRnkl+bT0japOpTQ/RZo2QHDKR3WhFRSE1I5O88UbzhUIIIeKRxuJi0J544gleeOGFnsfXXHMN6enp5OXlsWXLllM4MiGEOP15W+uY99GnAfrNrHU/nvvRp/G2GrcbmO6ZTofnXF6+5HO0pPRt+t2S4uLlSz5Hp+dcpnumG+YJKB/2fG0CZrWHuDwQZFZ3MTdA3EBU1cRFX/xKz/vIas9iRGAEWe1ZPe/rwi98BTXBQ18AIprO6n0NvLy5itX7GohoevwnCSHEWU5m6MSgLV26lD//+c8AvPXWW7z99tssW7aMF198kW9961ssX778FI9QCCFOX7a6NBwdtpj3FRRSO9Kw1SUb9QNH03U+yrqaFnsqewtLGF79ESnBFgL2VA7lFqArCs7gSDRdx6iEqjebjV7mmOKKS+cy9fpbWblhI5qp91cONRJm3swZFJfOTeCVopZtr+ahV3dQ7W/vuZbrsvHgFSUsnJibcB4hhDjbyAydGLSamhpGjBgBwL/+9S+uvfZaFixYwLe//W3Wr19/ikcnhBCntzy1YEjiXtv6YXRmTlHQVZWDeaPYVTyFg3mj0FUVFIXmFCevbTWeWTMVnEu1aiPW5Jemw2HVhqng3Lhj3rFjB+9v2kLEZKLOVsfBlIPU2eqImEy8v2kLO3bsiJsDosXcHc+V9SnmAGr87dzxXBnLtlcnlEcIIc5GUtCJQUtLS+PgwYMALFu2jPnzoyex6bouJ1wKIUQcqe7Ys3PHEneoJZBQnnhxUzwz+X7nFwD6FXXdjx/p/AJTPDMN82iaxrJly6iyV/HGiDf4T+5/WOdZx39y/8MbI96gyl7FsmXL4h6sFdF0Hnp1R3RfoK6R11ZFcWs5eW1VoEef+9CrO2T5pRDiY0uWXIpB+/SnP831119PcXExDQ0NXHbZZQBs2rSJ0aMTWbgjhBAfX7nFblLcVgK+djR0qp37CFqasXc6yW0uQkXBkWYjt9htmGd4agr44hc1w1NTDO9vrPTzRuf53KEmc7/lT3SSTCspOAhgoZ2HO2/kTW02N1X6OacodofyyspKdoZ3ssazpt+9NlNb9Lo3GldYWBgzz7qKRqr97RQF9nNewwekRnoL0hZTCu9nnMs+RrGuotFwPEIIcbaSgk4M2k9/+lMKCgo4ePAgP/zhD3E4HABUV1fzX//1X6d4dEIIcXpTVYXzrivml3/7Myvz/05qoI3kkIk2a4SWomTmVX6a/7rmBlTVuIH2oskTcC5bTXOyAwZqtq3rONtaWfSJcwzzeFuiyxp3MpqfcSspdPbcC2BhJyP7xMXia/azPX1b9MHRw1EAHT5M34av2bgPnbclWsxd5n2z3z1HJMBl3jd5w3Mp3paphnmEEOJsJQWdGDSLxcI3v/nNfte//vWvn4LRCCHEmacifSu7XH/l8lXppLS7eq4HbGHWlvyVivRJFGHcWNxiMvNtdxL3hQBd71vUdTUE/7Y7CYvJ+Ee/J9XGSLWRCy37+t2z08mFln282xmNM/K+dyetFoPlnQq0WAK8793JNKbGDMtKSeK8hg+6n3J0CnTgvIaVZKV8znA8R9I1nVCFH62lAzU1CWuhCyVOwSyEEKcrKeiEEEKIQdL1CD7fekIhL1arB7d7FoqS2HH8ES3C7//xQy4sy+p3z95u4sKyLJ61/ogLv2bcWBwgd8xY2F7R3XiuL6XrfhwzRqZyTlIl6P0n+hQlWhvOSapkxshUwzztgWDc10okblious8yy6MpQGqklWGhaqD/Z3i0tu31+F7dR8Tf0XPN5ErCfUURyRMzExqzEEKcTuRQFCGEEGIQvN43WbnqE5RtuoEPd3ydsk03sHLVJ/AOsERwIBtrNjB2U/THcaw+dMWbFDbWbDDME9F17iuvApQBKzEFhfvLq4joxvvsdu96i2TCA67a7EqFnTC7d71lmGeEmth+tnhxbf6mhPIkEte2vZ6G53b2KeYAIv4OGp7bSdv2+oReSwghTidS0AkhhBDHyet9k23b7yQUqulzPRSqZdv2OxMq6ip3bCWl3dyvmOumoOBoN1O5Y6thnjW+VqpDnTHv68DhUCdrfK2GeXw+4wbmicZ9Ms1NaqebWPWjrkNqp5tPprkN8zjcaQmNJ16crun4Xu2/jPRIvlf3o8tpmUKIM4wUdGJQIpEI//nPf/D5fKd6KEIIcVLpeoQ95d9n4PWN0Wt7yh9G143bt9hDiS3NjBfn7QgnlCdenNOZ2LLDeHHJjnpCtYuiDzTIabBSeNhOToMVujoVhGoXkewwnhXLGz8BR3r0tRQUsmwjGJkynizbiJ4iODUjk7zxEwzzhCr8PTNzETS22vfwnnM9W+17iHQNKOIPEaowPqRFCCFON7KHTgyKyWRiwYIF7Ny5E7fbfaqHI4QQJ010z1yNQYROKFSNz7eetLQ5MaMm5E9nF3+P+3oT8qcb3vckJfYjPV5cCjkonR3oZkvM0zKVcAcp5BjmWR/MoKElmeIdCzm35kMcod6/IbdaNT7ImUC5Oon1QTtG526qqomLvvgVNi59iWkZF6JkVRO2+jGHitHrLmdTw7vM+MJnUePsL9RaosXcytRNLM3+G/UWX8+9zE43t9dew7yWaT1xQghxppCCTgzaxIkT2b9/v2EfISGEONuEQt4hiRtZMgmLy0GHv2XAZZc6OkmuVEaWTDLMM8ftIEePUIMCygALcHSNXHTmuB2GeVZv34G19gDteUUxT8u01h5k9fYdjJ4Su7m41z6aosA/udS7k6MXBKWEVC6t3InmGYnXfrXheAAagu1MnjScmnEPEbb17pUzt6cxedf1NATbKY6TQ01NYmXqJh7J+02/e/VmH4/k/Yb7qm7jqlTjz1kIIU43suRSDNojjzzCN7/5Tf71r39RXV1Nc3Nzn39CCHE2slo9QxKnqiYuu/VrKCjoRy3f1NFRULjs1q/FnYFSNY27XvwDoICu9b2pa4DCnS/+AVXTBnp6jybVgqXFh61qH0q47548JdyBrWoflhYfTarFME+Ww2bYbgC62g04jNsfhMNhTFtXUz3lF4StfQ8+CVubqJ7yC9StqwmHjZeSmvMdLM19qe8AjhrQ0zn/hznfuOAVQojTjczQiUG7/PLLAbjyyitRjvhLrq7rKIpCJGK8f0QIIc5EbvcsrNYcQqFaYvUJsFpzcLtnxc1VXDqXKxd/l3eefZrWxoae66kZWVz0ha9QXDo3bo7gho3Me+8tHvL5+N9rv0BdWu/pkVlNjdz1tz8yb/N6ghs2klI6O2aeEcXFVKZEoKUJc4uPiD0V3WxBCXdiCragoGNK0RhRbDwnNlTtBraXrSNY/I/eJx2dRIe20f9ke9mFTJ0d+3PaVL+JepPBSZgK1Jkb2VS/iVk58f9/JoQQpwsp6MSgvfvuu6d6CEIIcdIpiokxxQ+wbfud9La47rkLwJji+xPuR1dcOpeiWaVU7fyQVl8TDncaeeMnxJ2Z6xaui546+YnN65m3ZQPbRo+jwZVGhr+JSXt3YepaLtkdF8u5hSG0udV89FYeCjrmYMsRd6M5Rsyt5tzCkGGeoWo30OIv67PMsh8FwsmNtPjLgNgFnTdYm9B4Eo0TQojThRR0YtDOP//8Uz0EIYQ4JTyeS5k08RfsKf9+nwNSrNYcxhTfj8dz6THlU1UTIyZMPq6xmLN6Z7lMus7U8p1x4wYS6WzAPaqFgkuqqFqVTWegd2mlJSVM3txa3KNaiHQ2GGQZunYDlpQQHe3x81hSjAvM5IjxeI81DkDTIsddgAshxFCRgk4MmWAwyIEDB+jo6HtC2OTJx/fLiRBCnAk8nkvJyprfdeqlF6vVg9s9K+GZuaFinzkDc04O4dpaBmz+piiYs7Oxz5xhmMdsji7VdI9qwVXQQmuNnXDQjNkexpET7DlvpTsulu52A62NsdsSJNJuIJLphkOGIb1xBkbbXRBORTe1xDq8EyWSGo1LQPnaVbzz7K/7vD9HeiYXfTGxJbJCCDFU5FAUMWh1dXV88pOfJDU1lQkTJjBt2rQ+/4QQ4mynKCbS0uaQk3MlaWlzTnoxB6CYTGR/997uAR09QACyv3svisl4bMEtSZjb00CPHpaZOixI2uhmUod1FXM6mNvSCW5JMsyjqibSLroGnf47DLuvuS+8Ju6Mlt+UTbAzaeBtil3Jgh1J+E3Zhnl212fQVnNV9ClH5ep+3FZzFbvrjQtViBZzrzz5aL9itbWxnleefJTytavi5hBCiKEiBZ0YtHvuuQefz8fatWtJTk5m2bJl/OEPf6C4uJhXXnnlVA9PCCHOGJqmU7W7iT3ra6ja3YSmxapiBuZcsIC8nz2FObtvcWPOzibvZ0/hXLAgbo5QQxDPrhuiDwaqxADP7usJNQQN80Q0nRc2JqG4z0c39y3+dHP0+gsbk4jEeY+ZyR6e93e99ADj0YHnm6NxRoJaAeGWibRX3YgedvZNE3bRXnUj4ZaJBLUCwzyaFuGdZ38NgILOcLuPcU4vw+0+lK4BvvuHX6NpciCYEOLkkCWXYtDeeecdXn75ZWbOnImqquTn53PJJZfgdDp57LHHWLRo0akeohBCnPb2bfLy/gvlBHy9e8FS3FbOu66YommJtUiAaFGXevHFBDdsJFxXhzkrC/vMGXFn5rrZMlJRymYybMtdeMf9+ai+b+l4dl9Pqncm+pQUwzxr9tYzrb2BlpwA6JMwtbWghDvRzRYiyamgBJjmb2DN3nrmjYm9r68kUMCBkJnfN8Cn3Z24zb1VXVNE4R8+CwdCZkoCBYbj8TjtAOTX2Dn3wzwCrmTarBGSQyZS/Ol8kGFnX0pvXCxVOz+ktbGe0an1XJi9D6eld5tBc2cS79YWsbchGne8+yGFEOJYSEEnBi0QCODxRH/ZSEtLo66ujjFjxjBp0iTKyspO8eiEEOL0t2+Tl2VPb+93PeALsezp7Sz86sRjKuoUk8mwNYGRYedPZt+y5ThqZ+DwTqctbTdhqx9zyEVy01jQFYJaC0Xnn2OYZ+eaw2ip+6MPVIVISt9ZMXTQUivYueawYUHX3LiBT6WF+H1DEtvaVIqsOk6TTnNEYV9IQUfhlowQzY0bcHB5zDyzC9OZEd7HOd7lADgbe/vf6QS5zPsmq0csYHZh7BwArb4mRqfWc2Xezn4Thg5zB1fm7eSVqvG0+hI75VMIIQZLllyKQRs7diy7d+8GYMqUKTz99NNUVVWxdOlScnNzT/HohBDi9KZpOu+/UG4Y88GL5ce8/PK4qQovZSyLfq0r2JvG46yZg71pPOjRvXj/l7EM1AFOFjmC5veimTr6947rpoBmCqH5vYZ52ht3McUe4ZaMDlwm2BsyURY0szdkwmWCWzI6mGKP0N64yzCPonVyXtXy7pc+eigAnFe1HEXrxIjD5eQTOZXo9P8IVCW6BPS8nEocLudATxdCiCEnM3Ri0O6++26qq6sBePDBB1m4cCF//vOfSUpK4tlnnz21gxNCiNNcdbmvzzLLgbQ2hagu95E3NrFWAINR5i3jr7nvEuwMcGPzp3GYeguTgNbMc85/8HLuOuZ7ywwbcOdkmDmcQAeAnAzjX0UsWvRvz1PsESbaNPYdHksw6MJu91OUsxuTqveJi+XQOy8Q0QzrSyJaNG7kgpti5sm1+TGbY+8fVBVINwdx2vyG4xFCiKEiBZ0YtBtvvLHn6xkzZlBZWcmuXbsYOXIkmZmZp3BkQghx+gs0Gxdzxxo3WHXBaOPxl0eu41/aes6tHY8n5MZr9fFB9k4iXQVUd1wsJbPzKdsT//VKZucb3nell9LR9Fva68bh3fw5tLZ0bIAGVCQ34pn6PLbM3bjSSw3zNG7Z2vO1gkKmbTjJJgdtkVbq2w+hdy2gbNyylZEGZ8fs/6iCMV1fazpUBV20hpNwmDvIs/t7Zu32f1TBmNEXGL95IYQYAlLQiSFnt9uZPn36qR6GEEKcEVKc1iGNG6wse+9+toiq8+/cHXHjBjJqVAEWk5XOcGjgaTEdLGYro0YVGOZp8HjY+85nUA9+ot+9cJubw6vvQBvxH8Z9zoPRIkerEv388uxjmJ5xMXZzb3Qw3ExZwwqqgnt64mLx6m7GAOXNGbxTW0RruDfeYQ5xUfY+ip0NPXFCCHGiSUEnjsvixYsTjn3yySdP4EiEEOLMllvsJsVtNVx26UizklvsPinjme6ZTrY9G2/Q2zNrdSQFhWx7NtM98f9wZ05S6QwT3Vh2ZFGn996Pp6U1gF41pyvF0ZWhio6OXlVKS2vAME/enEsp3NLCLM/VRIANaSbqrQqZIZ2pjanM81zN+sMvkTfnUsM8poJ5rH0jnw+qRvS71xpO4pWq8ZzLIUwF8+K+NyGEGApS0InjsmnTpoTilKOb2wohhOhDVRXOu654wFMuu517bTFqnENIhopJNbFk9hIWv7cYBaVPUdddUH1n9ncwxWkIXllZSVtbW7SQG+g8FwXa2tqorKyksLAwZp72JhMmLfasmYKCSbPR3mQ8HkU1MS3jYt7JNvOT8Ta8tt5i0tOu8Y2d7XwiNB8lzvuaWZjOT72jMRFi4ONVdP7tLeLrhemGeYQQYqhIQSeOy7vvvnuqhyCEEGeNomkeFn51Yr8+dI40K+dee2x96IbC/Pz5PHnBkzy+7nFqg7U917Pt2Xxn9neYnz8/bo7W1tbeB7GOlTw6bgANHb4ERhw/rmN/M++PzOI7U2397nmtCt+ZmswPyWLRfj/MjZ2nZvcOTJ0dGB2vYursoGb3DulDJ4Q4KaSgE0IIIU4DRdM8FE7Jip562RwixRldZnmyZuaONj9/PhcM+wRb336eluoDpOaOZPL8z2G2JCX0fEeKY0jigkktQPzXjMbFpttc/Hh810zf0atHFAV0nZ+Ms3J50GWYJ9H+ctKHTghxskhBJwbtwgsvNFxa+c4775zE0QghxJlLVZWT0pogEc3Ll1P76GMk19SQ3HWtIuf3ZH/3XpwLDI6B7JIdcZGiWwkQ+1CUFKxkR4wLqBGjXfjVg7RpGcRKlGxqYMTo/nvajrRt7Ai89fWxAxSF2mSFbSNGcKFBHoc7sf//JBonhBCDJY3FxaBNnTqVKVOm9PwrKSmho6ODsrIyJk2adKqHJ4QQ4hg1L19O1d33EK6p6XM9XFtL1d330Lx8efwkgTBzOrvOedQ1XK4asrIqcLlqQNcAovcDYcM0Mzo6ON/5u2iaozbjdT8+P/V3zOjoMMxzKPlw/DEnEJczroSAwzXgtsDomCDgcJEzriSh1xNCiMGSGToxaD/96U8HvP69730v7t4IIYQQpxc9EqH20cdAH6Bk0fXoTNajj5F68cUoptgHiKipSRRqHi50Q3DsP0my9Z5C2dGegn33pyms9aCmGi+nNAXq2DXcwt9KHCzYFMTV1juu5mSV5dPsFDRbKAoY98Vz0wjkGMb0xsW2rrmNt+ZezlXL/xrr8E7emns5Fze3MS8tNe7rCSHEYElBJ06YG2+8kdmzZ/PjH//4VA9FCCFEgoIbNvabmetD1wnX1BDcsJGU0tkxw6yFLgIFmwkX/6nfDrgka4Dw5D8RKM8kr/Bcw/FEUrJZUrSYOmsSu/OSGFkfxtGm0ZqsciDTjK7AktDXWZiShNH5lIW+BhyRZFpVZ/89dF3vK1VrptDXYDgeb0eY8lETeHnB57lo5Ws4A80991pSXLwz73LKR03A22E88yiEEENFCjpxwqxevRqbrf9pYkIIIU5f4Trjma6E4xQN77i/QIRYp/vjHfcXxih3gEEptto5iTrbRwDoClR6LP1i6mwZrHYWYFQabjuUhelAM0x09sw09uiajVR3+tk2IouJM2Pn8SRFf3UqHzWBvQXjGV79ESnBFgL2VA7lFqCrap84IYQ40eS7jRi0T3/6030e67pOdXU1GzZs4P777z9FoxJCCHE8zFlZQxLn862nQ/OCAhoquxiPjzTcNDGOnaiKRodWi8+3nrS0OTHzfHi4OqHxfHi4mnMz3THv72q1ETrciSXcSOd4F9iO+BWoPYJll5+Q18SuNOM/RM5xO8i1WqgJdaKrKgfzRvW5rwC5Vgtz3Imd8imEEIMlBZ0YNJer7wllqqoyduxYvv/977MggZPQhBBCnD7sM2dgzskhXFs78D46RcGcnY195gzDPKGQF4D1lPJHvkSjktlzL12v52aeYRZre+Jiyaj/EJTRccedUf8hMD7m/dSsLKAFk7cd1duOlpYEVhOEIqhNHT2TiKlxClWTovBIcR5f3v5Rv57p3TkeLs7DZHD6sxBCDCUp6MSg/f73vz/VQxBCCDFEFJOJ7O/eS9Xd9/T0Z+u9GS1Ssr97r+GBKABWq4f1lPIU3+p3r5F0nuJb3MOPmG41bpo+V/eSG3JSY81EV/ofzq3oGrmhOuYmGReG5xRl8b/v7gdA1WGkN0yKHiGg6BwyR5dzdsfFsyjLzW8nFnBfeRXVoc6e67lWCw8X57Eoyx03hxBCDBUp6IQQQgjRh3PBAvjZU9Q8+hjeFh8hixlrZxhPqpucBPvQpbpm8ifltugUVr9G3iroGn9Svsw3XQYb1oCGzFE88v7P+XLJwyi61qeoU3QNUHh43//QcN5dDDPIM2dUBm67hSxfhIvaLDj13jzNisY7yZ3Uu03MGZUR971BtKhbmOlija8Vb0cYT5KZOW6HzMwJIU46KejEoKWlpQ3YWFxRFGw2G6NHj+aLX/wit9xyyykYnRBCfPxomk51uY9Ac4gUp5XcYjeqemyFRq3LwbvjR9LamNJzzZGewUUuB84Enr/W30YDaQP3AgdQVBpIZ63f+Hj/vZ6ZzPV9yG923M/9RV+j2tY7o5cbquP7+/6HGb4drPbMxKjzqUlVuG9KPjVvHOp3L1VXuCqYRM75wzEdw+dkUhRpTSCEOOWkoBOD9sADD/CDH/yAyy67jNmzo0dYr1u3jmXLlnHnnXdSUVHBHXfcQTgc5rbbbjvFoxVCiLPbvk1e3n+hnIAv1HMtxW3lvOuKKZpmvLyxW/naVbzy5KP9rrc2NvDKk49y5eLvUlw61zBHosf2x4vz2KzcO+br/G7H/SysX8la12S8SRl4Ohoo9W/FhMatJQ9zq81qmEfTdFpX16MMUGF2XwusqUe7YswxF79CCHEqSUEnBu2DDz7gkUce4fbbb+9z/emnn2b58uX83//9H5MnT+bnP/+5FHRCCHEC7dvkZdnT2/tdD/hCLHt6Owu/OjFuUadpEd559teGMe/+4dcUzSpFVWPvo/NY+u93O564OW4Hdw2/mC8DD+/9OfP8m3vuVVk9PFD032wefnHcUyWry319ityBtDaFqC73kTc2LaGxCyHE6UAKOjFob775Jk888US/6xdffDHf+MY3ALj88stZsmTJyR6aEEJ8bGiazvsvlBvGfPBiOYVTsgxnoKp2fkhrY71hnpaGeqp2fsiICZNjxszxbSW3vS3uYSZzfC2Qfl7MPD2nSoY+wbLMeZT6t+LpaMCblMFa12Q0xcRvEzhVMtBsXMwda9xQ0jWdUIUfraUDNTUJa6ELRWYJhRAJkoJODFp6ejqvvvoqX//61/tcf/XVV0lPTwcgEAiQmir7DIQQ4kQZqhmoVl9TQq8XL84UqOWRfc/GPczENPyLcV/ryFMlVynTeq4PO4ZTJVOcxksyjzVuqLRtr8f36j4i/o6eayZXEu4rikiemGnwzDOEFoHKVdBaC45syJ8LBjO7QohjJwWdGLT777+fO+64g3fffbdnD9369et5/fXXWbp0KQBvvfUW559//qkcphBCnNWGagbK4U5suWHcOEc2i+rf57c77ue+AQ4zeXjf/7Co/n1wfCeh1xvsqZK5xW5S3FbDoteRFj1A5mRp215Pw3M7+12P+DtoeG4nGTeOP7OLuh2vwLLvQPPh3mvOYbDwCSi58tSNS4izjBR0YtBuu+02SkpK+N///V/+/ve/AzB27Fj+/e9/M3dudNN899JLIYQQJ8ZQzUDljZ+AxeWgw98y4AEiOjpJrlTyxk8wfqH8ueAcxqL6D1hYv5I1RxxmMse/FRM6OPOicYnSNZJCu7AG60jSs0CfDkpisz2qqnDedcUse3pb15Uj31u019651xaftANRdE3H9+o+wxjfq/uxlWScmcsvd7wCL95M39brQHN19Pq1f5SiToghIgWdGBLz5s1j3rx5p3oYQghxRtM0jcrKSlpbW3E4HOTn56OqiR0uMlQzUDqwtqSRaast6Oh9ijq965fzdSVNR/+a3p9qis7EvHgzKnqfw0z07pwLH094+d3blW/z+LrHqQ3W9lzLtmezZPYS5ufPTyhHkXUNC92/4P3mWwlovTNfDrWBc52/o8h6J3ByioxQhb/PMsuBRPwhQhV+bEXukzKmIaNFojNzA/5XogMKLFsC4xbJ8kshhoAUdGJIaJrG3r178Xq9aJrW594nPvGJUzQqIYQ4c+zYsYNly5bR3Nzcc83pdLJw4UJKSkriPr93Bqr/KZfdEpmBKvOWsTWtGt/0ZEp3pJPS3vurQsAWYV1JIwfS2ijzljErZ5bxoEqu5PC0/4djw09oMGXQSgoOAmREGmmduZhhCc7QvF35NovfW4yq6yzsLCJHc1KjNvO2vp/F7y3myQuejF/U9RQZI9GPqjO07sfHWGR0RjRe/7CWqtZ28hw2Lp+QjcWUWAGutRgXc8cad1qpXNV3mWU/OjRXReMKYx+II4RIjBR0YtDWrFnD9ddfT2VlJfpRPyUVRSESiZyikQkhxJlhx44dvPjii/2uNzc38+KLL3LttdcmVNQVTfOw8KsT+/Whc6RZOffaxPrQ1QXrADiQ08bB7CqyG60kh0y0WSPUpofQlb5xRsrXruL/Xt1CKPsWdFPvUk9FC2F9dQufyVkVt59dRIvw+LrH+Vz7RK47fB3WUHrPvdutjbww7AWeWPcEF464EJNRIVa5in3ekSzzfbvfraCezjLft1nIDylKsMj43dpKftjYgN/WVcCF/LiWV/Pt9AxuLc2P+3w1NSluzLHEnVZaa+PHHEucEMKQFHRi0G6//XZmzpzJa6+9Rm5uLkqCG9SFEEJEVzgsW7bMMGbZsmWMGzcuoeWXRdM8FE7Jip562RwixRldZpno3rAse1bP17oCNRkDL+E8Mm4gmhbhtb8+R3teUb97ujmJ9rwiXn/+Of47Tj+7Mm8ZFzV6uKni9n73kkLurutL484Yas21vN98a9ejoz8LFdD4oPlLFDbXEu9T/t3aSv5foBGsffP4rUr0+lriFnXWQhcmV5LhskuTy4q10BVnNKchR/bQxgkhDCW2LkAIA+Xl5Tz66KOMHz8et9uNy+Xq808IIURslZWVfZZZDqS5uZnKysqEc6qqQt7YNMbMyiFvbNoxHfQx3TOdbHv2gAeiACgo5NhzmO6Zbpjn4I7t+FPcXU86KlfXY5/dxcEdsZeIAniba7ju8HU9r913LCqgc93ha/E21xjmqfZlde2bi/VZqLRqWVT7jAvVzojGjxsa+ryP3gFFH/+4oYHOiIYRRVVwX1GEDv1Wt+h6dLei+4pRZ+aBKF0H4sT+rJVjPxBHCBGTFHRi0EpLS9m7d++pHoYQQpyRWltbhzRusEyqiSWzlwADFVDRx9+Z/R3j5Y3ARxUV6Jak/kVPTzIF3WLlo4oKwzwpew5jDaUbFJgq1lAGKXuM9mxBwDbG8H6ica9tq6YpWTV8X03JKq9tq477WocCe1hZ+w/aIi19rgcjLays/QeHAnsSGvNpp/tAHKB/UXfsB+IIIYzJkksxaP/93//NN77xDWpqapg0aRIWi6XP/cmTJ5+ikQkhxOnP4XAMadxQmJ8/nycveHLAUyW/M/s7CZ0qqZstcWMSiXO3tSeUJ16c3Z3YXrR4cRXlDZBAa7iK8gaYmhfzvqZFeOfZX9MarOdwsJxM23CSTQ7aIq3Utx9CR6f5D7+mKM6S1NNWyZXR1gQD9qF7XFoWCDGEpKATg/aZz3wGgC996Us91xRFQdd1ORRFCCHiyM/Px+l0Gi67dDqd5OfHP2hjKM3Pn8+FIy6kzFtGXbCOLHsW0z3T487MdRs5dhysXZ9YnAHVYbx0MdG45Mw9mJMbCbe5GXiBkoY52Udy5h7gnJh57K0ByEyOOx57a8DwftXOD2ltrAei7SDq2g/2i2lpqKdq54eMmHCG/mG05MroqaGVq6IHoDiyo8ssz8QCVYjTmBR0YtAq4iyXEUIIEZuqqixcuHDAUy67LVy4MOF+dEPJpJrityaIoaCgELvNSrCtfeDlibqOPdlGQUGhYZ7cGbNoWdmMpdMx4KFbuq7TYWkld4bxODs66sie9jxVq+4ANPoWdRqgkD3teTo6bjbMM8mm4WnX8FqVmO8ru11nks24wGz1NRneP9a405ZqktYEQpxgsodODFp+fr7hPyGEEMZKSkq49tprcTqdfa47nc6EWxacblRV5ZNXXhUteo5u/KbroCh88sqr4haq6Rlz2NamdT2t/+EhANvbNNIz5hjmaalLJnX4JvLm/gpzsq/PPXOyj7y5vyJ1+CZa6oxn33Jm5XLXzpbe93H0+wLu3NVCzqxcwzzJrjTD+8caJ4T4+JIZOjFkduzYwYEDB+jo6HsE85VXyjp5IYSIp6SkhHHjxlFZWUlraysOh4P8/PxTMjM3VLoL1WXL3qC5uffgD6fLlXDD9Jq9LRwK2IlYIkxKNpF8xKRYmw7b2yJUd9qp2dtC3tjYxU84MIZQezKOvE3Yh21li38+TZEc0kw1THG9japEaG+3Ew4YH4pSMKoAR+s7PLG5hJ+Mt+G19Q4ou11n8a52LIG9FIwynpU6lOSh1aqRElIGPPBFRydg1TmU5KHAMJMQ4uNOCjoxaPv37+dTn/oU27Zt69k7B/QsjTnWPXS/+MUv+NGPfkRNTQ1Tpkzhf/7nf5g9e/aAsRdccAH//ve/+12//PLLee21147xnQghxKmlqiqFhcZLEM80gy1UA83RPnjVnTrVnWEyzAo2Bdp1aAjr/eJiOXRgG/u8s2ktaedP6pdoTO892SRd/zQ36c/g2GfD4tlGyTmxV5eoqsrUz87l3b8u4/Nr2tnvdhJMsmLvCDHK10yrZuPCz8dfIrveW8a6CfVcWJaFjt6nqIs2LYB1E+pxess4d8zlhrmGWkSLHPfeSSHEyScFnRi0u+++m8LCQlasWEFhYSHr1q2joaGBb3zjG/z4xz8+plwvvPACixcvZunSpZSWlvLUU09x6aWXsnv3bjweT7/4v//9731mBBsaGpgyZQrXXHPNoN+XEEKIoTGYQjXFae3z+MgizijuaJoaYL1SynJlNoqmMaJmPynBFgL2VA7ljORn6rdYoKyjWDU+zKRbnSl6iE2ev77nWkiBOlPsRuFHUs2tHMhp41C2l6KqTFyOgp5TLv2tFezLa+BATjuq+eS0q+j2duXbA55uumT2koRONxVCnHxS0IlBW716Ne+88w6ZmZmoqoqqqpx77rk89thjfO1rX2PTpk0J53ryySe57bbbuOWWWwBYunQpr732Gs888wxLlizpF5+ent7n8fPPP4/dbpeCTgghzhK5xW5S3FYCvtgzcI40K7nFbsM8rsxMVjpGUrz/Qy5a9TrOQO+pos0pTt6ZezkriyZxh63NMI+maSxbtswwZtmyZYwbN85wlq50ZAFbX9H4r23F2CZfh5rc+/NMa2ukfesLtDi2UHpJgeFrDaW3K99m8XuLe2YIu3mDXha/t5gnL3hSijohTkNn7sJ8cdqIRCKkpqYCkJmZyeHD0X4z+fn57N69O+E8HR0dbNy4kfnze39YqKrK/PnzWb16dUI5fve73/G5z32OlJSUmDGhUIjm5uY+/4QQQpyeVFWheFb/FRpHGj3Tg6rGaPTdpXPSDIYd3s9Vbz1PaqDv9/3UQDNXvfU8ww5X0DlphmGeysrKuD83mpubqaysNIyZmTWVO7dMJXn27Si2vnv/FFsaybNv584tU5mZNdUwz1CJaBEeX/d4v2IOepeAPrHuCSKatCIS4nQjBZ0YtIkTJ7JlyxYASktL+eEPf8jKlSv5/ve/z6hRoxLOU19fTyQSITs7u8/17Oxsampq4j5/3bp1bN++nS9/+cuGcY899hgul6vn34gRIxIeoxBCiJNL03TK13txm8CmRBiWtJ1i2/sMS9qOTYngNsHeDV40beClmN28HZ1ctDK6t/ro0q/78UUrX8fb0WmYp7U1sSWQ8eLaN24ic/S10dc/qv1B9+PMomtp35j4KpfBKPOW9S6z1CGzLZPhrcPJbMsEPVrU1QRrKPOWnZTxCCESJ0suxaDdd999BALRPQff//73+eQnP8l5551HRkYGL7zwwkkbx+9+9zsmTZoU8wCVbvfeey+LFy/uedzc3CxFnRBCnKaqy304Ax18wrkOt+XXmNWGnnthLQNf51f4T2sp1eU+w1Mu2zdv6LPM8mgK4Az4ad+8AYZdFjPO4XAkNO54caG9TX2WWfYbj6Kg2NMJ7W3CYdyRYUjUBesAGBYYxpSGKdgj9p57QVOQLRlbOJxyuCcuUZqmU13uI9AcIsUZXRobbzZVCHFspKATg3bppZf2fD169Gh27dpFY2MjaWlpAzaBjSUzMxOTyURtbW2f67W1teTk5Bg+NxAI8Pzzz/P9738/7utYrVasVuPN80IIIU4PAX87cxxryUh6rN89k9JARtJjzHHcS6t/nGGeTJ+XWsOI3jgj+fn5OJ1Ow2WXTqczbh9W1eYCwnHHE4078bLsWQwLDGOOdw4aUOXK7Dm9M8dfxxzvHNZ41pBlz0o4575NXt5/obzP/scUt5XzriumaJrxMlohROJkyaU4IdLT04+pmANISkpixowZrFixoueapmmsWLGCc845x/C5f/vb3wiFQtx4443HNV4hhBCnJ3sghCfpN0C0R/mRuh97kn6DPWDctiDH7O/5WgfC9lQ6nemE7al9do0dGTcQVVUJeiai6wP3Fdd1CHomxm1bkDS52PD+scYN1tTMqUxvnM7+zGH8pXQhr049lxUls3h16rn8pXQh+zOHMb1xOlMzpyaUb98mL8ue3t7vMJuAL8Syp7ezb5Nx4SyESJwUdOK0snjxYn7zm9/whz/8gZ07d3LHHXcQCAR6Tr28+eabuffee/s973e/+x1XX301GRkZJ3vIQgghTqCM8DbMSn2/Yq6booBZqScjvM0wz8QxHhzmEJ2pbgKjJ9OWP5b2vFG05Y8lMHoynaluUs3tTBxjPHPUEdZ45sNO3u0sIoilz70ASbzbWcQzH3bSEdYM8+xw7KfO3IQ2wCEkABo6XnMjOxz7DfMMlUMHD1HlLuCtktkErLY+9wJWG2+VzKbKXcChg4fi5tI0nfdfKDeM+eDF8rj7HoUQiZEll+K0ct1111FXV8cDDzxATU0NU6dOZdmyZT0HpRw4cKDfXz13797NBx98wPLly0/FkIUQQpxAJqVxSOLMrjxG53XyfnJRv3u62UJ7XhFFbYcwu/IM8/xp9UdoOhzQ0zkYSiNbbSGZTtqwUKuloncdsfKn1R9x63mxDwara6/n5ey/cV/VbWjoqEcc1aJ1ZXk6+yWuav+84XiGir+lhZVFk6MPBpoK1XVWFk3C39ISN1d1uc+wzQRAa1Mo7r5HIURipKATp5277rqLu+66a8B77733Xr9rY8eORT963YsQQoizgmVUIXyQYJwBbcQcNqfMBo2YBcvmlFlcOGKO4fKlysZgz9c6CjWaM27cQLLsWaxybuYRfsPttdeQFe4tbOrNTTyd/RKrnJv5sv1rhnmGyj5zMgGbwayiohCw2dlnTmZqnFyBZuNi7ljjhBDGpKATQgghxGlLKZiHlpyDEqwZcNmlroNuz0UtmGeYp+LgIVp0e/+eBT0vpNCip1Bx8BBFhbGLw/x0e8x7xxI33TOdbHs2q9nCmtQtTAiOJj3sotHs50P7XnQFcuw5TPdMT+j1Bi09HWoDicXFkeLse/BYhlnBpkC7Dg1hPWacEOL4yB46IYQQQpy+VBPqtGi/tqO3XHU/VqddA6rJMM2m2sSO248Xd9M5BdjinPmVrETjjJhUE0tmLwFAV2BbSjn/dm1gW0o5elf+78z+DqY472uo5FiThiwut9hNittKrkVhgdPMuQ4zM1Oi/7vAaSbXouBIi7YwEEIMnhR0QgghhDh9aRGWbdjF7R33UKP3nR2q0dO5veMelm3YDVrEME1bUnJCLxcvzqIqLLGkGMZ8x+LAkkCvtfn587lh+sNgSiOnwUrhYTs5DVYwpXPD9IeZnz8/oTH30CJQ8T5seyn6v3E+kyPNcTvItVoMY4ZZLcxxx+/Dp6oK58/LYZbd1K/4tSkwy27iE3NzpB+dEENEllwKIYQQ4rQVqVjJd/yfwY+DtzpmMlvdhQcfXtys08ah6Qpr/OO5pGIlpqJPxMxTmD+SLUk2UjraB1x1qQOt1mQK80cajidU4Wd+hwkLyTxFO3VHnFLpQeFubJzfoRKq8GMrchvmeq3Ox2vrWvnUyrw+Tc9bUpy8FmplYo6PRVnGOXrseAWWfQeaD/decw6DhU9AyZVxn25SFB4pzuPL2z8C6HP2Zvfn9XBxHqYEWhLpmo5tez1hBZSjPm1FUdDRsW1vQF80CkWKOiEGTWbohBBCCHHaWr3Xi19JBUVBQ2WNVsIr2lzWaCVoqKAo+JVUVu817mt2TrqTHeOnAfRrFND9eNe4qZyTPvAhJ93CzR0AnI+Fl3Dwc+w8SDI/x87fcHB+VyuD7rhYIrrO02+8yZXL/0pqoG+TckegmSuX/5Vfv/EmkUQO/drxCrx4c99iDqC5Onp9xyvxcwCLstz8dmIBOUfN1OVaLfx2YkHCxWWowk/E39GvmOumoBDxhwhVGPf8E0IkRmbohBBCCHHaemd/JxB/ueQ7+zs51+C+SVG489xSftAZYe7erTg62nvuBaw2VhVN5v+dWxp3BmqXGianOyca56g7UGlCI42QNgEw9cTNNMizurGZae+9DPQ/p0UhWmROfe8VVi9ayLkZrtiJtEh0Zm7AfnZ6NNuyJTBuUdx9hhAt6hZmuljja8XbEcaTZGaO25HQzFy3cHN7/KBjiBNCGJOCTgghhBCnrXBLEDCeNeuNM7Yoy41d7cD86r/QLCpttmSS29tQOzUWfWMcFyYwA3XQY0OxKuR3foDb8hvMSn3vGPRMfJ238VHSuRz02AwLugM7P+yzzPJoCuAM+Dmw80M4d27sRJWr+s/M9aFDc1U0rvA8g7heJkVhXlpqQrEDaWo8HPMw0aPjHD3lsRDieElBJ4QQQojT1vjUCA5vK62mlP794wB0HUeklfGp8Q8AaV6+nOz77gX6zoppgHLfvTQ77TgXLDDM4bFZOJj2d6Y3/a7fPRP1ZFge4wP3rXhsUwzzpASPKOYUHUdOELM9TDhoprXGTvdRl33iBtJaa3z/WOOGQKu1BVO4lWRTKsoA/z/TdZ1gpAXNatD3TgiRMNlDJ4QQQojT1uy5szivoauz+NH7yboen9ewktlzZxnm0SMRKh96BOi/xFElujix8qFH0CPGheEcRxJX+H4fzTNAf3KAK3y/Z47D+Hj/KcOGAeAqbKbk+r2MvvIABfMPM/rKA5RcvxdXYXOfuFi0lCzD+8caNxQcaWmUNawAosXbkbofb2pYgSMtrd9zhRDHTgo6IYQQQpy2au3DGdZZy2XeN3FE+ja+dkRaucz7JrmdtdTahxvmaV2/AXNDXcylgCpgbqijdf0GwzymDb/FhDbgZCFEizoTGqYNvzXMM7JkAukTdAouqcKSEu5zz5ISpuCSKtIn6IwsmWCYpyropKUzqV+t203XobnTSlUw/rLVoZI3fgJ+WyMrvf+kLdLS514w0sJK7z9pTm4kb7zxexNCJEaWXAohhBDitFXbGmL5uZ/kqndfpDD4EdW2XIImO/ZIkNz2alR0Xr7gWia1hgzz7P6wAuPucb1xM+eUxg5o+iixgceJUxQoPM9LWBt4pk/Xo/fjnUXS6m+mrLaIK/N2out9c3UXee/WjmKMP87SzSGkqiYumj+NV15czuG23Qwb6SDZodDWqnP4UCu6Dld+cgHqSWqaLsTZTgo6IYQQQpy26pMUysdO5mWLiYtWvsbwQO8BIM0pLt6ZdznloyZQn2Rc+TTYUhIq6BpsxlG6uyChAz/ixfl864nojYYzfRG9EZ9vPWlpc2LmcbjT2NuSyStV47koex+plt52CS1hK+/WjmJvSybT3SdxeaMWobhyKfNnhKgeZ8biiC5jdQBprSZydkUorqwA7a6ETt4UQhiTgk4IIYQQp630jGTwQvmoCewtGM/w6o9ICbYQsKdyKLcAXVV74wxUj7FiT4X0loH3m2hAY2o0zkhb2mdQ+H9Y0WPmaUeBtM9gN8gTCvX2zdNQ2cV4fKThpolx7ERF6xc3kNyx41AUlb0tmZS3ZGJzm7FZNNo7Vdp9YRRAUVVyx44zzDOkKlfhtdRTPyUVC2GO3LVoTglTPwO8O+rwHMPJm0KI2KSgE0IIIcRp68gm17qqcjBvVNy4gWSmd/LsJSrf+LvW3Z2tN2/X42cvUflUeqdhnoqDVTyX4eEHDbV0ApttVupMJrIiEaa2hzABj2R4uOFgFRPGxz6S32r1ALCeUv7Il2hUMnvupev13MwzzGJtT1ws1bt3oesae+2FvJ9xLq1mR889R2or5zV8wOhgBdW7dzFiwmTDXENFb6lmz+iumc4Y60n3FKWQ1VKd0GynEMKYFHRCCCGEOG3NcTvItVqoDsUutIZZLcxxO2LeB8hOMS6MEo3b3LmdfzmtVCZlU202UW/u/VUqMxwmNxxhm83KhM7tTGBGzDwu50w2dl7MU5Y7+t1rJJ2n+BaLO37FhU6jbnbQ6mtir72QNzyX9r9nSuENz6Vc5n2TVl+TYZ6h5DP7CFkNllIqCiGbCZ/Zh5xzKcTgySmXQgghhDhtmRSFR4rzoksHj7rXfe3h4jxMcU4PmZYxhVvf7n3e0Xl04NYVCtMyjPvHdWZETxrZZrNSb+r7d/F6k5ltNmufuFiC+/38iS91DeDoWaxoI4U/KV8iuN9vmCfZ6eb9jHNj5Ik+fj9jHslOt2GeoRRKyx7SOCGEMSnohBBCCHFaW5Tl5rcTC/otq8y1WvjtxAIWZbnj5giVbSatWTNsW5DmjxAq22yYZ+yIsdEvjl63Cb2V4ZFxMbxd/hF1SbaBm6UDKCp1STbeLv/IMM/h5NzoMkuD01VazakcTs41zDOUrLbECrVE44QQxmTJpRBCCCFOe4uy3CzMdLHG14q3I4wnycwctyPuzFy3cF3dkMQp3a8X62WVo+JiqNLbIYFzN6NxsdW1Gu/5O9a4oeB2z8JqzSEUqokZY7Xm4nYbN4MXQiRGCjohhBBCnBFMisK8tNTjeq45K2tI4hraGhLKEy8uGOcQl0TjPKm2hPIkGjcUFMXEmOIH2Lb9zq4rRy4/jRa6Y4rvR1GkZYEQQ0GWXAohhBDirGefOQNzTo7h0kRzTg72mbEPMgFQGozbIyQaN8qdibU90tv9+2i6jrUtwih35sD3u8wuTCfXZTOcMMx12ZhdmB5/0EPI47mUsc7HMIf6HntiDqUz1vkYngEOcRFCHB+ZoRNCCCHEWU8xmcj+7r1U3X1Pz9H5vTej5VD2d+9FMRnPGhVoo3G1KvhT9IGXXergDigUaKMN8zib/4O2cwRMTY+O5chCs2ts2i4fTts2YOBWDQAmVeHBK0q447myI7fwRd9W1/8+eEUJJvXkNgho214PL+Uwih/TlrabsNWPOeQiuWksoNJmqyd5onGxKoRIjMzQCSGEEOJjwblgAXk/ewpzdt/DOMzZ2eT97CmcCxbEzWE/uJvSD7tmnY6eXOt6PPtDN/aDuw3zlDj2kumvxrK5AaU90uee0h7BsrmBLH81JY69cce0cGIuv7pxOjlOKzlqM4VqAzlqMzlOK7+6cToLJ568A1EAdE3H9+o+ABRU7E3jcdbMwd40HqXrV0/fq/vRNeOTQIUQiZEZOiGEEEJ8bDgXLCD14osJbthIuK4Oc1YW9pkz4s7MdQv49jOsIZULy0ysLWkkmNxbjNnbTZTuSGdYg52Ab79hHrtjJJ8f939sfmM2X/nTK1QPz6XBlUaGv4ncQ9X8etKVTL1sHXbHZQmNa6TaxGetW2jpaOm5lmo9zEh1GHByC7pQhZ+IvwMATdeobz9EW6SVZJODTNtwVEUl4g8RqvBjK3Kf1LEJcTaSgk4IIYQQHyuKyURK6ezjeu5Hgehpkfm1dkbW2mnPSaXTpmJp17DVtPQsc/wo0MkEgzzusV/kgld/yCfX7QIgu9zXc08D7lv3R1ondOK+9oW4Y9qxYwcvvvhiv1YKLc0tvPjii1x77bWUlJQk/B4jWoQybxl1wTqy7FlM90zHpCZ+gInWEi3mDgV2U9awgrZIb5GZbEplesbFDE8Z2xMnhBgcKeiEEEIIIRLkzx8Dq5eRZx/D9IyLsZud0RvJEBzRTFnDCqqCe6Jxhky4XnYRIYBy1Ga8aFtxHdcrLvimcSGlaRr//Ps/DPvi/fPv/2DcuHGoavydNm9Xvs3j6x6nNljbcy3bns2S2UuYnz8/7vMB1NQkDgV2s9L7z3732iItrPT+k3meq8lMnZRQPiGEMdlDJ4QQQgiRoNBwyHEUMc9zNcmmvi0Ukk2pzPNcTY6jiNBw4zzBDRvRGoP9irluCgpaQ5Dgho2Gefbt20dHuNOwL15HuJN9+/YZD4hoMbf4va9TG+jbP84bqGHxe1/n7cq34+YAsOQ72NS0wjBmU9M7WPIdCeUTQhiTgk4IIYQQIkFZ7k4mebpnqnTCdbvpPLSOcN1uuk9FmeS5mCy3cSPvoWp0vnnN2oTyxIuLaBEeX/kg+tEnbgJ616mgT6z6HhEtEiNDr8O7dxDsbDGMCXY2c3j3jvgDF0LEJUsuhRBCCCESNMKXQbreSWd1GaGtL6C3N/XcU2xpWCdfR/qw6eg+44bgQ9XoXPf7E8oTL66sZj21nc0x+/TpikJNh5+ymvXMGjbHMFerr8nw/rHGCSGMyQydEEIIIUSCiswFdB4uo33d0j7FHIDe3kT7uqV0Hi6jyFxgmGeoGp3nuCBFt/ZvodAzqOj9HJdhGuoOrjIOOIY4hzstbsyxxAkhjElBJ4QQQgiRICXFTGir8cmToW0voKQYL4LqbnQefXBUUXcMjc5nzZ7A1HBh9EGMvnhTw4XMmm105iZkRTTD+8cSlzd+Ao5046bhqRmZ5I03HpMQIjFS0AkhhBDiYyWiRVhfs57X97/O+pr1Ce0L67a9clu/mbmj6W1NbK/cFjfXUDQ6L8uaxr9GpnNxx8ToTN0RUnQrF3dM5F8j0ynLmmaYZ1rODLLDYRR94Kk+RdfJCYeZlmM8YwigqiZmfGoW0YpyoCpTZ/rVs1CPoRWCECI22UMnhBBCiI+NwR7L3+KtxZnA67R4a+MHMfhG595OjcOBj8he8x7XTL4Wb4pKGyGSseJp1ejY9iKHsy7A2znLMI8v1cJiv48l6Rkouh49CKVLd5H39WYfvlQLxnNvoOsR2lP+QsElAQ6uzqHCWUzAnkpKsIXC5nJGnFNDe8pf0fXbURQp6oQYLCnohBBCCPGxED2WfzH6UbNG3qCXxe8t5skLnoxb1KU4fQm9VqJxAJqisjWzCK81D0+qjdmKSqJljsekcNeLfyDsayRSvRl3ZjFpVhd6yE9bfTk6Onf+7QCWm681zLOz+gDDh5u4cb+b5zIjYGntvRl2cmO9yvBRPnZWH+C8OOe5+HzrCYVq2N56Ac9ddRMtqe6ee6ktPm7c/yfcoffw+daTlmZ8wIoQIj4p6IQQQghx1otoER5f93i/Yg6iTbwVFJ5Y9wQXjrgQk8FSwJHTc2hy66g+Buwhp6MTSYvGJWLZ9moeenUH1f72nmu5LhsPXlHCwom5cZ8/ed9uDvkae149Ur+nz30FyG5qYPi+3ZBZGjOPP+RkdWQWv/TdiuKLkJu8F7saJKjZqWkr4peYIfI7SkLx5ydDIS8fbL2AX02+q9+9Focren0rTCjxxs0lhIhP9tAJIYQQ4qxX5i3rXWapQ2ZbJsNbh5PZlgl6tBCrCdZQ5i0zzGO35+C/JtyVpm9x2P24+bNh7Pb4Bd2y7dXc8VxZn2IOoMbfzh3PlbFse3XcHFptYkVRvDi3axZ/3nkNI9UmPmvdzgK9hXMjERboLXzG+iEj1Sb+vOuzuF3GSzcBFCWd50bd1P3g6JsA/HnUTShKekJjF0IYkxk6IYQQQpz16oLRBt3DAsOY0jAFe8Tecy9oCrIlYwuHUw73xMXids8iMstFI37cfzNj8vXei6SB/7NhtNlu3G7jwiei6Tz06g50wKTDxRELOSjUoLPC1ImmwEOv7uCSkhxMaozWBkC4sTHmvWOJU1QTrnCECy37+t2z08mFln2821mEksBBJu+sqqfFXWDwYgrNqW7eWfURn/9U3HRCiDikoBNCCCHEWS/LnsWwwDDmePvv2UqOJDPHO4c1njVk2eM3/NYjHYSmatRM6cS6V8HkV4i4dEKjdRRFxxwOxc2xrqKRan87n+u0cIvJRoq5t2j7hmbj9+F2nve3s66ikXOKMmLmMaUnNssVL66upY1SywFg4Ek1XYfZloPUtbTFfa1d9dVgVNAdGSeEGDQp6IQQQghx1puaOZXpjdOB/nvfFBR0dKY3Tmdq5lTDPL7GtYT1ICgKigIdY3qP5le6/m9YD+JrXEtaxtyYebwt0WLuTrOt3z27QvR6ZzTOiOWolgfHG2cJNpKidMa8ryjgoANLsBEYYZgrxZpYG4hE44QQxmQPnRBCCCHOeocOHsIatg54kAlEizpr2Mqhg4cM84QOr0zo9eLFZSUncYspWsxpis5W+x7ec65nq30PmhItEG8x2chKTjLMY585A3NOzgBHvUTpgDknB/tM4/5xw1NjL+s81rjzLphBaosvOq034KB0nC0+zrsgfk87IUR8MkMnhBBCiLNea2tr/KAE4qwdWkJ54sUNP9yOqiqsTN3E0uy/UW/x9dzL7HRze+01zGuZRvLhdhgbO49iMlF72yLSH/4dGn3/Uq8RnTWsvW0RxXH62jkcKb050cinCgcBWkmhkjz0rsxHxsUye/hs5r/5X/zDcTvoGihHjEqPjuri2ueZPfwXcXMJIeKTgk4IIYQQZz1HimNI4txpc7B6f0UoSe2/2QxA17GGNNwFxv3VOpva2ZC6iUfyftPvXr3ZxyN5v+G+qtuY2WR8WmZEi/C9pGXkf1rli29pZLb03mtMhT9cYqIy6U2WaV83bMfgtTbQmmRlZsd2LuM9XPQWtn4cvMEFbEiaiNfaQBFFhmNSFbhy9GpGai38SfkSjUe0Ik+nkZv0Z5g6+kMMznoRQhwDKeiEEEIIcdbLjrhI0a0ECDHgqksdUrCSHXEZ5lEKzmXMu1a2FXRGlxQeWdR1LTEcU21FWXiuYR5zmoWl2X/rSnr0i0TH83T2S8xJu9IwT3c7htqxKhtGq5TuG0Va0EWT3c/aov1oJqCrHcOsnNgnb65sbMbsCXHdoX/1u+eklev4F5s9xaxsbOacPMMh0dC4liQ9wGxlLTNZzy59PD7ScNPEOHaiKhro0bhMg32GQojEyB46IYQQQpz9AmHmdI6Jfn301q6ux3M6x0AgbJxHNeE550dM2tHab1mlNaQxaUcrnnN+BHGO968eUxtdZhlrlkqBOksT1WNqDfN0t1kobJjM5zY/QGbn5YTsk8jsvJzPbX6AwobJfeJiOexz8DXvc9EHGgRqk/BXJhOoTYJo/cV/1/2Zw774M507vat7vlbRKOFD5vIBJXyIijZgnBDi+MkMnRBCCCHOempqEoWah4s7J7HGsic6U9clBStzOsdQqHlQU40PIQGg5Eo8/JasZd/Gp9QTSlKwdui49SyUhT+HEuNZNYDGUENC444Xl2XPorBhMqPrZ/DyxJ8TsPp67qWE3Mz96FM9cUam+CsY1lFH80EbtWUuwm29Bak5OUL2dD95I7xM8VcAxstJK70fkWv8tnrizhufQKAQwpAUdEIIIYQ461kLXZhcSRT6PeSHsqhRfbQRIhkrOZobFQWTy4q10HjJZY+SK6F4IUmv/xH18AHMo0bC5TeDJYGCkL4FlqrrTG8PkRWJUGcyUWazonUt5YxXiE3NnMZIXwlvjfl9v3uBJB9vjfk951d8jqmZ0wzzzFCbaT5oo2plWr974TY1en1eEzNmN8d9b0mHI5BAN4Wkw9K2QIihIAWdEEIIIc56iqrgvqKIhud2oqIwTOtfuLivGIWS4EkdzcuXU/voY4RranqumX/6Z7K/ey/OBQviPn+6ZzrZ9mwm1X3EdxoayYn0Fjc1JhNPZKSzPauQ6Z7phnkOlTexYfiyrjd51M2uvXgb8pZxqPwrFI6PXRwOz41QW+Y64on9E9VucjL8rvhF2Agtj2DcqGicEGLwZA+dEEIIIT4WkidmknHjeEyuvrNoJpeVjBvHkzwxM8Yz+2pevpyqu+/pU8wBhGtrqbr7HpqXL4+bw6Sa+InnAn7ircMT6VskeSIRfuKt48ee8w1PpgR4ddfK6DJLg714AauPV3cZ98VrqW7vWmYZO1E4aKal2rjROcCEURehNtF/r2I3HdTGaJwQYvBkhk4IIYQQHxvJEzOxlWQQqvCjtXSgpiZhLXQlPDOnRyLUPvrYwE2zu069rH30MVIvvhjFqPebFmHKxj+j07+EUonWQlM2/gXOu9fwgJU6vTGhcceLMzUn9v4TiUudPRv3NyfT+Mmt9HuDXR+be+VkUn88O6HXFEIYkxk6IYQQQnysKKqCrciNfaoHW5E74WIOILhhY7+ZuT50nXBNDcENG40TVa6C5sNGE2vQXBWNMzBq5Ejj10kwzmmL3zA84ThFxeO8h9zNd2IO9V3aam5PJ3fznXic9/RtOC6EOG4yQyeEEEIIkaBwnfHx/4nGaS3VCf1VPV7cDVMv4Oeb3YTNvpj99cxhNzdMvcDwdZILXKgpESIBFWWARDo6JodGckH8Q2NCFX70kIqzbhapdTNoS9tN2OrHHHKR3DQWBRW9K85W5I6bTwhhTP40IoQQQgiRIHOW8amTicbt6fQnlCdeXJLZzPVjvxZ9EKO/3vVjv0aS2fhv+LsCDnKn+ruOP+mbSEdHAXKn+NkViN+HLtzc2xJCQcXeNB5nzRzsTeNRjvjV88g4IcTxk4JOCCGEECJB9pkzMOfkgBJjsaSiYM7JwT5zhmGe/a5cakwmtBj3NaDaZGK/K35Ht2+ddw03Fz2AEnH3HUrEzc1FD/Ct866Jm2OvfRKtw+0Mm9eEJbnvqCz2CMPmNdE6PIW99klxc9UHE9vXl2icEMKYLLkUQgghhEiQYjKR/d17qbr7nmhRd+ThKF1FXvZ37zU+EAXIcmTz+6SpLAlujJ4bckR9qOvR1ZPPJk1lviOBhm5Ei7q7z/kUf9nyHgeaaxjpzOH6KRfEnZnr5nGm8FDnzfxq+FM4hrXTXp9EuN2E2RbBltmBosK3O2/ni874e+haHJ1YaCcFa8zlmwFCdDo6ExqbEMKYzNAJIYQQQhwD54IF5P3sKczZfYstc3Y2eT97KqE+dFMzp2Gu+m/e8H2bVi2jz71WLZM3fN/GfPiuuA3Bj5RkNvPFGfN54MIb+eKM+QkXcwCzC9PZmvoJ7ui8h1o1nZTsDlz5baRkd1CrZnBH5z1sTf0EswvT4+ZyOFNZY9kD0G8GsvvxGsseHM7UhMcnhIhNZuiEEEIIIY6Rc8ECUi++OHrqZV0d5qws7DNnxJ2Z6+bd68fe4aKCc/iobja5STtJUZsIaGlUd4xHx4S9Ky5vXEbcfINlUhW+OjGP730wmxWRmVynHmY4nRzCwgvaMMKofG9iHqYETgTNz89nTYGTN+3JfHNXiOxQ7yym16rwk3E2XEEnN+fnn8i3JMTHhhR0QgghhBDHQTGZSCk9vl5qgX3be77WMXG4Y2LsuHHnH9drHAtN02FlA98M2ZhnNZOlu3vufRaNlaEwyqoGtEU6apyiTlcUVo6eRF1E59/ZZqY1RcgM6dRbFTalRfcNZpkmocfahyiEOCay5FIIIYQQ4iRLMTUNadxgVZf7cAY6uMpqIfOofW+ZKFxltZDa2kF1uS9urjW+Vuo0QFHQFIWN6WbezLWwMd2MpiigKNRp0TghxOBJQSeEEEIIcZLlFqdjUxsADR2djiQf7TYvHUm+rrYBGja1gdzi+HvWhkLA385EW3RppHLUzFn344k2nYC/PW4ub0c4oddMNE4IYUyWXAohhBBCnGwjZpE16Sb27rqGFudedFPviY9KxEJq82hGjP0bjPjTSRlOcqATxWSJeV9RFOwmC3og/smUnqQET9ZMME4IYUxm6IQQQgghTrKaDS/QllFPc9oOdLWjzz1d7aA5bQdtmfXUbHgh8aRaBCreh20vRf9XiyT8VL3VO2Rxc5zJ5HY0oOgDd9lTdI1hHfXMcSYnPD4hRGzypxEhhBBCiJMs6KukfM+c6IOjzwbpely+Zw4zHJWJJdzxCuFl32GVw4k/2Y6rLcjc1mbMC5+AkivjPr1dC2BP4O/87VogbozpwGoeKf8pXy55GEXX0JXevNEiT+Hh8qcwjbFC4Xlx8wkhjMkMnRBCCCHESdYUyYJwd4uDGBVd2BSNi2fHK7yx/ie8PMVO5+h67HkH6Bxdz8tT7Lyx/iew45W4KZJHuQmGm9GPbJR+BF3XCYSbSR7ljj+e1loW1b/Pb3fcT06ovs+t3FAdv91xP4vq34fW2vi5hBBxyQydEEIIIcRJ1mwbRRij5YsKYSw020YZJ9IivLHlaSwjDuE66pZT8aGM8PHGlqe5bNwiUGP3yMubMJFXQ39nuv1idF3vczBKd5G3q2MdV0xYGOedAY5ow/VF9e+zsH4la1yT8SZl4OloYI5/K6bu9uKObIMkQohEyQydEEIIIcRJltRycEjiwhUfEPTUAKCjsoMJrOJcdjABUNGBgKeWcMUHhnlU1UTJjZey0vtP2iItfe4FIy2s9P6TkhsuRTUoCnvkz6UtOQdNBxMa8/yb+VTdCub5N2NCQ9OhLTkH8ufGzyWEiEtm6IQQQgghTrI8V2K/gsWLW1W/CbfiYz2l/JEv0ahk9txL1+u5mWeYpaxlVf0mPlFk3KC8MifI2tQPqKvYictRQLLJQVukFX9rBfvzGsnMuZziBMYcQeWhzpt5lB+i6XBkH3Kta0XnQ5038wNUEigPhRBxSEEnhBBCCHGSjRxZiNq5B82cBMrRe+gAXUcNhxg5stAwj1+N8CGlPMW3+t1rJJ2n+Bb38CMmqMYnXka0CG/8/kFuW96CTgtNKTWELGasnWHcgXYu/hB+l/49LnzgQkxxZunWVTTyfOtUmtR7eNDyR4bR2HOvhgwe6ryJN0NTuaqikXOKMgxzCSHikyWX4rTzi1/8goKCAmw2G6Wlpaxbt84w3ufzceedd5Kbm4vVamXMmDG8/vrrJ2m0QgghxLGrDrlJqu1aTnn0QSRdj5NqD1EdchvmSc2ayh/5UvTB0YWhogI6f+RLpGZNNcxTVr2Bq1+LFl4qkBFoZ5ivlYxAOyZAB65+rYGy6g3x3hrelmjz8Te12Zwb+jmf67iPr3Xcxec67uPc0M94U5vdJ04IMTgyQydOKy+88AKLFy9m6dKllJaW8tRTT3HppZeye/duPB5Pv/iOjg4uueQSPB4PL730Enl5eVRWVuJ2u0/+4IUQQogEtfr9WFp8ULWPUPZIdEtSzz0l3IG19iCWFh+tfr9hHtU5g0blo9gBikojmajOAsM8LevXktu1dU5TFOqzMmmzJZPc3kZmXT2qrpPZAtXr10JeqWEuT6qt5+sIKitdU8FqglAEtamj50zPI+OEEMdPCjpxWnnyySe57bbbuOWWWwBYunQpr732Gs888wxLlizpF//MM8/Q2NjIqlWrsFgsABQUFJzMIQshhBDHzOFOA8DS4sPc4iNiT0U3W1DCnZiCLT1FT3dcLA2dA7cZONY4V0v0/qHheZRNn06b3d5zLzkYZHpZGcMPVfXEGZldmE6uy0aVFTrHudCTe3/dVNrCWHb5yQtF44QQgydLLsVpo6Ojg40bNzJ//vyea6qqMn/+fFavXj3gc1555RXOOecc7rzzTrKzs5k4cSKPPvookUjsvQKhUIjm5uY+/4QQQoiTKW/8BBzp0QNMFEXH7aohK6sCt6sGRYkWTakZmeSNn2CYx2NJ7Fe5eHGpqSM5NDyPlfPm0Zac3OdeW3IyK+fN49DwPFJTR8Z9LZOqsGjBKDqmpqPb+u63020mOqams2jBKEzqAHsHhRDHTAo6cdqor68nEomQnd23L012djY1NTUDPmf//v289NJLRCIRXn/9de6//35+8pOf8Mgjj8R8ncceewyXy9Xzb8SIEUP6PoQQQoh4VNXERV/8Cq7CZkqu38voKw9QMP8wo688QMn1e3EVNnPhF74St01AsbaDdL0edG3gAF0jXa+nWNthmKc9v5CNM6ZHH/Tbixd9vHH6dNrzjQ9pAYjoOi/5Gw1y6fyfv5FIjCbmQohjIwWdOKNpmobH4+HXv/41M2bM4LrrruP//b//x9KlS2M+595778Xv9/f8O3gwsV5AQgghxFByFbZQuKAKS0q4z3VLSpjCBVW4CltiPLNX/YGPuJlnAKV/UadrgMLNPEP9gY8M8wTa22hPtg984iaAotButxNob4s7pjWNzdQoJoNcKtWKiTWNskJGiKEgBZ04bWRmZmIymaitre1zvba2lpycnAGfk5uby5gxYzCZev+COX78eGpqaujo6BjwOVarFafT2eefEEIIcTLpeoQ95d8HYk2IKewpfxhdN243oHltzGIt9/Aj0o9oDwCQTiP38CNmsRbNa3wASUpKSkLjTiTuwK7yhHIlGieEMCaHoojTRlJSEjNmzGDFihVcffXVQHQGbsWKFdx1110DPmfevHn85S9/QdM0VDX694k9e/aQm5tLUlLSgM8RQgghTjWfbz2h0MDbCaJ0QqFqfL71pKXNiRnlikykoT2NWda1zFDWs0sfj4803DQxjp2ouoa5PR0XEw3Hk5qamtC4E4nL8DdBclZicUKIQZMZOnFaWbx4Mb/5zW/4wx/+wM6dO7njjjsIBAI9p17efPPN3HvvvT3xd9xxB42Njdx9993s2bOH1157jUcffZQ777zzVL0FIYQQIq5QyDskcQ6tHs+uGwBQdY0SPmQuH1DCh6hdSzA9u6/HodUb5snPz4+7YsXpdJKfnx93zHPSXWQ1NRju68tqrGdOuituLiFEfFLQidPKddddx49//GMeeOABpk6dyubNm1m2bFnPQSkHDhygurq6J37EiBG8+eabrF+/nsmTJ/O1r32Nu+++e8AWB0IIIcTpwmrt31v1eOIUGkk+OJbczXeitqezq3E0a6uns6txNGpbBrmb78R2YCzKUcsxj6aqKgsXLjSMWbhwYc9qGCOps2Zw9/KXMdrXd/dbr5A6a0bcXEKI+BRdlyOGxMdbc3MzLpcLv98v++mEEEKcFLoeYeWqTxAK1QID/SqmYLXmMG/uv1GU2CddBtau4/CSp1g7+1Z+Rog6pTdXlq5wN1ZK1/2OYY/fQ0rp7Ljj2rFjB8veWEZbvYKqJaGpHSRn6iy8bCElJSUJv7/m5cv56+//zP9eczN1aRm9Y2qs566X/sTnb7kB54IFCecb8DXk57cQgOyhE0IIIYQ46RTFxJjiB9i2/U4gepT/EXcBGFN8v2ExB2CfOYP33Q6+T/fpk70nrNShcR9tPOB2cMvMxGbDrKFM0utKCfhCPddSdCvWUGZCz+/mXLCAzwPnP/YDNjncNLjSyPA3Ma3Vx7B7lwy6mBNC9JIZOvGxJ3/hE0IIcap4vW+yp/z7fQ5IsVpzGVN8Px7PpXGfH9F05j70OrXt+sBtAnSdHJvCygcvj9vIe98mL8ue3h7z/sKvTqRoWmJLRXtePhIhuGEj4bo6zFlZ2GfOQDEZF6mJkp/fQkTJDJ0QQgghxCni8VxKVtb8rlMvvVitHtzuWXFn5rqtq2ikNoRh/7iaUDTunKKMgWMATdN5/wXjNgIfvFhO4ZQs1DiFYR+6jiXcgJkalLAKMo8gxJCTgk4IIYQQ4hRSFJNhawIj3pb2IYmrLvf1WWY5kNamENXlPvLGpiX0mqE3/4x59QMk0XvCZuStTMLnfB/rpTcklEMIEZ8UdEIIIYQQZyhPqnHD8ETjWuMUc8caF3rzzySt+q/ogyMm9FS9nqRV/0UIpKgTYohI2wIhhBBCiDPU7MJ0cl02Yi2CVIBcl43ZhemGedpaOhJ6vUTi9HAY8+oHoq9/1MC6H5tXP4geDif0mkIIY1LQCSGEEEKcoUyqwoNXRNsJHF3UdT9+8IqSuAeiJKdaUCMdsfe46TpqpIPkVEvcMXWufQsT9Ubb+jBRR+fat+LmEkLEJwWdEEIIIcQZbOHEXH5143RyXH2XVea4bPzqxuksnJgbN0dKqoXivX+LPji6qOt6XLz3JVISKOj0psMJjTvROCGEMdlDJ4QQQghxhls4MZdLSnJYV9GIt6UdT2p0mWW8mblu7uZ95FWvwtIZoHz0NYRsvQefWENNFO99CU/9FtzN+wDjnnRK2rCEXjPROCGEMSnohBBCCCHOAiZVMWxNYCRSHz2J0lO/haz6rfjcowklObF2NOP27UXpanzeHWfEUnoJkbcyUfWBl13qOmhKFpbSS45rrEKIvmTJpRBCCCHEx5w5K6vnawWdNF85Od6NpPnKe4q5o+NiUcxmwud8H4i5epPwOQ+hmGVeQYihIAWdEEIIIcTHnH3mDMw5OYYNys05Odhnzkgon/XSG+iY+0s0pe/yTE3JomPuL6VlgRBDSP40IoQQQghxFojoOmt8rXg7wniSzMxxOzDFKtCOophMZH/3Xqruvida1B05tdaVI/u796KYTAmPx3rpDegXX0fH2rfQmw6jpA3DUnoJVpmZE2JIKboe63xaIT4empubcblc+P1+nE7nqR6OEEIIccxeq/NxX3kV1aHOnmu5VguPFOexKMudcJ7m5cupffQxwjU1PdfMOTlkf/denAsWDOWQB01+fgsRJQWd+NiT8baB1AAAE+9JREFUHwhCCCHOZK/V+fjy9o84+he67rm5304sOKaiTo9ECG7YSLiuDnNWFvaZM45pZu5kkZ/fQkTJnLcQQgghxBkqouvcV17Vr5gD0IkWdfeXV7Ew03VMyy9TSmcP5TCFECeQHIoihBBCCHGGWuNr7bPM8mg6cDjUyRpf68kblBDipJKCTgghhBDiDOXtCA9pnBDizCMFnRBCCCHEGcqTlNjumUTjhBBnHinohBBCCCHOUHPcDnKtFmLtjlOAYVYLc9yOkzksIcRJJAWdEEIIIcQZyqQoPFKcB9CvqOt+/HBxXsIHogDoeoSmpjXU1LxCU9MadD0yNIMVQpwQMv8uhBBCCHEGW5Tl5rcTCwbsQ/fwMfah83rfZE/59wmFevvQWa05jCl+AI/n0qEcthBiiEgfOvGxJ31shBBCnA0ius4aXyvejjCeJDNz3I5jmpnzet9k2/Y7IUZHu0kTf3FaFXXy81uIKJmhE0IIIYQ4C5gUhXlpqcf1XF2PsKf8+/Qv5qC7o92e8ofJypqPopx+TcaF+DiTPXRCCCGEEB9zPt/6Psss+9MJharx+daftDEJIRIjBZ0QQgghxMdcKOQd0jghxMkjBZ0QQgghxMec1eoZ0jghxMkjBZ0QQgghxMec2z0LqzWH/s0PuilYrbm43bNO5rCEEAmQgk4IIYQQ4mNOUUyMKX6g+9HRdwEYU3y/HIgixGlICjohhBBCCIHHcymTJv4CqzW7z3WrNee0a1kghOglbQuEEEIIIQQQLeqysuZ3nXrpxWr14HbPkpk5IU5jUtAJIYQQQogeimIiLW3OqR6GECJBsuRSCCGEEEIIIc5QUtAJIYQQQgghxBlKCjohhBBCCCGEOENJQSeEEEIIIYQQZygp6IQQQgghhBDiDCUFnRBCCCGEEEKcoaSgE0IIIYQQQogzlBR0QgghhBBCCHGGkoJOCCGEEEIIIc5Q5lM9ACFONV3XAWhubj7FIxFCCCFEorp/bnf/HBfi40oKOvGx19LSAsCIESNO8UiEEEIIcaxaWlpwuVynehhCnDKKLn/WEB9zmqZx+PBhUlNTURRlSHM3NzczYsQIDh48iNPpHNLcopd8zieHfM4nh3zOJ4d8zifPifqsdV2npaWFYcOGoaqyi0h8fMkMnfjYU1WV4cOHn9DXcDqd8gvDSSCf88khn/PJIZ/zySGf88lzIj5rmZkTQg5FEUIIIYQQQogzlhR0QgghhBBCCHGGkoJOiBPIarXy4IMPYrVaT/VQzmryOZ8c8jmfHPI5nxzyOZ888lkLcWLJoShCCCGEEEIIcYaSGTohhBBCCCGEOENJQSeEEEIIIYQQZygp6IQQQgghhBDiDCUFnRBCCCGEEEKcoaSgE+IY/OIXv6CgoACbzUZpaSnr1q0zjP/b3/7GuHHjsNlsTJo0iddff73PfV3XeeCBB8jNzSU5OZn58+dTXl5+It/CGWGoP+cvfvGLKIrS59/ChQtP5Fs4IxzL5/zhhx/ymc98hoKCAhRF4amnnhp0zo+Tof6sv/e97/X7b3rcuHEn8B2cGY7lc/7Nb37DeeedR1paGmlpacyfP79fvHyPHthQf87yPVqIwZGCTogEvfDCCyxevJgHH3yQsrIypkyZwqWXXorX6x0wftWqVXz+85/n1ltvZdOmTVx99dVcffXVbN++vSfmhz/8IT//+c9ZunQpa9euJSUlhUsvvZT29vaT9bZOOyficwZYuHAh1dXVPf/++te/noy3c9o61s85GAwyatQoHn/8cXJycoYk58fFifisASZMmNDnv+kPPvjgRL2FM8Kxfs7vvfcen//853n33XdZvXo1I0aMYMGCBVRVVfXEyPfo/k7E5wzyPVqIQdGFEAmZPXu2fuedd/Y8jkQi+rBhw/THHntswPhrr71WX7RoUZ9rpaWl+le/+lVd13Vd0zQ9JydH/9GPftRz3+fz6VarVf/rX/96At7BmWGoP2dd1/UvfOEL+lVXXXVCxnumOtbP+Uj5+fn6T3/60yHNeTY7EZ/1gw8+qE+ZMmUIR3nmG+x/f+FwWE9NTdX/8Ic/6Lou36NjGerPWdfle7QQgyUzdEIkoKOjg40bNzJ//vyea6qqMn/+fFavXj3gc1avXt0nHuDSSy/tia+oqKCmpqZPjMvlorS0NGbOs92J+Jy7vffee3g8HsaOHcsdd9xBQ0PD0L+BM8TxfM6nIufZ4ER+LuXl5QwbNoxRo0Zxww03cODAgcEO94w1FJ9zMBiks7OT9PR0QL5HD+REfM7d5Hu0EMdPCjohElBfX08kEiE7O7vP9ezsbGpqagZ8Tk1NjWF89/8eS86z3Yn4nCG6lOePf/wjK1as4IknnuDf//43l112GZFIZOjfxBngeD7nU5HzbHCiPpfS0lKeffZZli1bxq9+9SsqKio477zzaGlpGeyQz0hD8Tl/5zvfYdiwYT3FinyP7u9EfM4g36OFGCzzqR6AEEKcaJ/73Od6vp40aRKTJ0+mqKiI9957j4svvvgUjkyI43PZZZf1fD158mRKS0vJz8/nxRdf5NZbbz2FIzszPf744zz//PO899572Gy2Uz2cs1asz1m+RwsxODJDJ0QCMjMzMZlM1NbW9rleW1sb89CCnJwcw/ju/z2WnGe7E/E5D2TUqFFkZmayd+/ewQ/6DHQ8n/OpyHk2OFmfi9vtZsyYMfLf9HF8zj/+8Y95/PHHWb58OZMnT+65Lt+j+zsRn/NAPu7fo4U4VlLQCZGApKQkZsyYwYoVK3quaZrGihUrOOeccwZ8zjnnnNMnHuCtt97qiS8sLCQnJ6dPTHNzM2vXro2Z82x3Ij7ngRw6dIiGhgZyc3OHZuBnmOP5nE9FzrPByfpcWltb2bdvn/w3fYyf8w9/+EMefvhhli1bxsyZM/vck+/R/Z2Iz3kgH/fv0UIcs1N9KosQZ4rnn39et1qt+rPPPqvv2LFD/8pXvqK73W69pqZG13Vdv+mmm/QlS5b0xK9cuVI3m836j3/8Y33nzp36gw8+qFssFn3btm09MY8//rjudrv1l19+Wd+6dat+1VVX6YWFhXpbW9tJf3+ni6H+nFtaWvRvfvOb+urVq/WKigr97bff1qdPn64XFxfr7e3tp+Q9ng6O9XMOhUL6pk2b9E2bNum5uf+/vfuPibr+4wD+/Hj4ke5yiGBwERxreO0OsIlFghVskOdWTmcjswSplORX3IJyLDGxCbl26EVL0zYh12T0w9wkEzMpvRAYCpIhUoE0d4vZbEUkxN37+4fzMz9x8pVU4uD52O6P9/v9+rxf7/eb7bbXPvf5oBcFBQXi1KlTorOz84bnnKxux1nn5+eLuro60dXVJRwOh0hOThaBgYGit7d3zPc3Xoz2nN98800hy7L4+OOPhdPpVD5//PGHKobf0Wq3+pz5HU1081jQEY1CeXm5CAsLE7Isi9jYWHHixAllLCEhQaxatUoVX11dLYxGo5BlWURGRoqamhrVuNvtFkVFRSIoKEhMmzZNJCUliY6OjrHYyrh2K8+5v79fLFy4UMyaNUtMnTpVGAwGsWbNmklfZAgxunPu6uoSAIZ9EhISbnjOyexWn/Xy5cuFXq8XsiyLkJAQsXz5cvHDDz+M4Y7Gp9Gcs8Fg8HjOr7/+uhLD72jPbuU58zua6OZJQggxtvcEiYiIiIiI6FbgM3REREREREReigUdERERERGRl2JBR0RERERE5KVY0BEREREREXkpFnREREREREReigUdERERERGRl2JBR0RERERE5KVY0BERTVBCCGRkZGDmzJmQJAktLS1jmr+urg6SJOG3334b07w3YjRr+zf7SExMhNVq/dfrA4CKigrMmDHjpuYAAEmS8Nlnn930PEREND6xoCMimqC++OILVFRU4MCBA3A6nYiKirptuTwVMPHx8XA6nfDz87ttef+t8bw2IiKi0fD5rxdARES3x48//gi9Xo/4+PjrxgwODkKW5duSX5ZlBAcH35a5b9Z4XhsREdFo8A4dEdEElJ6ejtzcXPT09ECSJISHhwO4cictJycHVqsVgYGBsFgsAICysjJER0dDp9MhNDQUWVlZ6OvrU83pcDiQmJgIrVYLf39/WCwWXLp0Cenp6fj6669ht9shSRIkSUJ3d7fHnyp+8skniIyMxLRp0xAeHg6bzabKER4ejpKSEjz//POYPn06wsLCsHPnzhH3mpiYiNzcXFitVvj7+yMoKAi7du3Cn3/+ieeeew7Tp09HREQEDh48qFzzz7WdP38eixcvhr+/P3Q6HSIjI/H55597zPfrr79ixYoVCAkJgVarRXR0NPbu3TssbmhoCDk5OfDz80NgYCCKiooghFDGBwYGUFBQgJCQEOh0Ojz00EOoq6sbca/79+9HTEwMfH19ce+996K4uBhDQ0PKeGdnJx599FH4+vrCbDbj8OHDI85HRETejwUdEdEEZLfbsWnTJtxzzz1wOp1oampSxiorKyHLMhwOB3bs2AEAmDJlCt5++22cOXMGlZWV+Oqrr/Dqq68q17S0tCApKQlmsxn19fU4fvw4Fi9eDJfLBbvdjri4OKxZswZOpxNOpxOhoaHD1tTc3IynnnoKTz/9NNra2rBx40YUFRWhoqJCFWez2fDAAw/g1KlTyMrKQmZmJjo6Okbcb2VlJQIDA9HY2Ijc3FxkZmYiJSUF8fHxOHnyJBYuXIjU1FT09/d7vD47OxsDAwP45ptv0NbWhi1btuDOO+/0GHv58mXMmzcPNTU1+O6775CRkYHU1FQ0NjYOW5OPjw8aGxtht9tRVlaG999/XxnPyclBfX09qqqqcPr0aaSkpGDRokXo7Oz0mPfYsWNIS0tDXl4evv/+e7z33nuoqKjA5s2bAQButxvLli2DLMtoaGjAjh07sG7duhHPjYiIJgBBREQT0tatW4XBYFD1JSQkiLlz5/7faz/66CMREBCgtFesWCEWLFhw3fiEhASRl5en6jt69KgAIC5duiSEEOKZZ54Rjz32mCrmlVdeEWazWWkbDAaxcuVKpe12u8Vdd90ltm/fPmLuhx9+WGkPDQ0JnU4nUlNTlT6n0ykAiPr6eo9ri46OFhs3bvQ4/z9jPXn88cdFfn6+ak0mk0m43W6lb926dcJkMgkhhDh//rzQaDTiwoULqnmSkpJEYWGhEEKI3bt3Cz8/P9VYSUmJKn7Pnj1Cr9cLIYQ4dOiQ8PHxUc158OBBAUDs27fvumsnIiLvxmfoiIgmmXnz5g3r+/LLL1FaWoqzZ8/i999/x9DQEC5fvoz+/n5otVq0tLQgJSXlpvK2t7djyZIlqr4FCxZg27ZtcLlc0Gg0AIA5c+Yo45IkITg4GL29vSPOfe01Go0GAQEBiI6OVvqCgoIA4LrzvPTSS8jMzERtbS2Sk5Px5JNPqua8lsvlQklJCaqrq3HhwgUMDg5iYGAAWq1WFTd//nxIkqS04+LiYLPZ4HK50NbWBpfLBaPRqLpmYGAAAQEBHvO2trbC4XAod+SuruXq36m9vR2hoaG4++67VTmJiGhiY0FHRDTJ6HQ6Vbu7uxtPPPEEMjMzsXnzZsycORPHjx/HCy+8gMHBQWi1Wtxxxx1jtr6pU6eq2pIkwe12j/qaa/uuFlbXm2f16tWwWCyoqalBbW0tSktLYbPZkJubOyz2rbfegt1ux7Zt25TnDq1WKwYHB29ofwDQ19cHjUaD5uZmpZC96no/9ezr60NxcTGWLVs2bMzX1/eGcxMR0cTCgo6IaJJrbm6G2+2GzWbDlClXHq2urq5WxcyZMwdHjhxBcXGxxzlkWYbL5Roxj8lkgsPhUPU5HA4YjcZhRc1/ITQ0FGvXrsXatWtRWFiIXbt2eSzoHA4HlixZgpUrVwK4UiSeO3cOZrNZFdfQ0KBqnzhxArNnz4ZGo8HcuXPhcrnQ29uLRx555IbWFxMTg46ODkRERHgcN5lM+Pnnn+F0OqHX65WcREQ0sfGlKEREk1xERAT+/vtvlJeX46effsKePXuUl6VcVVhYiKamJmRlZeH06dM4e/Ystm/fjosXLwK48nbKhoYGdHd34+LFix7vhOXn5+PIkSN44403cO7cOVRWVuKdd95BQUHBmOxzJFarFYcOHUJXVxdOnjyJo0ePwmQyeYydPXs2Dh8+jG+//Rbt7e148cUX8csvvwyL6+npwcsvv4yOjg7s3bsX5eXlyMvLAwAYjUY8++yzSEtLw6effoquri40NjaitLQUNTU1HvNu2LABH3zwAYqLi3HmzBm0t7ejqqoK69evBwAkJyfDaDRi1apVaG1txbFjx/Daa6/dohMiIqLxigUdEdEkd//996OsrAxbtmxBVFQUPvzwQ5SWlqpijEYjamtr0draitjYWMTFxWH//v3w8bnyQ4+CggJoNBqYzWbMmjULPT09w/LExMSguroaVVVViIqKwoYNG7Bp0yakp6ePxTZH5HK5kJ2dDZPJhEWLFsFoNOLdd9/1GLt+/XrExMTAYrEgMTERwcHBWLp06bC4tLQ0/PXXX4iNjUV2djby8vKQkZGhjO/evRtpaWnIz8/Hfffdh6VLl6KpqQlhYWEe81osFhw4cAC1tbV48MEHMX/+fGzduhUGgwHAlTeV7tu3T8m5evVq1fN2REQ0MUlCXPNPcYiIiIiIiMhr8A4dERERERGRl2JBR0RERERE5KVY0BEREREREXkpFnREREREREReigUdERERERGRl2JBR0RERERE5KVY0BEREREREXkpFnREREREREReigUdERERERGRl2JBR0RERERE5KVY0BEREREREXkpFnRERERERERe6n9rTJW9FjICFwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for trial in trials_dict_new.keys():\n",
    "    plt.scatter(trials_dict_new[trial][:,0], trials_dict_new[trial][:,1])\n",
    "    plt.xlabel(\"fraction mislabeled\")\n",
    "    plt.ylabel(\"angular similarity\")\n",
    "    plt.title(\"Angular Similarity Between Softmaxed Outputs from Model Trained with a Given Mislabeling Percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a3584163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mislabeling_dist_CL(error_percentage, training_dataset, epochs):\n",
    "    mislabeled_dataset = Mislabeling_Dataset(training_dataset, internal_dataset_labels=training_dataset.targets, \\\n",
    "                                             fraction_mislabeled=error_percentage, random_state=0)\n",
    "    model_mislabeled_stats = CNN(len(training_dataset.classes)).to(device)\n",
    "    optimizer_mislabeled_stats = optim.Adam(model_mislabeled_stats.parameters(), lr = 0.01)\n",
    "    loaders_mislabeled_stats = {\n",
    "    'train' : torch.utils.data.DataLoader(mislabeled_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0),\n",
    "\n",
    "    'test' : torch.utils.data.DataLoader(training_dataset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0),\n",
    "    }\n",
    "    print(\"training {}% mislabeled model\".format(error_percentage*100))\n",
    "    converge_fail = train_CNN(epochs, model_mislabeled_stats, loaders_mislabeled_stats, optimizer_mislabeled_stats, max_count=5, count=0)\n",
    "    if converge_fail:\n",
    "        print(\"No output returned.\")\n",
    "        return None\n",
    "    else:\n",
    "        outputs_mislabeled_stats = softmaxed_outputs_array(model_mislabeled_stats, loaders_mislabeled_stats)\n",
    "        return outputs_mislabeled_stats, mislabeled_dataset.labels, mislabeled_dataset.true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5fe63ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 10.0% mislabeled model\n",
      "Epoch [1/1], Step [100/600], Loss: 0.9341\n",
      "Epoch [1/1], Step [200/600], Loss: 0.8406\n",
      "Epoch [1/1], Step [300/600], Loss: 1.0196\n",
      "Epoch [1/1], Step [400/600], Loss: 0.7069\n",
      "Epoch [1/1], Step [500/600], Loss: 0.9914\n",
      "Epoch [1/1], Step [600/600], Loss: 0.8145\n"
     ]
    }
   ],
   "source": [
    "CL_testing, mislabeled_labels, true_labels = mislabeling_dist_CL(0.1, train_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c08ccf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_dict = {}\n",
    "for n in range(len(train_data.classes)):\n",
    "    idx_n = np.where(mislabeled_labels.numpy() == n)[0]\n",
    "    thresh_n = np.mean(CL_testing[idx_n, n])\n",
    "    thresholds_dict[n] = thresh_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "485fa4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictions = np.argmax(CL_testing, axis=1)\n",
    "df = pd.DataFrame(CL_testing)\n",
    "df[\"true\"] = true_labels.numpy()\n",
    "df[\"label\"] = mislabeled_labels.numpy()\n",
    "df[\"pred\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b35c2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass_df = df[df[\"pred\"] != df[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "69079884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_17912\\1716425587.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_df[\"CL_pred\"] = misclass_df.apply(lambda row : row[row[\"pred\"]] > thresholds_dict[row[\"pred\"]], axis=1)\n"
     ]
    }
   ],
   "source": [
    "misclass_df[\"CL_pred\"] = misclass_df.apply(lambda row : row[row[\"pred\"]] > thresholds_dict[row[\"pred\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "edc7c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Small\\AppData\\Local\\Temp\\ipykernel_17912\\3471051112.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  misclass_df[\"CL_true\"] = misclass_df.apply(lambda row : row[\"true\"] != row[\"label\"], axis=1)\n"
     ]
    }
   ],
   "source": [
    "misclass_df[\"CL_true\"] = misclass_df.apply(lambda row : row[\"true\"] != row[\"label\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cbece628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4472"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(misclass_df[\"CL_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "587e31a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5956"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(misclass_df[\"CL_true\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af0150c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
